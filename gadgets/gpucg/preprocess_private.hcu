
/*

-------------------------------------------------------------------------------------
Implementation details header. For internal use only in the cuda NFFT implementation.
-------------------------------------------------------------------------------------

*/


#ifndef _PREPROCESS_PRIVATE_HCU_
#define _PREPROCESS_PRIVATE_HCU_

#include "preprocess.hpp"
#include "types.hcu"

#include <vector_types.h>
#include <cuComplex.h>

#include <thrust/device_vector.h>
#include <thrust/pair.h>

namespace mr_recon
{

/*

	'NFFT_preData', 'NFFT_H_preData', and 'NFFT_iteration_preData' are data structures generated by the NFFT/NFFT_H preprocessing steps.
	They contain the necessary data to execute the GPU based NFFT and NFFT_H algorithms.

	!!! IMPORTANT !!!
	Be sure to arrange entries in an order that is immunne to Cudas __builtin_align__(n) declarations.
	Pointers are ok to put anywhere(TODO:check this), but the UINTd objects we need to put first.

*/

	template< class UINTd, class FLOATd, char TYPE > class NFFT_plan
	{
	public:
		__host__ NFFT_plan( UINTd matrix_size, UINTd matrix_size_os, UINTd fixed_dims, unsigned int domain_size_samples, unsigned int domain_size_coils, float W );
		__host__ ~NFFT_plan();

		// CPU-based (offline) preprocessing
		__host__ bool preprocess( RealFloatArray *trajectory );

		// Radial GPU preprocessing
		__host__ bool preprocess_radial( unsigned int num_projections, unsigned int samples_per_projection, unsigned int projections_per_frame, unsigned int angular_offset, unsigned int frames_per_rotation, float gc_factor );

		// Generic GPU-based preprocessing
		__host__ bool preprocess_generic( unsigned int num_samples, FLOATd *traj );

		// Setup Cuda for NFFT_H
		__host__ bool initialize();

		// NFFT convolve
		__host__ bool convolve( cuFloatComplex *samplesDevPtr, cuFloatComplex *result );

		// Compute entire NFFT
		__host__ bool compute( cuFloatComplex *samplesDevPtr, cuFloatComplex *imageDevPtr, bool oversampled_image, bool densityCompensate );		

		// Cleanup Cuda memory
		__host__ bool cleanup();

		uint2 *stripsMapDevPtr_NFFT;	// For each thread provide a texCoord (.x) to access the strip texture + number of strips (.y)
		uint2 *stripsMap_NFFT;		// For each thread provide a texCoord (.x) to access the strip texture + number of strips (.y)

		UINTd matrix_size; 				// Matrix size
		UINTd matrix_size_os;			// Oversampled matrix size

		UINTd fixed_dims;				// "Boolean" denoting whether dimension is fixes (i.e. no gridding is neccessary).

		UINTd *stripsDir_NFFT;			// For each thread provide a unit d-dimensional direction vector for the strip encoding
		UINTd *stripOrigins_NFFT;		// Array of strip start points (d-dimensional grid positions)

		FLOATd *sample_positions;		// Array of sample positions.

		UINTd *stripsDirDevPtr_NFFT;	// For each thread provide a unit d-dimensional direction vector for the strip encoding
		UINTd *stripOriginsDevPtr_NFFT;	// Array of strip start points (d-dimensional grid positions)

		unsigned int *stripLengthsDevPtr_NFFT;	// Array of strip lengths		

		unsigned int domain_size_samples;	// Domain length for each coil
		unsigned int domain_count_samples;	// Number of domains
		unsigned int domain_size_coils;		// Number of coils to process in parallel
		unsigned int number_of_coils;

		unsigned int d;				// Dimensionality
		float alpha;				// Oversampling factor
		float W;				// Kernel width (Jackson, i.e. on non-oversampled matrix)

		unsigned int number_of_strips_NFFT;	// Number of strips
		unsigned int number_of_samples;		// Number of samples

		unsigned int *stripLengths_NFFT;	// Array of strip lengths		

		void *sample_positions_DevPtr;		// !!! Temporary workaround !!!

		// Radial trajectories only
		unsigned int samples_per_projection;
		unsigned int projections_per_frame;
		unsigned int angular_offset;
		unsigned int frames_per_rotation;
		float interframe_rotation; 
		float gc_factor;
		float total_projections_f;

		unsigned int max_strips_per_domain_NFFT;

		bool successfully_preprocessed;
		bool initialized;

		cuFloatComplex *deapodization_filter_NFFT;
		cuFloatComplex *deapodization_filter_NFFT_H;
		cuFloatComplex *deapodization_filter_NFFT_it;

	};


	template< class UINTd, class FLOATd, char TYPE > class NFFT_H_plan
	{
	public:

		__host__ NFFT_H_plan( UINTd matrix_size, UINTd matrix_size_os, UINTd fixed_dims, UINTd domain_size_grid, unsigned int domain_size_coils, float W );
		__host__ ~NFFT_H_plan();

		// CPU-based (offline) preprocessing
		__host__ bool preprocess( RealFloatArray *trajectory );

		// Generic GPU-based preprocessing
		__host__ bool preprocess_generic( unsigned int num_samples, FLOATd *traj );

		// Radial GPU-based preprocessing
		__host__ bool preprocess_radial( unsigned int num_projections, unsigned int samples_per_projection, unsigned int projections_per_frame, unsigned int angular_offset, unsigned int frames_per_rotation, float gc_factor );
		__host__ void preprocess_radial_allocate( unsigned int *num_strips, unsigned int *stripOffsets);

		// Setup Cuda for NFFT_H
		__host__ bool initialize();						

		// NFFT convolve (!!! available from .cu files only !!!)
		__host__ bool convolve( cuFloatComplex *samplesDevPtr, cuFloatComplex *result );

		// Compute NFFT
		__host__ bool compute( cuFloatComplex *samplesDevPtr, cuFloatComplex *imageDevPtr, bool oversampled_image, bool densityCompensate );		

		// Cleanup Cuda memory
		__host__ bool cleanup();

		UINTd matrix_size; 			// Matrix size
		UINTd matrix_size_os;		// Oversampled matrix size
		UINTd matrix_size_wrap;		// Wrap size at border

		UINTd domain_size_grid;		// Domain size in each dimension
		UINTd domain_count_grid;	// Domain count in each dimension

		UINTd fixed_dims;			// "Boolean" denoting whether dimension is fixes (i.e. no gridding is neccessary).

		FLOATd *sample_positions;	// Array of sample positions.

		uint2 *stripsMap_NFFT_H;	// For each thread provide a texCoord (.x) to access the strip texture + number of strips (.y)
		uint2 *strips_NFFT_H;		// Array of sample strips

		uint2 *stripsMapDevPtr_NFFT_H;	// For each thread provide a texCoord (.x) to access the strip texture + number of strips (.y)
		uint2 *stripsDevPtr_NFFT_H;		// Array of sample strips

		uint2 *domainsMapDevPtr_NFFT_H;	// For each thread provide a sorted (key, value) list to map threads to domains according to workload

		unsigned int d;				// Dimensionality
		float alpha;				// Oversampling factor
		float W;					// Kernel width (Jackson, i.e. on non-oversampled matrix)

		unsigned int domain_size_coils;		// Number of coils to process in parallel
		unsigned int number_of_coils;

		bool calculate_deapodization;		// Calculate deapodization filter during 'initialize()'
		bool do_deapodization;			// Perform deapodization during 'compute()'
		bool clean_deapodization;		// Clean deapodization filter during 'cleanup()'

		unsigned int *domainsMap_NFFT_H;	// For each thread provide a map to the desired domain (for grouping of domains with comparable number of strips)

//		unsigned int number_of_threads_NFFT_H;	// Number of threads
		unsigned int number_of_strips_NFFT_H;	// Number of strips
		unsigned int number_of_samples;		// Number of samples

		void *sample_positions_DevPtr;		// !!! Temporary workaround !!!
		float *weights_DevPtr;			// !!! Temporary workaround !!!

		// Radial trajectories only
		unsigned int samples_per_projection;
		unsigned int projections_per_frame;
		unsigned int angular_offset;
		unsigned int frames_per_rotation;
		float interframe_rotation;
		float gc_factor;
		float total_projections_f;

		bool successfully_preprocessed;
		bool initialized;
		
		cuFloatComplex *deapodization_filter_NFFT;		
		cuFloatComplex *deapodization_filter_NFFT_H;
		cuFloatComplex *deapodization_filter_NFFT_it;

		// Genetic-path vectors -->
		thrust::device_vector<FLOATd> *traj_positions;
		thrust::device_vector<unsigned int> *tuples_last;
		thrust::device_vector<unsigned int> *bucket_begin, *bucket_end;
		// <--

		int dummy[32];				// Force sizeof(this) != sizeof("other plans")
	};


	template< class UINTd, class FLOATd, char TYPE > class NFFT_iteration_plan
	{
	public:
		__host__ NFFT_iteration_plan( UINTd matrix_size, UINTd matrix_size_os, UINTd fixed_dims, UINTd domain_size_grid, unsigned int domain_size_samples, unsigned int domain_size_coils, float W );
		__host__ ~NFFT_iteration_plan();

		// CPU-based (offline) preprocessing
		__host__ bool preprocess( RealFloatArray *trajectory );

		// Generic GPU-based preprocessing
		__host__ bool preprocess_generic( unsigned int num_samples, FLOATd *traj );

		// Radial GPU-based preprocessing
		__host__ bool preprocess_radial( unsigned int num_projections, unsigned int samples_per_projection, unsigned int projections_per_frame, unsigned int angular_offset, unsigned int frames_per_rotation, float gc_factor );

		// Setup Cuda for NFFT_H
		__host__ bool initialize();						

		// NFFT convolve
		__host__ bool convolve( cuFloatComplex *samplesDevPtr, cuFloatComplex *result );

		// Compute NFFT
		__host__ bool compute( cuFloatComplex *samplesDevPtr, cuFloatComplex *imageDevPtr, bool oversampled_image, bool densityCompensate );		

		// Cleanup Cuda memory
		__host__ bool cleanup();

		UINTd matrix_size; 			// Matrix size
		UINTd matrix_size_os;		// Oversampled matrix size
		UINTd matrix_size_wrap;		// Wrap size at border

		UINTd domain_size_grid;		// Domain size in each dimension
		UINTd domain_count_grid;	// Domain count in each dimension

		UINTd fixed_dims;			// "Boolean" denoting whether dimension is fixes (i.e. no gridding is neccessary).

		UINTd *stripsDir_NFFT;		// For each thread provide a unit d-dimensional direction vector for the strip encoding
		UINTd *stripOrigins_NFFT;	// Array of strip start points (d-dimensional grid positions)

		UINTd *stripsDirDevPtr_NFFT;		// For each thread provide a unit d-dimensional direction vector for the strip encoding
		UINTd *stripOriginsDevPtr_NFFT;		// Array of strip start points (d-dimensional grid positions)

		FLOATd *sample_positions;	// Array of sample positions.

		uint2 *stripsMap_NFFT;	// For each thread provide a texCoord (.x) to access the strip texture + number of strips (.y)

		uint2 *stripsMap_NFFT_H;	// For each thread provide a texCoord (.x) to access the strip texture + number of strips (.y)
		uint2 *strips_NFFT_H;		// Array of sample strips

		uint2 *stripsMapDevPtr_NFFT;		// For each thread provide a texCoord (.x) to access the strip texture + number of strips (.y)

		uint2 *stripsMapDevPtr_NFFT_H;	// For each thread provide a texCoord (.x) to access the strip texture + number of strips (.y)
		uint2 *stripsDevPtr_NFFT_H;		// Array of sample strips

		uint2 *domainsMapDevPtr_NFFT_H;	// For each thread provide a sorted (key, value) list to map threads to domains according to workload
		unsigned int *stripLengthsDevPtr_NFFT;	// Array of strip lengths		

		unsigned int domain_size_samples;		// Domain length for each coil
		unsigned int domain_count_samples;
		unsigned int domain_size_coils;			// Number of coils to process in parallel
		unsigned int number_of_coils;			// Careful, influences density compensation also

		unsigned int d;				// Dimensionality
		float alpha;				// Oversampling factor
		float W;					// Kernel width (Jackson, i.e. on non-oversampled matrix)

		unsigned int number_of_samples;			// Number of samples
		unsigned int number_of_strips_NFFT;		// Number of strips
//		unsigned int number_of_threads_NFFT_H;	// Number of threads
		unsigned int number_of_strips_NFFT_H;	// Number of strips

		unsigned int *domainsMap_NFFT_H;	// For each thread provide a map to the desired domain (for grouping of domains with comparable number of strips)
		unsigned int *stripLengths_NFFT;	// Array of strip lengths			

		void *sample_positions_DevPtr;		// !!! Temporary workaround !!!
		float *weights_DevPtr;				// !!! Temporary workaround !!!

		// Radial trajectories only
		unsigned int samples_per_projection;
		unsigned int projections_per_frame;
		unsigned int angular_offset;
		unsigned int frames_per_rotation;
		float interframe_rotation;
		float gc_factor;
		float total_projections_f;
		unsigned int max_strips_per_domain_NFFT;

		float *regularizationDevPtr;
		cuFloatComplex *CSMdevPtr;
		float *intensity_correction_magnitudes_image_DevPtr;

		bool successfully_preprocessed;
		bool initialized;

		cuFloatComplex *deapodization_filter_NFFT;
		cuFloatComplex *deapodization_filter_NFFT_H;
		cuFloatComplex *deapodization_filter_NFFT_it;

		// Genetic-path vectors -->
		thrust::device_vector<FLOATd> *traj_positions;
		thrust::device_vector<unsigned int> *tuples_last;
		thrust::device_vector<unsigned int> *bucket_begin, *bucket_end;
		// <--
	};
};


/*
	Preprocessing steps for the deapodization implementation
*/

#include <vector_types.h>

extern "C" mr_recon::NFFT_H_plan< uint2, float2, 0>* preprocess_deapodization_2D( uint2, uint2, float, uint2 );
extern "C" mr_recon::NFFT_H_plan< uint3, float3, 0>* preprocess_deapodization_3D( uint3, uint3, float, uint3 );
extern "C" mr_recon::NFFT_H_plan< uint4, float4, 0>* preprocess_deapodization_4D( uint4, uint4, float, uint4 );

extern "C" void preprocess_deapodization_2D_cleanup( mr_recon::NFFT_H_plan< uint2, float2, 0>* );
extern "C" void preprocess_deapodization_3D_cleanup( mr_recon::NFFT_H_plan< uint3, float3, 0>* );
extern "C" void preprocess_deapodization_4D_cleanup( mr_recon::NFFT_H_plan< uint4, float4, 0>* );

#endif
