<?xml version="1.0" encoding="UTF-8"?>
<book version="5.0" xmlns="http://docbook.org/ns/docbook"
      xmlns:xlink="http://www.w3.org/1999/xlink"
      xmlns:xi="http://www.w3.org/2001/XInclude"
      xmlns:ns5="http://www.w3.org/2000/svg"
      xmlns:ns4="http://www.w3.org/1998/Math/MathML"
      xmlns:ns3="http://www.w3.org/1999/xhtml"
      xmlns:ns="http://docbook.org/ns/docbook">
  <info>
    <title>Gadgetron Users Guide</title>

    <author>
      <personname><honorific>Dr</honorific> <firstname>Michael
      Schacht</firstname> <surname>Hansen</surname></personname>

      <email>michael.hansen@nih.gov</email>
    </author>

    <author>
      <personname><honorific>Dr</honorific> <firstname>Thomas
      Sangild</firstname> <surname>SÃ¸rensen</surname></personname>

      <email>sangild@cs.au.dk</email>
    </author>

    <subtitle>A Medical Image Reconstruction Framework</subtitle>
  </info>

  <chapter>
    <title>Introduction</title>

    <sect1>
      <title>What is Gadgetron</title>

      <para>The Gadgetron is a streaming data processing framework for medical
      image reconstruction. It has been developed to make it easier to
      prototype, test, and deploy new image reconstruction algorithms.</para>

      <para>The framework features a number of reconstruction applications
      that can be employed directly. Moreover, it contains a wide range of
      toolboxes with common data structures and algorithms designed for a much
      broader use. These toolboxes can be used within the streaming framework
      to create new dedicated reconstruction components or used as shared
      libraries in standalone (or third party) applications.</para>

      <para>This document serves as an introduction to the Gadgetron framework
      and provides some "getting started" examples of using it. A scientific
      paper is also available <xref linkend="hansen12"/>.</para>

      <para>Although the Gadgetron is a generic, multi-modality image
      reconstruction framework, it was initially developed to support the work
      of the authors in the field of advanced MRI reconstruction. Specifically
      to support work on fast image reconstruction, not only on traditional
      CPU architectures, but also using commodity graphics hardware (GPUs).
      Some examples that are made publicly available through the Gadgetron
      framework include fast (re)gridding on the GPU <citation><xref
      linkend="sorensen08"/></citation>, Cartesian parallel imaging on the GPU
      <citation><xref linkend="hansen08"/></citation>, and non-Cartesian
      parallel imaging on the GPU <citation><xref
      linkend="sorensen09"/></citation>.</para>
    </sect1>

    <sect1>
      <title>Obtaining Gadgetron</title>

      <para>The Gadgetron is made available as a cross-platform source code
      distribution, which compiles and has been tested to run on Linux, Mac OS
      X, and Windows 7. Compilation instructions for these platforms are
      provided below.</para>

      <para>Generally speaking, the Gadgetron is easiest set up on Linux since
      all dependencies are readily available. If you want to get started
      quickly with the Gadgetron and happen to not be using Linux, it is easy
      to install Ubuntu (our preferred Linux distribution) in a virtual
      machine (e.g. VirtualBox, <uri type="website"
      xlink:href="https://www.virtualbox.org/">https://www.virtualbox.org/</uri>)
      and follow the Linux compilation instructions below.</para>

      <para>The Gadgetron is available from the project Sourceforge
      website:</para>

      <para><uri type="website"
      xlink:href="http://sourceforge.net/projects/gadgetron">http://sourceforge.net/projects/gadgetron</uri></para>

      <para>This manual is available in HTML form at:</para>

      <para><uri type="website"
      xlink:href="http://gadgetron.sourceforge.net/latest/manual/gadgetron_manual.html">http://gadgetron.sourceforge.net/latest/manual/gadgetron_manual.html</uri></para>

      <para>Or in PDF form at:</para>

      <para><uri type="website"
      xlink:href="http://gadgetron.sourceforge.net/latest/manual/gadgetron_manual.pdf">http://gadgetron.sourceforge.net/latest/manual/gadgetron_manual.pdf</uri></para>

      <para>API documentation (generated with Doxygen) is available
      from:</para>

      <para><uri type="website"
      xlink:href="http://gadgetron.sourceforge.net/latest/api/">http://gadgetron.sourceforge.net/latest/api/</uri></para>

      <sect2 xml:id="sect.dependencies">
        <title>Dependencies</title>

        <para>The Gadgetron depends on a number of libraries that can either
        be downloaded for free or that may already be part of the installation
        on your workstation. If you are working on a Linux platform you should
        be able to install all dependencies without compiling anything. The
        following is a list of the components that you will need. Some are
        optional.</para>

        <para>To install these components please follow the platform specific
        installation instructions provided below (<xref
        linkend="sect.installation"/>).</para>

        <itemizedlist>
          <listitem>
            <para><emphasis>CMake</emphasis>. The Gadgetron uses
            <application>cmake</application> for cross platform building.
            Available from <uri type="website"
            xlink:href="http://www.cmake.org/cmake/resources/software.html">http://www.cmake.org/cmake/resources/software.html</uri>.</para>
          </listitem>

          <listitem>
            <para><emphasis>ADAPTIVE Computing Environment (ACE)</emphasis>.
            Available from <uri type="website"
            xlink:href="http://www.cs.wustl.edu/~schmidt/ACE.html">http://www.cs.wustl.edu/~schmidt/ACE.html</uri>.</para>
          </listitem>

          <listitem>
            <para><emphasis>Boost C++ Libraries</emphasis>. Available from
            <uri type="website"
            xlink:href="http://www.boost.org/">http://www.boost.org/</uri>.</para>
          </listitem>

          <listitem>
            <para><emphasis>FFT3W Library</emphasis> for Fast Fourier
            Transforms. Available from <uri type="website"
            xlink:href="http://www.fftw.org/">http://www.fftw.org/</uri>.</para>
          </listitem>

          <listitem>
            <para><emphasis>BLAS</emphasis> and <emphasis>LAPACK</emphasis>
            (optional). Most Linux distributions come with these libraries and
            they are included on Mac OS X as well, but the vendor depends on
            your distribution and platform. See specific instructions below
            for Windows.</para>
          </listitem>

          <listitem>
            <para><emphasis>HDF5</emphasis> (optional). Some of the the
            Gadgetron clients use the HDF5 file format for storing raw data
            and images. The libraries are available with most Linux
            distributions, and can be downloaded for Windows and Mac OS X from
            <uri
            xlink:href="http://www.hdfgroup.org/HDF5/">http://www.hdfgroup.org/HDF5/</uri>.</para>
          </listitem>

          <listitem>
            <para><emphasis>CUDA</emphasis> (optional). For GPU support, you
            need CUDA from Nvidia, which can de downloaded from <uri
            type="website"
            xlink:href="http://developer.nvidia.com/cuda-toolkit-40">http://developer.nvidia.com/cuda-downloads</uri>.
            You will need a CUDA driver for your graphics card too, which is
            available from the same website.</para>
          </listitem>

          <listitem>
            <para><emphasis>CULA</emphasis> (optional). We use CULA for LAPACK
            routines on the GPU. This is the only dependency which is not Open
            Source. You can however download a free version of CULA from <uri
            type="website"
            xlink:href="http://www.culatools.com/downloads/dense/">http://www.culatools.com/downloads/dense/</uri>.
            Registration is required.</para>
          </listitem>

          <listitem>
            <para><emphasis>QT4</emphasis> (optional). A few standalone and
            Gadgetron client example applications use QT for creating user
            interfaces. It comes packaged with most Linux distributions, but
            can otherwise be obtained from <uri type="website"
            xlink:href="http://qt.nokia.com/">http://qt.nokia.com/</uri> for
            all platforms.</para>
          </listitem>

          <listitem>
            <para><emphasis>Doxygen</emphasis> (optional). If you would like
            to build the API documentation you need Doxygen. It is available
            from <uri type="website"
            xlink:href="http://www.stack.nl/~dimitri/doxygen/">http://www.stack.nl/~dimitri/doxygen/</uri>.</para>
          </listitem>

          <listitem>
            <para><emphasis>Docbook</emphasis> (optional). If you would like
            to build the manual (this document) you need Docbook. A number of
            tools are needed such as <application>xsltproc</application> and
            <application>fop</application> (for the PDF version of the
            library). Additionally you need the Docbook stylesheets, available
            at <uri type="website"
            xlink:href="http://docbook.sourceforge.net/">http://docbook.sourceforge.net/</uri>.</para>
          </listitem>

          <listitem>
            <para><emphasis>Git (optional)</emphasis>. We use
            <application>git</application> to manage our source code archives.
            You can use any source code management system you prefer (or none
            at all), but if you would like to stay in line with the Gadgetron
            team, use <application>git</application>. Available from <uri
            type="website"
            xlink:href="http://git-scm.com/">http://git-scm.com/</uri>.</para>
          </listitem>
        </itemizedlist>
      </sect2>
    </sect1>

    <sect1 xml:id="sect.installation">
      <title>Compiling and Installing Gadgetron</title>

      <sect2 xml:id="sect.linuxinstall">
        <title>Linux Installation Instructions</title>

        <para>Linux is the preferred operating system to get started using the
        Gadgetron. All of the required dependencies are included in most major
        Linux distributions and can be installed easily and without having to
        compile anything. In the following sections we walk you through the
        required steps to set up a full Gadgetron installation. We assume that
        you are starting with a freshly installed Ubuntu 12.04 available from
        the Ubuntu website (<uri
        xlink:href="http://www.ubuntu.com">http://www.ubuntu.com</uri>). If
        you don't have a machine available for installing Ubuntu, you can
        always try it out in a virtual machine using virtualization software
        such as VirtualBox (<uri type="website"
        xlink:href="https://www.virtualbox.org/">https://www.virtualbox.org/</uri>).</para>

        <para>If you would like to use the GPU components included in the
        Gadgetron and you have an Nvidia GPU available on your system, please
        complete the CUDA/CULA installations as described in <xref
        linkend="section.linuxgpuinstall"/>.</para>

        <para>First install all dependencies for Gadgetron. The following will
        install everything you need:</para>

        <screen><prompt>user@mycomputer:~$</prompt> <userinput>sudo apt-get install doxygen cmake \
 libqt4-dev libglew1.6-dev \
 docbook5-xml docbook-xsl-doc-pdf \
 docbook-xsl-doc-html docbook-xsl-ns xsltproc \
 fop git-core libboost-dev libboost-python-dev \
 libfftw3-dev libace-dev python-dev python-numpy \
 freeglut3-dev libxi-dev liblapack-dev build-essential \
 libhdf5-serial-dev h5utils hdf5-tools hdfview </userinput>   </screen>

        <para>Now download the Gadgetron archive and unpack it somewhere. If
        you have access to a git repository, you can get the code with:</para>

        <screen><prompt>user@mycomputer:~$</prompt> <userinput>git clone ssh://user@hostname/path/gadgetron.git</userinput></screen>

        <para>Configure and build the Gadgetron:</para>

        <screen><prompt>user@mycomputer:~$</prompt> <userinput>cd gadgetron</userinput>
<prompt>user@mycomputer:~/gadgetron$</prompt> <userinput>mkdir build</userinput>
<prompt>user@mycomputer:~/gadgetron$</prompt> <userinput>cd build</userinput>
<prompt>user@mycomputer:~/gadgetron/build$</prompt> <userinput>cmake ../
</userinput><prompt>user@mycomputer:~/gadgetron/build$</prompt> <userinput>make</userinput>  </screen>

        <para>Install (default location is
        <filename>/usr/local/gadgetron</filename>):</para>

        <screen><prompt>user@mycomputer:~/gadgetron/build$</prompt> <userinput>sudo make install</userinput> </screen>

        <para>The final step is to add/modify a few environment variables in
        your <filename>~/.bashrc</filename> file.</para>

        <programlisting>export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/gadgetron/lib
export PATH=$PATH:/usr/local/gadgetron/bin
export GADGETRON_HOME=/usr/local/gadgetron     </programlisting>

        <para>You are now set up to run a simple example reconstruction as
        outlined in <xref linkend="sect.simpleexample"/>.</para>

        <sect3 xml:id="section.linuxgpuinstall">
          <title>Installing GPU components (CUDA and CULA) on Linux</title>

          <para>First install the Nvidia driver. The Ubuntu distribution comes
          with a driver that will work with CUDA in some instances, but we
          recommend that you install the latest developer driver from the
          Nvidia website.</para>

          <para>Download (to the current directory)
          <filename>devdriver_4.1_linux_64_285.05.32.run</filename> from <uri
          xlink:href="http://developer.nvidia.com/cuda-toolkit-41">http://developer.nvidia.com/cuda-toolkit-41</uri>
          and install the driver:</para>

          <para><screen><prompt>user@mycomputer:~$</prompt><userinput> sudo sh ./devdriver_4.1_linux_64_285.05.32.run</userinput></screen></para>

          <para>The process of getting this driver installed may vary from
          installation to installation. Specifically, you may need to remove
          any existing Nvidia driver before installing and you will have to
          shut down the display manager before installing.</para>

          <para>The display manager can be shut down with:</para>

          <para><screen><prompt>user@mycomputer:~$</prompt> <userinput>sudo service lightdm stop</userinput>
</screen></para>

          <para>We need to install gcc 4.4 since Ubuntu comes preconfigured
          with gcc 4.6, which is not compatible with the current versions of
          the CUDA nvcc compiler.</para>

          <screen><prompt>user@mycomputer:~$</prompt> <userinput>sudo apt-get install \
  gcc-4.4 g++-4.4 build-essential</userinput>   </screen>

          <para>Set up alternative systems to allow easy switching between the
          two versions of gcc/g++</para>

          <screen><prompt>user@mycomputer:~$</prompt> <userinput>sudo update-alternatives \
 --install /usr/bin/gcc gcc /usr/bin/gcc-4.6 40 \
 --slave /usr/bin/g++ g++ /usr/bin/g++-4.6</userinput>

<prompt>user@mycomputer:~$</prompt> <userinput>sudo update-alternatives \
 --install /usr/bin/gcc gcc /usr/bin/gcc-4.4 60 \
 --slave /usr/bin/g++ g++ /usr/bin/g++-4.4</userinput>    </screen>

          <para>Check your gcc compiler (should now be version 4.4.7):</para>

          <screen><prompt>user@mycomputer:~$</prompt> <userinput>gcc -v</userinput>      </screen>

          <para>When you want to switch between the two compiler
          versions:</para>

          <screen><prompt>user@mycomputer:~$</prompt> <userinput>sudo update-alternatives --config gcc</userinput>      </screen>

          <para>The final step is to actually install CUDA and CULA. Download
          the following files:</para>

          <itemizedlist>
            <listitem>
              <para><filename>cudatoolkit_4.1.28_linux_64_ubuntu11.04.run</filename>
              from <uri type="website"
              xlink:href="http://developer.nvidia.com/cuda-toolkit-41">http://developer.nvidia.com/cuda-toolkit-41</uri></para>
            </listitem>

            <listitem>
              <para>cula_dense_free_R14-linux64.run from <uri type="website"
              xlink:href="http://www.culatools.com/downloads/dense/">http://www.culatools.com/downloads/dense/</uri>
              (free registration requited)</para>
            </listitem>
          </itemizedlist>

          <para>Go to the folder where the files were downloaded and
          type:</para>

          <screen><prompt>user@mycomputer:~$</prompt> <userinput>sudo sh ./cudatoolkit_4.1.28_linux_64_ubuntu11.04.run
</userinput><prompt>user@mycomputer:~$</prompt> <userinput>sudo sh ./cula_dense_free_R14-linux64.run
</userinput></screen>

          <para>Follow the instructions. When you are done with the
          installation you may want to add the following to your
          <filename>~/.bashrc</filename> file.</para>

          <programlisting>export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda/lib64
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda/lib
export CULA_ROOT="/usr/local/cula"
export CULA_INC_PATH="$CULA_ROOT/include"
export CULA_BIN_PATH_32="$CULA_ROOT/bin"
export CULA_BIN_PATH_64="$CULA_ROOT/bin64"
export CULA_LIB_PATH_32="$CULA_ROOT/lib"
export CULA_LIB_PATH_64="$CULA_ROOT/lib64"
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$CULA_LIB_PATH_64    </programlisting>

          <para>You are now ready to compile and run CUDA (and CULA)
          applications. You may want to download the CUDA SDK from Nvidia to
          validate your installation but this is not required.</para>
        </sect3>
      </sect2>

      <sect2>
        <title>Mac OS X Installation Instructions</title>

        <para>The following instructions assume that you are starting on a Mac
        with OS X 10.6.8 (Snow Leopard) Installed. Additionally it assumes
        that you have Xcode (3.2.6) installed. If you have upgraded to Lion or
        are on an older release, you should still be able to make it all
        compile, but you may have to make some adjustments.</para>

        <para>We use MacPorts (<uri
        xlink:href="http://www.macports.org/">http://www.macports.org/</uri>)
        to install the required dependencies. You may use a different package
        management system or prefer to install packages manually. In that
        case, please look at the list of dependencies (<xref
        linkend="sect.dependencies"/>) and install the required dependencies
        for the components you would like to use.</para>

        <para>MacPorts is not the fastest way to install packages as they are
        compiled locally. We use this method here nonetheless to make it
        easier to follow the instructions. Please be patient when running the
        <command>port</command> commands.</para>

        <itemizedlist>
          <listitem>
            <para>Install MacPorts.</para>

            <para>Download <filename>MacPorts-2.0.4.pkg</filename> from <uri
            xlink:href="http://www.macports.org/">http://www.macports.org/</uri>.</para>

            <para>Run <command>sudo port -v selfupdate</command> to make sure
            you up to date.</para>
          </listitem>

          <listitem>
            <para>Get your Python installation up to date. Mac OS X ships with
            Python installed, but it is not a complete distribution. You need
            to update it if you would like to do Python development with the
            Gadgetron. If you already have <package>numpy</package> and
            <package>SciPy</package> installed, you may be able to skip this
            step. If you do not wish to use Python, you can also skip this
            step.</para>

            <screen>$ <userinput>sudo port install python27 py27-numpy py27-scipy</userinput></screen>

            <para>This should install Python 2.7. Now select Python 2.7 as as
            the active Python installation:</para>

            <screen>$ <userinput>sudo port select python python27</userinput></screen>

            <para>To make sure the build system finds the right version of
            Python we need to edit a couple of symbolic links manually:</para>

            <screen>$ <userinput>cd /System/Library/Frameworks/Python.framework/Versions</userinput>
$ <userinput>sudo ln -s /opt/local/Library/Frameworks/Python.framework/Versions/2.7</userinput>
$ <userinput>sudo rm Current</userinput>
$ <userinput>sudo ln -s 2.7 Current</userinput></screen>
          </listitem>

          <listitem>
            <para>Install Boost. Boost gets special treatment here. Depending
            on whether you would like to do Python development, you need to
            install Boost with or without boost_python. If you would like
            Python:</para>

            <screen>$ <userinput>sudo port install boost +python27</userinput></screen>

            <para>If you don't need Python support:</para>

            <screen>$ <userinput>sudo port install boost</userinput></screen>
          </listitem>

          <listitem>
            <para>Now we can install the rest of the packages:</para>

            <screen>$ <userinput>sudo port install git-core cmake libACE \
fftw-3-single fftw-3 qt4-mac-devel hdf5-18
</userinput></screen>

            <para>This may take quite a long time (hours).</para>
          </listitem>

          <listitem>
            <para
            xlink:href="http://www.hdfgroup.org/ftp/HDF5/hdf-java/hdfview/hdfview_install_macosx_intel64.zip">To
            visualize HDF5 files you may also want to install HDFView from
            http://www.hdfgroup.org/ftp/HDF5/hdf-java/hdfview/hdfview_install_macosx_intel64.zip</para>
          </listitem>

          <listitem>
            <para>Install CUDA and CULA. If you would like to use the GPU
            components, you need to install the following:</para>

            <itemizedlist>
              <listitem>
                <para>The Nvidia development driver
                (<filename>devdriver_4.1.28_macos.dmg</filename>) from <uri
                xlink:href="http://developer.nvidia.com/cuda-toolkit-40/">http://developer.nvidia.com/cuda-toolkit-41/</uri>.</para>
              </listitem>

              <listitem>
                <para>The CUDA Toolkit
                (<filename>cudatoolkit_4.1.28_macos.pkg</filename>) from <uri
                xlink:href="http://developer.nvidia.com/cuda-toolkit-40/">http://developer.nvidia.com/cuda-toolkit-41/</uri>.</para>
              </listitem>

              <listitem>
                <para>The CULA Dense Libraries
                (<filename>cula_dense_free_R14-osx.dmg</filename>) from <uri
                xlink:href="http://www.culatools.com/downloads/dense/">http://www.culatools.com/downloads/dense/</uri>.</para>
              </listitem>
            </itemizedlist>
          </listitem>

          <listitem>
            <para>Compiling the Gadgetron:</para>

            <screen><prompt>$</prompt> <userinput>cd gadgetron</userinput>
$ <userinput>mkdir build</userinput>
$ <userinput>cd build</userinput>
$ <userinput>cmake -DPYTHON_NUMPY_INCLUDE_DIR= \
  /opt/local/Library/Frameworks/Python.framework \
  /Versions/2.7/lib/python2.7/site-packages/numpy/core/include ../</userinput>
$ <userinput>make</userinput>
$ <userinput>sudo make install</userinput></screen>

            <para>The long path for the <package>numpy</package> header files
            is only needed if you want Python support. You can avoid this by
            creating a symbolic link:</para>

            <screen>$ <userinput>cd /opt/local/Library/Frameworks/Python.framework</userinput>
$ <userinput>cd Versions/2.7/include/python2.7</userinput>
$ <userinput>sudo ln -s ../../lib/python2.7/site-packages/numpy/core/include/numpy</userinput></screen>

            <para>After creating this link you should be able to compile with
            the following:</para>

            <screen><prompt>$</prompt> <userinput>cd gadgetron</userinput>
$ <userinput>mkdir build</userinput>
$ <userinput>cd build</userinput>
$ <userinput>cmake ../</userinput>
$ <userinput>make</userinput>
$ <userinput>sudo make install</userinput></screen>
          </listitem>

          <listitem>
            <para>Set environment variables:</para>

            <screen>$ <userinput>export GADGETRON_HOME=/usr/local/gadgetron</userinput>
$ <userinput>export PATH=$PATH:/usr/local/gadgetron/bin</userinput>
$ <userinput>export DYLD_LIBRARY_PATH=$DYLD_LIBRARY_PATH:/usr/local/gadgetron/lib</userinput></screen>

            <para>You may wish to add these lines to
            <filename>~/.bash_profile</filename>, You may also want to add
            paths to CUDA and CULA libraries if you are using those:</para>

            <screen>$ <userinput>export DYLD_LIBRARY_PATH=$DYLD_LIBRARY_PATH:/usr/local/cula/lib64</userinput>
$ <userinput>export DYLD_LIBRARY_PATH=$DYLD_LIBRARY_PATH:/usr/local/cuda/lib</userinput></screen>
          </listitem>

          <listitem>
            <para>Test your Gadgetron by following the instructions in <xref
            linkend="sect.simpleexample"/>.</para>
          </listitem>
        </itemizedlist>
      </sect2>

      <sect2>
        <title>Windows Installation Instructions</title>

        <para>It is probably appropriate to start this section with a warning:
        Windows is not the easiest environment in which to work with the
        Gadgetron. As indicated in <xref linkend="sect.dependencies"/>, the
        Gadgetron relies on multiple external libraries. Many of those
        libraries are not available as easy install packages and must be
        compiled separately. If you are uncomfortable setting up development
        tools on Windows, or if you are just looking for a fast and easy way
        to get started with the Gadgetron, we recommend installing on Ubuntu
        Linux - possibly using a virtual machine inside Windows (see <xref
        linkend="sect.linuxinstall"/>).</para>

        <para>The following is a list of steps we have used to install the
        Gadgetron on a clean Windows 7 (64-bit) machine:</para>

        <itemizedlist>
          <listitem>
            <para>Install Visual Studio 2010 (with Service Pack 1)</para>
          </listitem>

          <listitem>
            <para>Install CUDA/CULA (optional, but required for GPU support).
            Download from <uri
            xlink:href="http://developer.nvidia.com/cuda-toolkit-40">http://developer.nvidia.com/cuda-toolkit-41</uri>):</para>

            <para>Install Nvidia Developer Driver (Version 286.19)</para>

            <para>Install Nvdia Toolkit (4.1)</para>

            <para>Install gpucomputingsdk (Install as Asministrator)</para>

            <para>Install <filename>cula_dense_free_R14-win64.exe</filename>
            (as Administrator). Download from
            <uri>http://www.culatools.com/downloads/dense/</uri>. Assuming
            CULA was installed in <filename>C:\Program
            Files\CULA\R14</filename>, add <filename>C:\Program
            Files\CULA\R14\bin64</filename> to your <varname>PATH</varname>
            environment variable.</para>
          </listitem>

          <listitem>
            <para>Create a folder for external libraries, say
            <filename>C:\Libraries</filename>.</para>
          </listitem>

          <listitem>
            <para>Install FFTW3 (<uri
            xlink:href="http://www.fftw.org/install/windows.html">http://www.fftw.org/install/windows.html</uri>)</para>

            <para>Copy FFTW3 binaries to
            <filename>C:\Libraries\FFTW3</filename></para>

            <para>Create *.lib files, on the command line type:</para>

            <programlisting>c:\Libraries\FFTW3&gt;lib /machine:x64 /def:libfftw3f-3.def
c:\Libraries\FFTW3&gt;lib /machine:x64 /def:libfftw3-3.def
c:\Libraries\FFTW3&gt;lib /machine:x64 /def:libfftw3l-3.def
</programlisting>

            <para>Add <filename>C:\Libraries\FFTW3</filename> to path.</para>
          </listitem>

          <listitem>
            <para>Install ACE (<uri
            xlink:href="http://download.dre.vanderbilt.edu/">http://download.dre.vanderbilt.edu/</uri>)</para>

            <para>Unpack ACE into C:\Libraries\ACE-6.0.5\ACE_wrappers</para>

            <para>Add <filename>config.h</filename> in
            <filename>ACE_ROOT/ace/</filename> with the following
            content:</para>

            <programlisting>//We are on Windows
#include "ace/config-win32.h" 

//This ensured that INLINE settings 
//do not vary between Debug and Release modes
#define ACE_NO_INLINE </programlisting>

            <para>Open the VS 2010 project in the source code archive</para>

            <para>Set build type to Release/x64</para>

            <para>Build (this takes a while)</para>

            <para>Add to <varname>PATH</varname>:
            <filename>C:\Libraries\ACE-6.0.5\ACE_wrappers\lib</filename></para>
          </listitem>

          <listitem>
            <para>Install Python (optional). Regrettably, the off-the-shelf
            Python header files cannot be compiled in debug mode on Windows.
            This enforces the Gadgetron to be compiled in release mode.</para>

            <para>Install python-2.7.2.amd64 (<uri
            xlink:href="http://www.python.org">http://www.python.org</uri>)</para>

            <para>Add install folder (e.g. <filename>C:\Python27</filename>)
            to PATH environment variable</para>

            <para>Add <varname>PYTHON_ROOT</varname> environment
            variable</para>

            <para>From <uri
            xlink:href="http://www.lfd.uci.edu/~gohlke/pythonlibs/">http://www.lfd.uci.edu/~gohlke/pythonlibs/</uri>
            download and install the following:</para>

            <para><itemizedlist>
                <listitem>
                  <para><filename>numpy-MKL-1.6.1.win-amd64-py2.7</filename></para>
                </listitem>

                <listitem>
                  <para><filename>scipy-0.10.0.win-amd64-py2.7</filename></para>
                </listitem>

                <listitem>
                  <para><filename>matplotlib-1.1.0.win-amd64-py2.7</filename>
                  (not strictly necessary)</para>
                </listitem>

                <listitem>
                  <para><filename>ipython-0.11.win-amd64-py2.7</filename> (not
                  strictly necessary)</para>
                </listitem>
              </itemizedlist></para>
          </listitem>

          <listitem>
            <para>Install ACML (BLAS and LAPACK)</para>

            <para>Download <filename>acml4.4.0-win64.exe</filename> From: <uri
            xlink:href="http://developer.amd.com/libraries/acml/downloads/pages/">http://developer.amd.com/libraries/acml/downloads/pages/</uri></para>

            <para>Install Library in say
            C:\Libraries\C:\Libraries\acml4.4.0</para>

            <para>Add
            <filename>C:\Libraries\acml4.4.0\win64\lib;C:\Libraries\acml4.4.0\win64_mp\lib</filename>
            to <varname>PATH</varname></para>
          </listitem>

          <listitem>
            <para>Install Boost (<uri
            xlink:href="http://www.boost.org">http://www.boost.org</uri>)</para>

            <para>Unpack boost to
            <filename>C:\Libraries\boost_1_48_0</filename></para>

            <para>Open a command line as Administrator (type cmd and hit
            "shift+ctrl + enter")</para>

            <para>From <filename>C:\Libraries\boost_1_48_0</filename> type
            "<command>bootstrap</command>" (not bootstrap.bat)</para>

            <para>Type <command>.\b2 --with-python --build-type=complete
            address-model=64</command> (This only builds the boost_python
            library, add others as needed)</para>

            <para>Add <filename>C:\Libraries\boost_1_48_0\stage\lib</filename>
            to <varname>PATH</varname></para>
          </listitem>

          <listitem>
            <para>Install <application>git</application> (if you are using
            source code management):</para>

            <para>Run installation package Git-1.7.7.1-preview20111027 (As
            Administrator), download from <uri
            xlink:href="http://code.google.com/p/msysgit/">http://code.google.com/p/msysgit/</uri></para>

            <para>Use run in git bash only option</para>

            <para>Use checkout Windows LF and commit Unix Line feeds</para>
          </listitem>

          <listitem>
            <para>Install CMake (<uri
            xlink:href="http://www.cmake.org/cmake/resources/software.html">http://www.cmake.org/cmake/resources/software.html</uri>)</para>

            <para>Run cmake-2.8.6-win32-x86 (As Administrator)</para>
          </listitem>

          <listitem>
            <para>Download and unpack Gadgetron source code.</para>
          </listitem>

          <listitem>
            <para>Create Visual Studio project (your process may vary):</para>

            <para>Start <application>cmake-gui</application></para>

            <para>Select source and target directories</para>

            <para>Hit configure (first time)</para>

            <para>Add variable BOOST_ROOT to point to BOOST folder</para>

            <para>Hit configure (again)</para>

            <para>Specify location of FFTW and FFTWf libraries</para>

            <para>Hit configure (again)</para>

            <para>Specify location of CULA (include and library)</para>

            <para>Specify location of ACE include dir</para>

            <para>Hit configure (again)</para>

            <para>Specify <varname>PYTHON_NUMPY_INCLUDE_DIR</varname> =
            <filename>C:/Python27/Lib/site-packages/numpy/core/include</filename></para>

            <para>Hit configure (again)</para>

            <para>Specify the following environment variables:</para>

            <programlisting>BLAS_CALBLAS= \
  C:/Libraries/acml4.4.0/win64/lib/libacml.lib

BLAS_acml_LIBRARY= \
  C:/Libraries/acml4.4.0/win64/lib/libacml_dll.lib

BLAS_acml_mp_LIBRARY= \
  C:/Libraries/acml4.4.0/win64_mp/lib/libacml_mp_dll.lib

BLAS_acml_mv_LIBRARY= \
  C:/Libraries/acml4.4.0/win64/lib/libacml_mv_dll.lib</programlisting>

            <para>Hit configure</para>

            <para>Hit "generate"</para>
          </listitem>

          <listitem>
            <para>You should now have a visual studio project that you can
            open and build (try Release/x64 mode and try the install
            target).</para>
          </listitem>
        </itemizedlist>

        <para>Before attempting to run any reconstructions, please set the
        environment variable <varname>GADGETRON_HOME</varname> to point to the
        installation folder of your Gadgetron installation and make sure that
        the paths of all dependencies are in your <varname>PATH</varname>
        environment variable.</para>

        <para>You now have a working installation of the Gadgetron in Windows.
        Follow the instructions below to run a simple reconstruction example
        (<xref linkend="sect.simpleexample"/>).</para>
      </sect2>
    </sect1>

    <sect1 xml:id="sect.simpleexample">
      <title>Hello Gadgetron: Your First Image Reconstruction</title>

      <para>Some basic sample datasets are available from the Sourceforge
      website:</para>

      <para><uri type="website"
      xlink:href="https://sourceforge.net/projects/gadgetron/files/testdata/">https://sourceforge.net/projects/gadgetron/files/testdata/</uri></para>

      <para>You will generally encounter two types of data in this manual: a)
      Simple array format described in <xref linkend="simplearrayfiles"/> and
      b) HDF5 files which are a generic format for storing many different
      kinds of data and images. It is beyond the scope of this manual to
      explain the HDF5 file format, but we have added a small introductory
      section in the appendix (<xref linkend="section.hdf5"/>).</para>

      <para>Download the file <filename>gadgetron_testdata.h5</filename> from
      the website. In this example we will work with the dataset called
      "simple_gre" in the HDF5 file.</para>

      <para>Open two terminal windows to observe both client and Gadgetron
      communication output. In the Gadgetron terminal window simply
      type:</para>

      <screen><prompt>user@mycomputer:~/temp/gadgetron_out$</prompt> <userinput>gadgetron</userinput>  </screen>

      <para>In the client window (in the folder where you just downloaded the
      data) type:</para>

      <screen><prompt>user@mycomputer:~/temp/test_data$</prompt> <userinput><command>mriclient \
    -d gadgetron_testdata.h5 \
    -g simple_gre \
    -c default.xml</command></userinput>
</screen>

      <para>You should now see some logging information both in the Gadgetron
      window and in the client window. Specifically, you should see that a
      connection is being made and when the reconstruction is done the client
      should shut down:</para>

      <screen><prompt>user@mycomputer:~/temp/test_data$</prompt> <userinput>mriclient \
    -d gadgetron_testdata.h5 \ 
    -g simple_gre \ 
    -c default.xml</userinput>

Gadgetron MRI Data Sender
  -- host            :      localhost
  -- port            :      9002
  -- hdf5 file  in   :      gadgetron_testdata.h5
  -- hdf5 group in   :      simple_gre
  -- conf            :      default.xml
  -- loop            :      1
  -- hdf5 file out   :      ./out.h5
  -- hdf5 group out  :      2012-05-11 12:52:14
(31540|140170355443520) Connection from 127.0.0.1:9002
31540, 81, GadgetronConnector, Close Message received
(31540|140170283570944) Handling close...
(31540|140170283570944) svc done...
(31540|140170283570944) Handling close...
</screen>

      <para>The images are saved in the folder in which you started the
      <application>mriclient</application>. The client appends the result to
      an HDF5 file called <filename>out.h5</filename> (if no other file name
      is specified). A group is created with the current time and data and the
      images are stored in that group. If you run multiple reconstructions one
      after another, the results will be added to the same file, but a new
      group is created for each run. That makes it easy to compare results
      from different reconstructions. The images are stored in a single
      precision format as specified by the <filename>default.xml</filename>
      configuration file. Please see <xref linkend="section.hdf5"/> for
      details on how to read the output file. Briefly you could read and
      display the data in Matlab with:</para>

      <programlisting>images = h5read('out.h5','/2012-05-11 12:52:14/data_0');
imagesc(images(:,:,1,1));colormap(gray);</programlisting>
    </sect1>
  </chapter>

  <chapter>
    <title>Framework Overview</title>

    <sect1>
      <title>Gadgetron Streaming Architecture</title>

      <para>The Gadgetron consists of a streaming processing architecture and
      a set of toolboxes. The toolboxes are used within the streaming
      components but come as individual shared libraries and can thus also be
      used in standalone applications. The architecture is outlined in <xref
      linkend="fig.gadgetron.architecture"/>.</para>

      <figure xml:id="fig.gadgetron.architecture">
        <title>Gadgetron Architecture</title>

        <mediaobject>
          <imageobject role="html">
            <imagedata align="left" fileref="figs/architecture.png"
                       format="PNG" width="10in"/>
          </imageobject>

          <imageobject role="fo">
            <imagedata align="left" fileref="figs/architecture.png"
                       format="PNG" width="5in"/>
          </imageobject>

          <textobject>
            <phrase>Gadgetron Architecture</phrase>
          </textobject>
        </mediaobject>
      </figure>

      <para>The Gadgetron receives connections from clients through a TCP/IP
      connection. A client can be any application from which you can open a
      TCP/IP socket and send data. Once a connection to a client has been
      established (see <xref linkend="sect.communicationprotocol"/>), the
      Gadgetron will read data from the socket and pass it on down a chain of
      processing steps. The responsibility of reading and writing packages on
      the socket is dispatched to a set of Readers and Writers (see <xref
      linkend="sect.readerswriters"/>). Each step in the processing chain is
      implemented in a module or Gadget (see <xref linkend="sect.gadgets"/>).
      A reconstruction process is defined by defining a chain of Gadgets. The
      assembly of Gadgets is done dynamically at run-time (see <xref
      linkend="sect.streamconfiguration"/>).</para>

      <sect2 xml:id="sect.gadgets">
        <title>Gadgets</title>

        <para>A Gadget is the functional unit of the Gadgetron. You can think
        of the Gadget as a device with an input and output. Data passes
        through the device and is modified and/or transformed between input
        and output. By wiring multiple Gadgets together you create a
        reconstruction program. A schematic outline of a Gadget is seen in
        <xref linkend="fig.gadgetron.gadget"/></para>

        <figure xml:id="fig.gadgetron.gadget">
          <title>Gadget</title>

          <mediaobject>
            <imageobject role="html">
              <imagedata align="left" fileref="figs/gadget.png" format="PNG"
                         width="6in"/>
            </imageobject>

            <imageobject role="fo">
              <imagedata align="left" fileref="figs/gadget.png" format="PNG"
                         width="3in"/>
            </imageobject>

            <textobject>
              <phrase>Gadget</phrase>
            </textobject>
          </mediaobject>
        </figure>

        <para>The Gadget is an active object based on the
        <classname>ACE_Task</classname> from the ACE library. It has its own
        thread (or threads) of execution and an input queue where data is
        placed for processing by either the Gadgetron framework or an upstream
        Gadget.</para>

        <para>The active thread(s) in the Gadget will pick up a data package
        from the queue, and then pass it on to a virtual
        <function>process</function>. An abbreviated version of the header
        <filename>Gadget.h</filename> is seen below:</para>

        <programlisting>class Gadget : public ACE_Task&lt;ACE_MT_SYNCH&gt;
{

public:
   virtual int svc(void)
   {
      //Pick up package from queue
     
      //Call process
      if (this-&gt;process(m) == -1) {
         //Handle error
      }
      return 0;
   }

   //More function (left out for simplicity)

protected:
   virtual int process(ACE_Message_Block * m) = 0;

   virtual int process_config(ACE_Message_Block * m) {
      return 0;
   }

};</programlisting>

        <para>The data package used by the <classname>ACE_Task</classname> is
        the <classname>ACE_Message_Block</classname>, which is a very basic
        block of data (essentially just a byte array). To allow the Gadgets to
        check if the data blocks on the message queue are of the expected
        type, the Gadgetron uses a modified
        <classname>ACE_Message_Block</classname> called
        <classname>GadgetContainerMessage</classname>, which can contain any
        class with a no-argument constructor. It is possible to check if the
        <classname>GadgetContainerMessage</classname> contains a specific type
        of data, and if so, access that object. Suppose we want to store a
        class named <classname>MyClass</classname>:</para>

        <programlisting>GadgetContainerMessage&lt;MyClass&gt;* m = 
  new GadgetContainerMessage&lt;MyClass&gt;();

MyClass* mc = m-&gt;getObjectPtr();

//Do something with mc

m-&gt;release(); //Delete the message block and containing data</programlisting>

        <para>When a function receives an
        <classname>ACE_Message_Block</classname> it is possible to check if it
        is of a certain type:</para>

        <programlisting>int process(ACE_Message_Block* mb)
{
  
  GadgetContainerMessage&lt;MyClass&gt;* m = 
    AsContainerMessage&lt;MyClass&gt;(mb);

  if (m) {
    MyClass* mc = m-&gt;getObjectPtr();
    
    //Do something with mc

  } else {
    //Something went wrong, deal with error
    return -1;
  }

  mb-&gt;release();

  return 0;
}</programlisting>

        <para>It is possible to chain more than one
        <classname>ACE_Message_Block</classname> together using the
        <function>cont</function> function. This effectively provides a way to
        pass multiple arguments into a Gadget and checking if they have the
        appropriate types:</para>

        <programlisting>int process(ACE_Message_Block* mb)
{
  
  GadgetContainerMessage&lt;MyClass&gt;* m1 = 
    AsContainerMessage&lt;MyClass&gt;(mb);

  GadgetContainerMessage&lt;MyOtherClass&gt;* m2 = 
    AsContainerMessage&lt;MyOtherClass&gt;(mb-&gt;cont());

  if (m1 &amp;&amp; m2) {
    MyClass* mc = m1-&gt;getObjectPtr();
    MyOtherClass* moc = m2-&gt;getObjectPtr();
    
    //Do something with mc

  } else {
    //Something went wrong, deal with error
    return -1;
  }

  mb-&gt;release(); //This deletes both message blocks

  return 0;
}</programlisting>

        <para>It gets a bit tedious and error prone to repeat code like the
        above in every Gadget. To overcome this, the Gadgetron comes with a
        set of templated classes to automate the steps. Say we would like to
        make a Gadget which takes a single input argument, we would inherit
        from <classname>Gadget1</classname>. If you need two arguments, you
        inherit from <classname>Gadget2</classname>:</para>

        <programlisting>template &lt;class P1, class P2&gt; class Gadget2 : public Gadget
{
protected:
   int process(ACE_Message_Block* mb)
   {
     //Do type checking 
   }

   virtual int process(GadgetContainerMessage&lt;P1&gt;* m1, 
     GadgetContainerMessage&lt;P2&gt;* m2) = 0;
};</programlisting>

        <para>The base class performs the type checking for you and only when
        the arguments have been verified, it will call the virtual
        <function>process</function> above. So, all you need to do in order to
        implement a Gadget that takes two arguments is to implement this
        function. As an example, let's look at a very simple Gadget, which
        receives an image header and some image data and does a Fourier
        transform of the first 3 dimensions. First the header file
        <filename>FFTGadget.h</filename></para>

        <programlisting>#include "gadgetroncore_export.h"
#include "Gadget.h"
#include "GadgetMRIHeaders.h"
#include "hoNDArray.h"
#include &lt;complex&gt;

class EXPORTGADGETSCORE FFTGadget : 
public Gadget2&lt;GadgetMessageImage, hoNDArray&lt; std::complex&lt;float&gt; &gt; &gt;
{
 public:
  GADGET_DECLARE(FFTGadget)

 protected:
  virtual int process( 
     GadgetContainerMessage&lt; GadgetMessageImage&gt;* m1,
     GadgetContainerMessage&lt; hoNDArray&lt; std::complex&lt;float&gt; &gt; &gt;* m2);

};</programlisting>

        <para>Let us walk through the code step by step. The Gadget takes two
        arguments: 1) <classname>GadgetMessageImage</classname>, which is just
        a struct with some image header information (it is defined in
        <filename>GadgetMRIHeaders.h</filename>), and 2) a
        <classname>hoNDArray</classname>, which is a multidimensional array
        (see <xref linkend="sect.ndarray"/>) storage container. In this case
        the <classname>hoNDArray</classname> contains complex floating point
        data.</para>

        <para>There are a couple of other things to notice. One is the
        <function>EXPORTGADGETSCORE</function> macro in the class definition.
        This is needed to make things work properly on Windows. It is defined
        in <filename>gadgetroncore_export.h</filename> and is used (on
        Windows) to indicate if the class is being imported or exported from a
        DLL. It translates into <function>__declspec(dllexport)</function> or
        <function>__declspec(dllimport)</function> in Windows and is empty in
        Linux/OSX. It is beyond the scope of this manual to go into why such a
        declaration is needed, but keep this in mind when you start creating
        your own Gadgets. Each shared library (DLL) has its own export
        declaration macro.</para>

        <para>The other thing to notice is the
        <function>GADGET_DECLARE(FFTGadget)</function> macro. This macro is
        required for Windows to correctly handle shared libraries and is
        needed whenever you create a new Gadget to make things work properly
        on Windows.</para>

        <para>The actual implementation looks like this:</para>

        <programlisting>#include "FFTGadget.h"
#include "FFT.h"

int FFTGadget::process( 
   GadgetContainerMessage&lt; GadgetMessageImage&gt;* m1,
   GadgetContainerMessage&lt; hoNDArray&lt; std::complex&lt;float&gt; &gt; &gt;* m2)
{
  FFT&lt;float&gt;::instance()-&gt;ifft(m2-&gt;getObjectPtr(),0);
  FFT&lt;float&gt;::instance()-&gt;ifft(m2-&gt;getObjectPtr(),1);
  FFT&lt;float&gt;::instance()-&gt;ifft(m2-&gt;getObjectPtr(),2);

  if (this-&gt;next()-&gt;putq(m1) &lt; 0) {
     return GADGET_FAIL;
  }

  return GADGET_OK;
}

GADGET_FACTORY_DECLARE(FFTGadget)</programlisting>

        <para>Once we are inside the <function>process</function> function,
        the data has already been converted to the appropriate container
        messages and we can start processing the data. This function uses an
        FFT toolbox (more on toolboxes in <xref linkend="sect.toolboxes"/>).
        After the data has been Fourier transformed along the first 3
        dimensions it is placed on the next Gadgets queue. Remember the two
        <classname>GadgetContainerMessage</classname> objects were originally
        picked up from the message queue as a chain of
        <classname>ACE_Message_Block</classname> objects. They are still
        chained together, i.e. when passing <varname>m1</varname> on to the
        next Gadget we are effectively passing on both arguments.</para>

        <para>Another couple of macros to notice are the
        <varname>GADGET_OK</varname> and <varname>GADGET_FAIL</varname>. They
        are defined as 0 and -1 respectively. The convention in the Gadgetron
        is to return 0 when a function succeeds and &lt; 0 when it fails -
        unless the function returns a pointer.</para>

        <para>Last thing to notice is the
        <function>GADGET_FACTORY_DECLARE(FFTGadget)</function> statement. This
        is a macro which declares functions for loading a Gadget of this type
        out of a shared library and destroying it again when we are done. It
        ensures that we can load the Gadget on all platforms. When you create
        your own gadgets you should use this macro to declare the factory
        function for the Gadget.</para>

        <para>For a tutorial on how to make your own Gadget library see <xref
        linkend="sect.makingnewgadgetlibrary"/>.</para>

        <sect3 xml:id="sect.xmlparameters">
          <title>Gadget XML Configuration</title>

          <para>In addition to defining a Gadget's behavior in response to a
          data package, it is also possible for the Gadgets to receive
          configuration information or parameters. The user can define the
          Gadgets behavior in response to configuration information by
          implementing the <function>process_config</function> function in the
          Gadget header file. The configuration information or parameters is
          typically transmitted in the beginning of the reconstruction process
          from the client (see <xref linkend="sect.communicationprotocol"/>).
          The configuration information can in principle be in any format (a
          given application can use a binary format or a text format defined
          for the specific purpose), but conventionally the parameters are
          transmitted in XML format and the Gadgetron comes with toolbox
          functionality in <filename>GadgetXml.h</filename>, which allow easy
          access to parameters in XML format (see the examples throughout the
          source code on how to interpret parameters).</para>

          <para>An example of a parameter XML file for an MRI reconstruction
          is shown here:</para>

          <programlisting>&lt;?xml version="1.0" ?&gt;
&lt;gadgetron&gt;
    &lt;encoding&gt;
        &lt;kspace&gt;
            &lt;base_resolution&gt;
                &lt;value&gt;128&lt;/value&gt;
            &lt;/base_resolution&gt;
            &lt;readout_length&gt;
                &lt;value&gt;256&lt;/value&gt;
            &lt;/readout_length&gt;
            &lt;phase_encoding_lines&gt;
                &lt;value&gt;128&lt;/value&gt;
            &lt;/phase_encoding_lines&gt;
            &lt;partitions&gt;
                &lt;value&gt;64&lt;/value&gt;
            &lt;/partitions&gt;
            &lt;phase_resolution&gt;
                &lt;value&gt;1&lt;/value&gt;
            &lt;/phase_resolution&gt;
            &lt;slice_resolution&gt;
                &lt;value&gt;1&lt;/value&gt;
            &lt;/slice_resolution&gt;
            &lt;matrix_size&gt;
                &lt;value&gt;128&lt;/value&gt;
                &lt;value&gt;128&lt;/value&gt;
            &lt;/matrix_size&gt;
        &lt;/kspace&gt;
        &lt;trajectory&gt;
            &lt;value&gt;1&lt;/value&gt;
        &lt;/trajectory&gt;
        &lt;slices&gt;
            &lt;value&gt;1&lt;/value&gt;
        &lt;/slices&gt;
        &lt;acquisition_dwell_time_ns&gt;
            &lt;value&gt;7800&lt;/value&gt;
        &lt;/acquisition_dwell_time_ns&gt;
        &lt;channels&gt;
            &lt;value&gt;32&lt;/value&gt;
        &lt;/channels&gt;
    &lt;/encoding&gt;
    &lt;timing&gt;
        &lt;TR&gt;
            &lt;value&gt;5860&lt;/value&gt;
        &lt;/TR&gt;
        &lt;TE&gt;
            &lt;value&gt;2960&lt;/value&gt;
        &lt;/TE&gt;
    &lt;/timing&gt;
&lt;/gadgetron&gt;</programlisting>

          <para>The parameter scripts can have any format, but the convention
          is to have one root element called <varname>gadgetron</varname> and
          enclose all parameters in a hierarchical structure. The Gadgetron
          comes with functions and classes for parsing this format. Firstly,
          the <filename>TinyXML</filename> library is included with the
          Gadgetron and can be used to parse the XML script, but we also
          include some wrapper classes to make the parsing easier, the file
          <filename>GadgetXml.h</filename> includes the
          <classname>GadgetXMLNode</classname>:</para>

          <programlisting>class GadgetXMLNode
{
 public:
  GadgetXMLNode(TiXmlNode* anchor);

  //Other functions
 
  template&lt;typename T&gt; std::vector&lt;T&gt; get(std::string name);
}</programlisting>

          <para>This class can be used to access the XML parameters in a
          convenient way. There are multiple examples of this throughout the
          Gadgetron archive, but one example is given here:</para>

          <programlisting>int MyGadget::process_config(ACE_Message_Block* mb)
{

  //Use TinyXML to parse the doucment
  TiXmlDocument doc;
  doc.Parse(mb-&gt;rd_ptr());
 
  std::string path("gadgetron.encoding.kspace.matrix_size.value");

  //Get a vector with all the values 
  std::vector&lt;long&gt; dims = 
    n.get&lt;long&gt;(path);

  //Do something with the dimensions


  return GADGET_OK;
}</programlisting>

          <para>In the case of parsing the XML parameters listed above,
          <varname>dims</varname> would contain two values ([128,
          128]).</para>
        </sect3>
      </sect2>

      <sect2 xml:id="sect.readerswriters">
        <title>Readers and Writers</title>

        <para>As illustrated in <xref linkend="fig.gadgetron.architecture"/>
        the Gadgetron uses a set of Readers and Writers to deal with the
        incoming communication on the TCP/IP socket. Readers are responsible
        for deserialization of packages and Writers are responsible for
        serialization of packages. All packages that arrive on the socket will
        start with a message ID. Based on this ID, the Gadgetron delegates the
        responsibility of reading the package of the socket to a particular
        instance of a <classname>GadgetMessageReader</classname> defined by
        the following abstract class:</para>

        <programlisting>class GadgetMessageReader
{
 public:
  virtual ACE_Message_Block* read(ACE_SOCK_Stream* stream) = 0;
};</programlisting>

        <para>In order to be able to read a specific type of data, the
        <function>read</function> function must be implemented for that data
        type. As an example here is the
        <classname>GadgetMessageReader</classname>, which reads an MRI data
        acquisition from the socket.</para>

        <programlisting>class EXPORTGADGETSCORE MRIAcquisitionReader 
: public GadgetMessageReader
{
 public:
  GADGETRON_READER_DECLARE(MRIAcquisitionReader);
  virtual ACE_Message_Block* read(ACE_SOCK_Stream* socket);
};</programlisting>

        <para>Note the
        <function>GADGETRON_READER_DECLARE(MRIAcquisitionReader)</function>
        declaration. This is equivalent to the declaration needed for the
        Gadgets (see <xref linkend="sect.gadgets"/>) in order to make them
        load properly from shared libraries.</para>

        <para>The implementation of this particular reader is as follows (this
        is an abbreviated version without error checking, etc.):</para>

        <programlisting>ACE_Message_Block* MRIAcquisitionReader::read(ACE_SOCK_Stream* sock)
{

   GadgetContainerMessage&lt;GadgetMessageAcquisition&gt;* m1 = 
      new GadgetContainerMessage&lt;GadgetMessageAcquisition&gt;();
  
   GadgetContainerMessage&lt;hoNDArray&lt; std::complex&lt;float&gt; &gt; &gt;* m2 = 
      new GadgetContainerMessage&lt; hoNDArray&lt; std::complex&lt;float&gt; &gt; &gt;();
  
   m1-&gt;cont(m2);

   sock-&gt;recv_n(m1-&gt;getObjectPtr(), sizeof(GadgetMessageAcquisition);

   std::vector&lt;unsigned int&gt; adims;
   adims.push_back(m1-&gt;getObjectPtr()-&gt;samples);
   adims.push_back(m1-&gt;getObjectPtr()-&gt;channels);

   m2-&gt;getObjectPtr()-&gt;create(&amp;adims)
  
   long data_length = sizeof(std::complex&lt;float&gt;)*
      m1-&gt;getObjectPtr()-&gt;samples*m1-&gt;getObjectPtr()-&gt;channels;
      
   sock-&gt;recv_n (m2-&gt;getObjectPtr()-&gt;get_data_ptr(), data_length);
   
   return m1;
}

GADGETRON_READER_FACTORY_DECLARE(MRIAcquisitionReader)</programlisting>

        <para>The Reader allocates two
        <classname>GadgetContainerMessage</classname> data blocks to contain
        the incoming data. First an MRI acquisition header (defined in
        <filename>GadgetMRIHeaders.h</filename>) is read. Based hereon the
        length of each acquisition (number of samples) and the number of
        acquisition channels are determined. A
        <classname>hoNDArray</classname> is allocated to store the data read
        from the socket. Notice that the two
        <classname>GadgetContainerMessage</classname> are chained together
        using the <function>cont</function> function.</para>

        <para>A final important statement to notice is:</para>

        <programlisting>GADGETRON_READER_FACTORY_DECLARE(MRIAcquisitionReader)</programlisting>

        <para>This macro declares create and destroy functions to load the
        reader from a shared library on all platforms supported.</para>

        <para>Whereas the Readers are responsible for deserialization, the
        <classname>GadgetMessageWriter</classname> is responsible for the
        opposite operation (serialization). In practice, Gadgets that produce
        an output for the client application can hand that data back to the
        Gadgetron framework where it is placed on the output queue along with
        a message ID. This is for instance done in this (abbreviated) code
        from an <classname>ImageFinishGadget</classname>:</para>

        <programlisting>int ImageFinishGadget
::process(GadgetContainerMessage&lt;GadgetMessageImage&gt;* m1,
  GadgetContainerMessage&lt; hoNDArray&lt; float &gt; &gt;* m2)
{
   GadgetContainerMessage&lt;GadgetMessageIdentifier&gt;* mb =
      new GadgetContainerMessage&lt;GadgetMessageIdentifier&gt;();

   mb-&gt;getObjectPtr()-&gt;id = GADGET_MESSAGE_IMAGE_REAL_FLOAT;

   mb-&gt;cont(m1);

   int ret =  this-&gt;controller_-&gt;output_ready(mb);

   if ( (ret &lt; 0) ) {
      return GADGET_FAIL;
   }

  return GADGET_OK;
}</programlisting>

        <para>Notice that the Gadget has a reference to the Gadgetron
        framework through the <varname>controller_</varname> member variable,
        which is set during initialization.</para>

        <para>In the framework (more specifically in the
        <classname>GadgetStreamController</classname>) there is an active
        thread responsible for writing messages that are put on to the output
        queue. This is done by investigating the message ID and then picking
        the <classname>GadgetMessageWriter</classname> associated with this
        ID. A Writer must implement the following abstract class:</para>

        <programlisting>class GadgetMessageWriter
{
 public:
  virtual int write(ACE_SOCK_Stream* stream, 
                    ACE_Message_Block* mb) = 0;
};</programlisting>

        <para>The Writer is handed control of the socket along with the
        message block. A Writer declaration could look like:</para>

        <programlisting>class MRIImageWriter : public GadgetMessageWriter
{

public:
   GADGETRON_WRITER_DECLARE(GadgetMessageWriter);
   virtual int write(ACE_SOCK_Stream* sock, 
                     ACE_Message_Block* mb);
};</programlisting>

        <para>Notice again the
        <function>GADGETRON_WRITER_DECLARE(GadgetMessageWriterFLOAT)</function>
        which ensures proper run-time linking behavior. The implementation
        could look like (abbreviated with no error checking, etc.):</para>

        <programlisting>int MRIImageWriter::write(ACE_SOCK_Stream* sock, 
                          ACE_Message_Block* mb)
{

   GadgetContainerMessage&lt;GadgetMessageImage&gt;* imagemb = 
      AsContainerMessage&lt;GadgetMessageImage&gt;(mb);
  
   GadgetContainerMessage&lt; hoNDArray&lt; float &gt; &gt;* datamb =
      AsContainerMessage&lt; hoNDArray&lt; float &gt; &gt;(imagemb-&gt;cont());
  
   if (!datamb || !imagemb) {
      //Deal with errors
   }
   
   GadgetMessageIdentifier id;
   id.id = GADGET_MESSAGE_IMAGE_REAL_FLOAT;
 
   sock-&gt;send_n (&amp;id, sizeof(GadgetMessageIdentifier));

   sock-&gt;send_n (imagemb-&gt;getObjectPtr(), sizeof(GadgetMessageImage));

   sock-&gt;send_n (datamb-&gt;getObjectPtr()-&gt;get_data_ptr(), 
      sizeof(float)*datamb-&gt;getObjectPtr()-&gt;get_number_of_elements());

   return 0;
}

GADGETRON_WRITER_FACTORY_DECLARE(MRIImageWriter)</programlisting>

        <para>Once again notice the required
        <function>GADGETRON_WRITER_FACTORY_DECLARE(MRIImageWriter)</function>
        macro. Also notice that the message ID is transmitted to the client.
        The client is expected to follow the same communication model as the
        Reader, but it is determined entirely by the Writer implementation how
        the message is transmitted.</para>

        <para>Readers and Writers are loaded dynamically at run-time along
        with the Gadgets (see <xref linkend="sect.streamconfiguration"/>). The
        input and output behaviour can be adapted by manipulating which
        Readers and Writers are associated with which message IDs.</para>
      </sect2>

      <sect2 xml:id="sect.streamconfiguration">
        <title>Stream Configuration</title>

        <para>A Gadgetron reconstruction is made up of modules, i.e. Readers,
        Writers, and Gadgets. New reconstruction programs can be created by
        simply assembling existing components in a new way. The configuration
        of the Gadgetron stream is done at run-time and new configuration
        chains can be created without recompiling any of the underlying
        Gadgets. More specifically, the configuration is specified in an XML
        file that the Gadgetron will read before receiving data. The best way
        to explain the format is by looking at a (simplified) example:</para>

        <programlisting>&lt;?xml version="1.0" ?&gt;  
&lt;gadgetron&gt;
 
 &lt;readers&gt;
   &lt;reader&gt;
    &lt;slot&gt;1001&lt;/slot&gt;
    &lt;dll&gt;gadgetroncore&lt;/dll&gt;
    &lt;class&gt;MRIAcquisitionReader&lt;/class&gt;
   &lt;/reader&gt;
 &lt;/readers&gt;
  
 &lt;writers&gt;
  &lt;writer&gt;
   &lt;slot&gt;1005&lt;/slot&gt;
   &lt;dll&gt;gadgetroncore&lt;/dll&gt;
   &lt;class&gt;MRIImageWriterFLOAT&lt;/class&gt;
  &lt;/writer&gt;
  &lt;writer&gt;
   &lt;slot&gt;1006&lt;/slot&gt;
   &lt;dll&gt;gadgetroncore&lt;/dll&gt;
   &lt;class&gt;MRIImageWriterUSHORT&lt;/class&gt;
  &lt;/writer&gt;
 &lt;/writers&gt;

 &lt;stream&gt;
  &lt;gadget&gt;
   &lt;name&gt;Accumulator&lt;/name&gt;
   &lt;dll&gt;gadgetroncore&lt;/dll&gt;
   &lt;class&gt;AccumulatorGadget&lt;/class&gt;
  &lt;/gadget&gt;

  &lt;gadget&gt;
   &lt;name&gt;FFT&lt;/name&gt;
   &lt;dll&gt;gadgetroncore&lt;/dll&gt;
   &lt;class&gt;FFTGadget&lt;/class&gt;
  &lt;/gadget&gt;

  &lt;gadget&gt;
    &lt;name&gt;ExtractMAG&lt;/name&gt;
    &lt;dll&gt;gadgetroncore&lt;/dll&gt;
    &lt;class&gt;ExtractGadget&lt;/class&gt;
  &lt;/gadget&gt;

  &lt;gadget&gt;
   &lt;name&gt;ImageFinishFLOAT&lt;/name&gt;
   &lt;dll&gt;gadgetroncore&lt;/dll&gt;
   &lt;class&gt;ImageFinishGadgetFLOAT&lt;/class&gt;
  &lt;/gadget&gt;
 &lt;/stream&gt;

&lt;/gadgetron&gt;</programlisting>

        <para>The configuration file format contains 3 sections: 1) Readers,
        2) Writers, 3) Stream (with Gadgets) corresponding to the 3 different
        types of components that can be assembled in the Gadgetron.</para>

        <para>In the example above, the Readers section contains only one
        reader, which is the <classname>MRIAcquisitionReader</classname>
        mentioned previously. The message ID associated with this Reader is
        1001. Every time a message with ID 1001 arrives on the socket,
        responsibility for reading the message will be delegated to the
        <classname>MRIAcquisitionReader</classname>. When the Gadgetron
        configuration is loaded, the framework will load the
        <classname>MRIAcquisitionReader</classname> from the DLL (shared
        library) <filename>gadgetroncore</filename>. On the Linux platform
        this would be a shared library called
        <filename>libgadgetroncore.so</filename> and on the Windows platform
        it would be called <filename>gadgetroncore.dll</filename>.</para>

        <para>The Gadgetron framework knows how to load the components from
        the DLLs assuming that they have been declared properly as described
        in <xref linkend="sect.readerswriters"/> and <xref
        linkend="sect.gadgets"/>.</para>

        <para>The example Gadgetron configuration has two Writers, i.e. it is
        capable of outputting two different types of data. Again the
        declarations cause the Gadgetron framework to load specific instances
        of <classname>GadgetMessageWriter</classname> and associate them with
        specific ID numbers.</para>

        <para>There are certain built-in Readers and Writers in addition to
        those specified in the configuration file. As an example, there are
        Readers for receiving configurations to be used by the Gadgetron and
        for receiving the parameters that will be passed to all Gadgets (see
        <xref linkend="sect.communicationprotocol"/>). If the Gadgetron
        receives a message with an ID for which there is no associated Reader
        or encounters a message on the output queue for which there is no
        associated Writer an error will be generated, the Gadgetron stream
        shuts down, and the connection to the client will be closed.</para>

        <para>The <literal>&lt;stream&gt;</literal> section of the
        configuration specifies which Gadgets to load. In the example above,
        we have 4 Gadgets. In this specific case the reconstruction is an MRI
        reconstruction. The first Gadget is an
        <classname>AccumulatorGadget</classname>, which collects individual
        lines and inserts them in k-space. When the k-space image is complete
        it is sent to the next Gadget in the chain, the
        <classname>FFTGadget</classname>, which is responsible for Fourier
        transforming the data into image space. The next Gadget
        (<classname>ExtractGadget</classname>) will extract the magnitude of
        the complex image. Finally the last Gadget in the chain
        (<classname>ImageFinishGadgetFLOAT</classname>) sends the
        reconstructed image back to the Gadgetron framework where it is added
        to the output queue.</para>

        <para>It is also possible to send configuration parameters to Gadgets
        using the XML file. For example, to set a parameter in a Gadget, one
        could write:</para>

        <programlisting>  &lt;gadget&gt;
   &lt;name&gt;Accumulator&lt;/name&gt;
   &lt;dll&gt;gadgetroncore&lt;/dll&gt;
   &lt;class&gt;AccumulatorGadget&lt;/class&gt;
   &lt;property&gt;&lt;name&gt;MyTestProperty&lt;/name&gt;
   &lt;value&gt;Blah Blah&lt;/value&gt;&lt;/property&gt;
   &lt;property&gt;&lt;name&gt;MyTestProperty2&lt;/name&gt;
   &lt;value&gt;98776.862187&lt;/value&gt;&lt;/property&gt;
  &lt;/gadget&gt;
</programlisting>

        <para>The two properties will now be accessible inside the Gadget
        using the parameter access functions defined in
        <filename>Gadget.h</filename>:</para>

        <programlisting>class Gadget : public ACE_Task&lt;ACE_MT_SYNCH&gt;
{

//Other definitions

int get_bool_value(const char* name);
int get_int_value(const char* name);
double get_double_value(const char* name);

};</programlisting>

        <para>Additionally it is also possible to specify how many active
        threads there should be in a Gadget. This is specified with:</para>

        <programlisting>  &lt;gadget&gt;
   &lt;name&gt;Accumulator&lt;/name&gt;
   &lt;dll&gt;gadgetroncore&lt;/dll&gt;
   &lt;class&gt;AccumulatorGadget&lt;/class&gt;
   &lt;property&gt;&lt;name&gt;threads&lt;/name&gt;&lt;value&gt;5&lt;/value&gt;&lt;/property&gt;
  &lt;/gadget&gt;</programlisting>

        <para>Which would make the <classname>AccumulatorGadget</classname>
        have 5 threads.</para>
      </sect2>

      <sect2 xml:id="sect.communicationprotocol">
        <title>Communication Sequence</title>

        <para>Communication between a client and the Gadgetron follows a
        straightforward communication protocol. When the Gadgetron is started
        it will be expecting a connection on a specific port (port 9002 is the
        default). The communication sequence is as follows:</para>

        <orderedlist>
          <listitem>
            <para>The client makes connection</para>
          </listitem>

          <listitem>
            <para>The Gadgetron accepts the connection and creates a new
            instance of a <classname>GadgetStreamController</classname> (see
            <xref linkend="fig.gadgetron.architecture"/>). After creating the
            <classname>GadgetStreamController</classname> the Gadgetron
            returns to accept connections on the socket such that multiple
            clients can be connected simultaneously.</para>
          </listitem>

          <listitem>
            <para><classname>The GadgetStreamController</classname> takes
            control of the socket and expects to read a specific type of
            message, which either contains the filename of a specific stream
            configuration (see <xref linkend="sect.streamconfiguration"/>) or
            alternatively it can receive the actual XML stream specification
            directly on the socket. These two types of messages are read with
            Readers that are always registered for the Gadgetron (see <xref
            linkend="sect.readerswriters"/>). If the Gadgetron receives the
            filename of a Gadget stream it expects to be able to find that
            configuration file in the <filename>gadegtron/config</filename>
            folder (see <xref linkend="sect.fileorganization"/>).</para>
          </listitem>

          <listitem>
            <para>The <classname>GadgetStreamController</classname> is then
            expecting to receive parameters that will be transmitted to each
            individual Gadget. In principle the "parameters" is just a raw
            buffer of characters that will be transmitted as such to each
            individual Gadget. It is the convention however to send the
            parameters in an XML format. It is up to each individual Gadget to
            interpret the parameters. The user can implement any behavior in
            response to the parameters by implementing the
            <function>process_config</function> function (see <xref
            linkend="sect.gadgets"/>). The client can send parameters at any
            time during a reconstruction and they will always be transmitted
            to all Gadgets through the <function>process_config</function>
            function.</para>
          </listitem>

          <listitem>
            <para>The client then starts transmitting data packages that the
            Gadgetron processes. Images are returned to the client.</para>
          </listitem>

          <listitem>
            <para>When the client has no more data it will send a closure
            package. This package causes all Gadgets (in order) to process all
            remaining data on their input queue and then shut down.</para>
          </listitem>

          <listitem>
            <para>Once the final Gadget has shut down, the connection with the
            client is terminated.</para>
          </listitem>
        </orderedlist>

        <para>To make it easier to create a new client, the Gadgetron comes
        with a <classname>GadgetronConnector</classname> class:</para>

        <programlisting>class GadgetronConnector: 
  public ACE_Svc_Handler&lt;ACE_SOCK_STREAM, ACE_MT_SYNCH&gt; {

public:

 int open (std::string hostname, std::string port);   
 int putq  (ACE_Message_Block * mb ,  
     ACE_Time_Value *  timeout = 0);

 int register_reader(unsigned int slot, 
     GadgetMessageReader* reader);

 int register_writer(unsigned int slot, 
     GadgetMessageWriter* writer);

 int send_gadgetron_configuration_file(std::string config_xml_name);   
 int send_gadgetron_configuration_script(std::string config_xml_name);
 int send_gadgetron_parameters(std::string xml_string);
};</programlisting>

        <para>This class can be used to create simple clients that open a
        connection with the Gadgetron using the <function>open</function>
        function and then communicate with the Gadgetron through the Readers
        and Writers registered with the connector. See the
        <application>mriclient</application> example application
        (<filename>gagetron/apps/clients/mriclient</filename> in the source
        code archive) for a simple example of how to build a Gadgetron
        client.</para>
      </sect2>

      <sect2 xml:id="sect.fileorganization">
        <title>File Organization</title>

        <para>This section provides a brief overview of the file organization
        in the Gadgetron installation. Once you have compiled the Gadgetron
        and installed it (see <xref linkend="sect.installation"/>), it will
        reside in its designated installation folder
        (<varname>GADGETRON_HOME</varname>). For the purposes of this
        description, we will assume that the Gadgetron was installed in
        <filename>/usr/local/gadgetron</filename>.</para>

        <para>In <varname>GADGETRON_HOME</varname> you should find the
        following folders:</para>

        <para><itemizedlist>
            <listitem>
              <para><filename>bin</filename>: Contains all executables from
              the Gadgetron framework including the
              <application>gadgetron</application> executable itself and all
              clients and standalone applications.</para>
            </listitem>

            <listitem>
              <para><filename>config</filename>: Contains Gadgetron XML
              configuration files (see <xref
              linkend="sect.streamconfiguration"/>). This is where the
              Gadgetron searches for the configurations requested by the
              clients during initialization of the Gadget chain (see <xref
              linkend="sect.communicationprotocol"/>).</para>
            </listitem>

            <listitem>
              <para><filename>lib:</filename>Contains all shared libraries
              (Gadgets and toolboxes). Additionally, this is the default path
              where Python Gadgets look for Python modules.</para>
            </listitem>

            <listitem>
              <para><filename>include</filename>: Contains all header files
              for the Gadgets and Toolboxes in order that they can be linked
              into external applications and Gadget libraries compiled outside
              the Gadgetron source tree.</para>
            </listitem>

            <listitem>
              <para><filename>cmake:</filename> Contains a set of helpful
              CMake scripts that can be used if you wish to build applications
              or Gadget libraries outside the Gadgetron source tree. Among
              other things it contains a
              <filename>FindGadgetron.cmake</filename> script, which can be
              used to localize and set paths for the Gadgetron using
              CMake.</para>
            </listitem>
          </itemizedlist></para>
      </sect2>
    </sect1>

    <sect1 xml:id="sect.toolboxes">
      <title>Gadgetron Toolboxes</title>

      <para>The core reconstruction data structures and algorithms are made
      available through a set of toolboxes in shared libraries. The toolboxes
      implement the functionality of the various Gadgets, but they can also be
      used in standalone applications. A non-exhaustive overview of key
      functionality is covered in the following sections.</para>

      <sect2 xml:id="sect.ndarray">
        <title><classname>NDArray</classname></title>

        <para>Most image processing operations involve multi-dimensional
        arrays. Although the Gadgetron framework does not impose any specific
        array structure on the user, it does come with an abstract
        multi-dimensional array used throughout: the
        <classname>NDArray</classname>. It has a specific implementation for
        the CPU (<classname>hoNDArray</classname>) and GPU
        (<classname>cuNDArray</classname>). The abstract class definition
        looks like (abbreviated version):</para>

        <programlisting>template &lt;class T&gt; class NDArray
{
 public:
  
  NDArray ();

  virtual ~NDArray();
  
  virtual T* create(std::vector&lt;unsigned int&gt; *dimensions); 

  virtual T* create(std::vector&lt;unsigned int&gt; *dimensions, 
                    T* data, bool delete_data_on_destruct = false);

  virtual int permute(std::vector&lt;unsigned int&gt; *dim_order,
                      NDArray&lt;T&gt; *out = 0, int shift_mode = 0);
  
  inline unsigned int get_number_of_dimensions() const {
    return dimensions_-&gt;size();
  }

  unsigned int get_size(unsigned int dimension);

  boost::shared_ptr&lt; std::vector&lt;unsigned int&gt; &gt; get_dimensions();
  
  inline T* get_data_ptr() const { 
    return data_; 
  }
  
  inline unsigned long int get_number_of_elements() const {
    return elements_;
  }

  //Other public functions...

protected:

  virtual int allocate_memory() = 0;
  virtual int deallocate_memory() = 0;

  //Other private functions
  
};</programlisting>

        <para>The CPU (host) definition would look like (abbreviated):</para>

        <programlisting>template &lt;class T&gt; class hoNDArray : public NDArray&lt;T&gt;
{

public:
   //Public functions...

protected:
   virtual int allocate_memory();
   virtual int deallocate_memory();
};</programlisting>

        <para>As is seen from the <classname>NDArray</classname> header file,
        this class has a no-argument constructor, which makes it suited for
        encapsulating in the <classname>GadgetContainerMessage</classname>
        mentioned in <xref linkend="sect.gadgets"/>. The procedure for
        creating an array with complex float values would look something like
        this:</para>

        <programlisting>#include &lt;hoNDArray.h&gt;
#include &lt;complex&gt;

hoNDArray&lt; std::complex&lt;float&gt; &gt; myArray;

std::vector&lt;unsigned int&gt; dimensions;
dimensions.push_back(128);
dimensions.push_back(128);

if(!myArray.create(&amp;dimensions)) {
   //Deal with errors
}

//process data</programlisting>

        <para>To create an <classname>NDArray</classname> contained in a
        <classname>GadgetContainerMessage</classname> would look something
        like this:</para>

        <programlisting>GadgetContainerMessage&lt; hoNDArray&lt; std::complex&lt;float&gt; &gt; &gt;* m = 
  new GadgetContainerMessage&lt; hoNDArray&lt; std::complex&lt;float&gt; &gt; &gt;();

std::vector&lt;unsigned int&gt; dimensions;
dimensions.push_back(128);
dimensions.push_back(128);

if(!m-&gt;getObjectPtr()-&gt;create(&amp;dimensions)) {
   //Deal with errors
}

//Process data or pass on to other Gadget, etc. 

m-&gt;release(); //Delete the message block and containing data
</programlisting>

        <para>As mentioned in <xref linkend="sect.gadgets"/>, the
        <classname>GadgetContainerMessage</classname> is a specialized version
        of the <classname>ACE_Message_Block</classname> class from the ACE
        framework. Data is passed between Gadgets in the form of
        <classname>ACE_Message_Block</classname>s and Gadgets have access to
        utility functions that allow them to test if a given
        <classname>ACE_Message_Block</classname> is in fact a partcular type
        of <classname>GagetContainerMessage</classname>.</para>

        <sect3>
          <title>GPU Support</title>

          <para>The <classname>NDArray</classname> data structure also has a
          GPU implementation (abbreviated version of header below):</para>

          <programlisting>template &lt;class T&gt; class cuNDArray : public NDArray&lt;T&gt;
{
 public:
  cuNDArray();

  cuNDArray(const cuNDArray&lt;T&gt;&amp; a);

  // Constructor from hoNDArray
  cuNDArray(hoNDArray&lt;T&gt; *a);

  // Assignment operator
  cuNDArray&amp; operator=(const cuNDArray&lt;T&gt;&amp; rhs);
  
  virtual ~cuNDArray();

  virtual T* create(std::vector&lt;unsigned int&gt; *dimensions);

  virtual T* create(std::vector&lt;unsigned int&gt; *dimensions, 
                    int device_no);

  virtual T* create(std::vector&lt;unsigned int&gt; *dimensions, 
                    T* data, bool delete_data_on_destruct = false);

  virtual boost::shared_ptr&lt; hoNDArray&lt;T&gt; &gt; to_host() const;
  
  virtual int set_device(int device_no);
  inline int get_device() { return device_; }
  
 protected:
  
  int device_; 
  virtual int allocate_memory();
  virtual int deallocate_memory();
  
};</programlisting>

          <para>It has a few extra <function>create</function> functions
          compared to the host (CPU) version of this array. Specifically, it
          is possible to provide the array with the device number that the
          array should be allocated on. This is important when working on
          systems with multiple GPU processors. The default is to allocate it
          on the current device (device 0 unless specifically set otherwise).
          It is possible to query on which device the data is allocated and to
          effectively move the data from one device to another through
          operators. Similarly, one copy constructor takes a
          <classname>hoNDArray</classname> and transparently copies the host
          data to the GPU.</para>
        </sect3>
      </sect2>

      <sect2>
        <title><classname>vector_td</classname></title>

        <para>The class <classname>vector_td</classname> provides a basic
        representation of one-, two-, three-, or four-dimensional vectors
        (positions). It is templetized with the datatype <varname>T</varname>
        and dimensionality <varname>D</varname>. For convenience we provide a
        set of typedefs to commonly encountered instances. A subset of the
        definitions provided in <filename>vector_td.h</filename> is provided
        here (users should check the actual file e.g. for additional often
        used constructors):</para>

        <programlisting>
template&lt; class T, unsigned int D &gt; class vector_td
{
public:

  T vec[D];

  __inline__ __host__ __device__ T&amp; operator[](const int i){
    return vec[i];
  }

  __inline__ __host__ __device__ const T&amp; operator[](const int i) const {
    return vec[i];
  }
};


// Some typedefs for convenience

template&lt; class REAL, unsigned int D &gt; struct reald{
  typedef vector_td&lt; REAL, D &gt; Type;
};

template&lt; unsigned int D &gt; struct intd{
  typedef vector_td&lt; int, D &gt; Type;
};

template&lt; unsigned int D &gt; struct uintd{
  typedef vector_td&lt; unsigned int, D &gt; Type;
};

template&lt; unsigned int D &gt; struct floatd{
 typedef typename reald&lt; float, D &gt;::Type Type;
};

template&lt; unsigned int D &gt; struct doubled{
  typedef typename reald&lt; double, D &gt;::Type Type;
};

template&lt; class T &gt; struct complext{
  typedef vector_td&lt; T, 2 &gt; Type;
};

</programlisting>

        <para>A number of arithmetic and conditional operators on the
        <classname>vector_td</classname> are defined in
        <filename>vector_td_operators.h</filename>. Similarly, the header
        <filename>vector_td_utilities.h</filename> wraps common math
        functionality for the <classname>vector_td</classname> class. Many
        common operations that take one of more
        <classname>cuNDArray</classname> instances with element type
        <classname>vector_td</classname> are defined in
        <filename>ndarray_vector_utilities.h</filename>. We encourage the
        reader to explore these utilities on his own.</para>

        <para>The <classname>vector_td</classname> can be used in both host
        and device code. As an example of use it is contained in the interface
        of the non-Cartesian FFT described in <xref
        linkend="sect.NFFT"/>.</para>
      </sect2>

      <sect2>
        <title>complext</title>

        <para>A complex number class that can be used in both host and device
        code is found in <filename>complext.h</filename>. It contains a
        substantial set of useful operators and functions.</para>
      </sect2>

      <sect2 xml:id="sect.ffttoolbox">
        <title>Fourier Transforms</title>

        <sect3>
          <title>Cartesian FFT</title>

          <sect4>
            <title>FFT of a <classname>hoNDArray</classname></title>

            <para>The Gadgetron uses the FFTW library for Fourier transform of
            <classname>hoNDArray</classname> structures. Users can call the
            FFTW directly from their code, but to make things a little easier,
            we provide a simple wrapper class defined in
            <filename>toolboxes/ndarray/FFT.h</filename>. Here is an
            abbreviated version:</para>

            <programlisting>template &lt;typename T&gt; class EXPORTNDARRAY FFT
{

public:
 static FFT&lt;T&gt;* instance(); 

 void fft(hoNDArray&lt; std::complex&lt;T&gt; &gt;* input, 
          unsigned int dim_to_transform);

 void ifft(hoNDArray&lt; std::complex&lt;T&gt; &gt;* input, 
          unsigned int dim_to_transform);

 void fft(hoNDArray&lt; std::complex&lt;T&gt; &gt;* input);

 void ifft(hoNDArray&lt; std::complex&lt;T&gt; &gt;* input);

protected:
 FFT();
 virtual ~FFT();
};</programlisting>

            <para>The <classname>FFT</classname> class provides simple wrapper
            functionality to perform FFTs of <classname>hoNDArray</classname>s
            along a specific dimension or along all dimensions. It performs
            <emphasis>in place</emphasis> FFTs and works on complex arrays of
            single or double precision.</para>

            <para>An important feature of this class is that it is a process
            wide singleton for the Gadgetron. As outlined in the definition
            above, the constructor and destructor are protected and it is not
            possible to allocate a new <classname>FFT</classname> object. The
            way to use the class is through the <function>instance
            </function>function:</para>

            <programlisting>#include "FFT.h"

FFT&lt;float&gt;::instance()-&gt;fft(...);</programlisting>

            <para>The reason for this is that the FFTW planning routines are
            not thread safe. Multiple Gadgets (that each have their own thread
            of execution) may need to use FFTs and consequently the planning
            routines need to be protected with a mutex. All of this is handled
            inside the <classname>FFT</classname> class and since it is a
            singleton only one thread can run the planning routines at any
            given time.</para>

            <para>As mentioned it is possible for the users to call FFTW
            routines directly, and there may be some performance reasons for
            doing so (as opposed to using this wrapper), but please be aware
            of this thread safety issue when you design your Gadgets. If you
            want to be on the safe side, use the wrapper.</para>
          </sect4>

          <sect4>
            <title>FFT of a <classname>cuNDArray</classname></title>

            <para>Cartesian Fast Fourier Transform on the GPU is supported by
            wrapping Cuda's FFT routines as defined in
            <filename>cuNDFFT.h</filename>.</para>

            <programlisting>template&lt;class T&gt; class EXPORTGPUCORE cuNDFFT
{
 public:

  cuNDFFT() {}
  virtual ~cuNDFFT() {}

  int fft ( cuNDArray&lt;T&gt; *input, 
    std::vector&lt;unsigned int&gt; *dims_to_transform );

  int ifft( cuNDArray&lt;T&gt; *input, 
    std::vector&lt;unsigned int&gt; *dims_to_transform, 
    bool do_scale = true );

  int fft ( cuNDArray&lt;T&gt; *input, 
    unsigned int dim_to_transform);

  int ifft( cuNDArray&lt;T&gt; *input, 
    unsigned int dim_to_transform, 
    bool do_scale = true );

  int fft ( cuNDArray&lt;T&gt; *input );
  int ifft( cuNDArray&lt;T&gt; *input, 
    bool do_scale = true );

 protected:
  int fft_int( cuNDArray&lt;T&gt; *input, 
    std::vector&lt;unsigned int&gt; *dims_to_transform, 
    int direction, 
    bool do_scale = true );
};
 </programlisting>

            <para>The interface defines forwards and inverse transforms of a
            single array dimension, all dimensions of the array, or a subset
            of dimensions.</para>
          </sect4>
        </sect3>

        <sect3 xml:id="sect.NFFT">
          <title>Non-Cartesian FFT</title>

          <para>A dedicated GPU-implementation of the NUFFT - often referred
          to a gridding - is provided. The interface is defined in
          <filename>NFFT.h</filename> provided below in abbreviated
          form</para>

          <programlisting>template&lt; class REAL, unsigned int D &gt; class EXPORTGPUNFFT NFFT_plan
{
 public: // Main interface
    
  // Constructors
  NFFT_plan();
  NFFT_plan( typename uintd&lt;D&gt;::Type matrix_size, 
             typename uintd&lt;D&gt;::Type matrix_size_os, 
             REAL W, int device = -1 );

  // Destructor
  virtual ~NFFT_plan();

  // Clear internal storage in plan
  enum NFFT_wipe_mode { NFFT_WIPE_ALL, NFFT_WIPE_PREPROCESSING };
  bool wipe( NFFT_wipe_mode mode );

  // Replan 
  bool setup( typename uintd&lt;D&gt;::Type matrix_size, 
              typename uintd&lt;D&gt;::Type matrix_size_os, 
              REAL W, int device = -1 );
    
  // Preproces trajectory 
  // ( Cartesian to non-Cartesian / non-Cartesian to Cartesian / both )
  enum NFFT_prep_mode { NFFT_PREP_C2NC, NFFT_PREP_NC2C, NFFT_PREP_ALL };
  bool preprocess( cuNDArray&lt;typename reald&lt;REAL,D&gt;::Type&gt; *trajectory, 
                   NFFT_prep_mode mode );
    
  // Execute NFFT 
  // ( Cartesian to non-Cartesian or non-Cartesian to Cartesian)  
  enum NFFT_comp_mode { NFFT_FORWARDS_C2NC, NFFT_FORWARDS_NC2C, 
                        NFFT_BACKWARDS_C2NC, NFFT_BACKWARDS_NC2C };
  bool compute( cuNDArray&lt;complext&lt;REAL&gt; &gt; *in, 
                cuNDArray&lt;complext&lt;REAL&gt; &gt; *out, 
                cuNDArray&lt;REAL&gt; *dcw, NFFT_comp_mode mode );

  // Execute NFFT iteration 
  // (Cartesian to non-Cartesian and back to Cartesian space)
  bool mult_MH_M( cuNDArray&lt;complext&lt;REAL&gt; &gt; *in, 
                  cuNDArray&lt;complext&lt;REAL&gt; &gt; *out, 
                  cuNDArray&lt;REAL&gt; *dcw, 
                  std::vector&lt;unsigned int&gt; halfway_dims );
  
 public: // Utilities
  
  // NFFT convolution 
  // (Cartesian to non-Cartesian or non-Cartesian to Cartesian)
  enum NFFT_conv_mode { NFFT_CONV_C2NC, NFFT_CONV_NC2C };
  bool convolve( cuNDArray&lt;complext&lt;REAL&gt; &gt; *in, 
                 cuNDArray&lt;complext&lt;REAL&gt; &gt; *out, 
                 cuNDArray&lt;REAL&gt; *dcw, 
                 NFFT_conv_mode mode, bool accumulate = false );
    
  // NFFT FFT
  enum NFFT_fft_mode { NFFT_FORWARDS, NFFT_BACKWARDS };
  bool fft( cuNDArray&lt;complext&lt;REAL&gt; &gt; *data, 
            NFFT_fft_mode mode, bool do_scale = true );
  
  // NFFT deapodization
  bool deapodize( cuNDArray&lt;complext&lt;REAL&gt; &gt; *image );

 public: // Setup queries

  typename uintd&lt;D&gt;::Type get_matrix_size();
  typename uintd&lt;D&gt;::Type get_matrix_size_os();
  REAL get_W();
  unsigned int get_device();
  
...
};</programlisting>

          <para>After a <classname>NFFT_plan</classname> is constructed the
          <function>preprocess</function> function should be called with the
          desired trajectory. In the special case of radial sampling the
          header <filename>radial_utilities.h</filename> defines some
          convienient functions to compute radial trajectories and
          corresponding density compensation weights. After preprocessing the
          NFFT can be executed through the <function>compute</function>
          function. The individial building blocks of the NFFT - convolution,
          FFT, and deapodization - are exposed in the public interface and
          hence available for use in custom algorithms.</para>

          <para>It is often required to perform the NFFT on a number of
          different inputs. Particularly in 1D and 2D the best performance is
          obtained if many transforms are executed concurrently in order to
          keep the device fully occupied. Two strategies can be
          combined:<itemizedlist>
              <listitem>
                <para>The trajectory passed to the preprocess method is
                normally a one-dimension cuNDArray containing normalized (to
                the range [-0.5;0.5]) non-Cartesian positions as
                <classname>reald&lt;REAL,D&gt;</classname> elements of
                precision <classname>REAL</classname> and dimensionality
                <classname>D</classname>. However, if the cuNDArray is
                two-dimensional, the latter dimension specifies that we wish
                to transform a number of frames with different trajectories
                concurrently.</para>
              </listitem>

              <listitem>
                <para>If a number of transformations with identical
                trajectories are to be transformed, the input and output
                arrays to the compute methods can be any multiplum of the
                Cartesian and non-Cartesian dimensions configured from the
                <classname>setup</classname> and
                <classname>preprocess</classname> methods. The images provided
                are consequently batch transformed.</para>
              </listitem>
            </itemizedlist></para>

          <para><remark>Please note</remark>. The NFFT performs significantly
          better on GPUs supporting Cuda's shader model 2.0 or newer compared
          to devices supporting only shader models 1.x. The reason being that
          we rely on the inherent caching of global memory - available only on
          hardware supporting at least shader model 2.0.</para>
        </sect3>
      </sect2>

      <sect2 xml:id="sect.matrix_operators">
        <title>Linear (Matrix) Operators</title>

        <para>A fundamental building block of most image reconstruction
        algorithms is the abstract class
        <classname>linearOperator</classname>. A range of linear imaging and
        regularization operators are inherited from this pure virtual base
        class (abbreviated):<programlisting>template &lt; class REAL, class ARRAY_TYPE &gt; class linearOperator
{
 public:

  linearOperator() { weight_ = REAL(1); }

  virtual ~linearOperator() {}

  virtual void set_weight( REAL weight ){ weight_ = weight; }
  virtual REAL get_weight(){ return weight_; }

  virtual bool set_domain_dimensions( std::vector&lt;unsigned int&gt; *dims ) { ... }
  virtual bool set_codomain_dimensions( std::vector&lt;unsigned int&gt; *dims ) { ... }

  virtual boost::shared_ptr&lt; std::vector&lt;unsigned int&gt; &gt; 
    get_domain_dimensions() { ... }

  virtual boost::shared_ptr&lt; std::vector&lt;unsigned int&gt; &gt; 
    get_codomain_dimensions() { ... }

  virtual int mult_M( ARRAY_TYPE* in, ARRAY_TYPE* out, bool accumulate = false) = 0;
  virtual int mult_MH( ARRAY_TYPE* in, ARRAY_TYPE* out, bool accumulate = false) = 0;
  virtual int mult_MH_M( ARRAY_TYPE* in, ARRAY_TYPE* out, bool accumulate = false) = 0;
  
  virtual boost::shared_ptr&lt; linearOperator&lt; REAL, ARRAY_TYPE &gt; &gt; clone() = 0;

  ...
};</programlisting>The <classname>linearOperator</classname> is templated by
        two arguments: 1) the basic precision <classname>REAL</classname>
        (<classname>e.g. float</classname> or <classname>double</classname>)
        and 2) the <classname>ARRAY_TYPE</classname> (e.g.
        <classname>NDArray&lt;T&gt;</classname>,
        <classname>hoNDArray&lt;T&gt;</classname>, or
        <classname>cuNDArray&lt;T&gt;</classname>) representing the expected
        vector format for the matrix-vector multiplication the operator
        implements.</para>

        <para>Every <classname>MatrixOperator</classname> has an associated
        weight that is used to balance multiple matrix terms when added to a
        cost function (see <xref linkend="sect.linear_solvers"/>).</para>

        <para>The main functionality is provided in the three pure virtual
        functions, <function>mult_M</function>, <function>mult_MH</function>,
        and <function>mult_MH_M</function>, denoting multiplication with the
        matrix operator (<varname>M</varname>), multiplication with the
        adjoint (i.e. conjugate transpose) of the matrix operator
        (<varname>M<superscript>H</superscript></varname>), and an "iteration"
        of the two respectively
        (<varname>M<superscript>H</superscript>M</varname>).</para>

        <para>The <classname>clone</classname> method is required by some
        solvers to make a clone (copy) of a given
        <classname>linearOperator</classname>. Similarly, some solvers require
        knowledge of the <varname>domain</varname> and
        <varname>codomain</varname> dimensions on which the operator can be
        applied. The <classname>mult_M</classname> method converts the input
        vector of <varname>domain_size</varname> to one of
        <varname>codomain_size</varname> - and vice versa for
        <classname>mult_MH</classname>.</para>

        <para>The <classname>linearOperator</classname> is used to model a
        linear imaging modality's encodig operation (Fourier transform for
        MRI, Radon transform for CT, convolution for Microscopy etc.) but also
        common regularization operators such the identity matrix, the partial
        derivatives etc.</para>

        <para>Here follows a list that briefly describes the linear operators
        that are used for the reconstruction examples discussed later in this
        document (<xref linkend="sect.exampleapplications"/>, <xref
        linkend="sect.standalone_applications"/>).</para>

        <sect3>
          <title>List of linear operators</title>

          <para>The section provides a non-exhaustive list of availble linear
          operators in Gadgetron toolboxes.</para>

          <para>A two-level implementation strategy is used for most of the
          operators the Gadgetron provide. We first derive a class, say
          <classname>identityOperator</classname>, from the
          <classname>linearOperator</classname> base class. In this derived
          class we implement the pure virtual functions of the base class,
          e.g. <function>mult_M</function>, <function>mult_MH</function>, and
          <function>mult_MH_M</function>. The overall algorithm and
          functionality of the operator is implemented at this level. Like its
          superclass, the <classname>identityOperator</classname> is however
          templated on the underlying <classname>ARRAY_TYPE</classname> and
          thus cannot contain dedicated implementation code to a specific
          array implementation. The implementation of
          <function>mult_M</function>, <function>mult_MH</function>, and
          <function>mult_MH_M</function> is consequently based on a new set of
          pure virtual functions of the templated
          <classname>ARRAY_TYPE</classname>. We provide another level of
          inheritance, e.g. <classname>cuIdentityOperator</classname>, which
          in this case provides the <classname>cuNDArray</classname>-specific
          implementation of the pure virtual function in
          <classname>identityOperator</classname>. This hierachy has the
          desired design goal, that the core algorithm implementation is
          shared in the base class of the operator. Only the host/device
          specific sub-components are defined individually. It is thus fairly
          straightforward to derive both an <classname>cuNDArray</classname>
          and an <classname>hoNDArray</classname> version of an
          operator.</para>

          <para>As an example we provide a simplified declaration of the
          <classname>identityOperator</classname> and
          <classname>cuIdentityOperator</classname> below. Without specific
          mentioning for the subsequent operators, many follow a similar
          inheritance hierachy.</para>

          <itemizedlist>
            <listitem>
              <para><classname>identityOperator</classname></para>

              <para>Implements multiplication of a vector with the identity
              matrix.</para>

              <para><programlisting>// Notice: simplified code without error-checking

template &lt;class REAL, class ARRAY_TYPE&gt; class identityOperator
 : public linearOperator&lt;REAL, ARRAY_TYPE&gt;
{
 public:

  identityOperator() : linearOperator&lt;REAL, ARRAY_TYPE&gt;() {}
  virtual ~identityOperator() {}
  
  // operator_xpy implements the sum x+y and stores the result in y
  virtual bool operator_xpy( ARRAY_TYPE *x, ARRAY_TYPE *y ) = 0;

  virtual int mult_M( ARRAY_TYPE *in, ARRAY_TYPE *out, 
                      bool accumulate = false )
  {
    if( accumulate )
      operator_xpy( in, out );
    else 
      *out = *in;
  }

  ... // Similar code for mul_MH and mult_MH_M
};

</programlisting><programlisting>// Notice: 
// Simplified code without error checking and multi-device support

template &lt;class REAL, class T&gt; 
class cuIdentityOperator 
: public identityOperator&lt; REAL, cuNDArray&lt;T&gt; &gt;
{
 public:

  cuIdentityOperator() : identityOperator&lt; REAL, cuNDArray&lt;T&gt; &gt;() {}
  virtual ~cuIdentityOperator() {}
  
  virtual bool operator_xpy( cuNDArray&lt;T&gt; *x, cuNDArray&lt;T&gt; *y )
  { 
    return cuNDA_axpy( T(1), x, y );
  }

 ...
};

</programlisting>Notice that the template arguments to the
              <classname>cuIdentitytOperator</classname> differ from its base
              class. <classname>REAL</classname> specifies the desired
              precision (<classname>float</classname> or
              <classname>double</classname>) and <classname>T</classname>
              specifies the desired type - which could be identical to
              <classname>REAL</classname> or e.g. a
              <classname>complext&lt;REAL&gt;</classname>. Also notice how the
              <classname>cuIdentitytOperator</classname> class definition
              directly specifies the ARRAY_TYPE of its superclass (in this
              case to be of type
              <classname>cuNDArray&lt;T&gt;</classname>).</para>
            </listitem>

            <listitem>
              <para><classname>partialDerivativeOperator</classname></para>

              <para>Provides the partial derivative of an image in a given
              spatial dimension.</para>
            </listitem>

            <listitem>
              <para><classname>laplaceOperator</classname></para>

              <para>Computes the Laplacian of an image.</para>
            </listitem>

            <listitem>
              <para><classname>imageOperator</classname></para>

              <para>Performs multiplication with a diagonal matrix of the
              element-wise reciprocal of a given image.</para>
            </listitem>

            <listitem>
              <para><classname>convolutionOperator</classname></para>

              <para>Performs convolution of an image with a given
              kernel.</para>
            </listitem>

            <listitem>
              <para><classname>nfftOperator</classname></para>

              <para>Implements the non-Cartesian Fast Fourier Transform</para>
            </listitem>

            <listitem>
              <para><classname>senseOperator</classname></para>

              <para>Implements the encoding operator for the parallel MRI
              imaging technique Sense. Comes in two flavours for 1) Cartesian
              and 2) non-Cartesian reconstruction.</para>
            </listitem>

            <listitem>
              <para><classname>encodingOperatorContainer</classname></para>

              <para>As we require exactly one encoding operator (but allow
              multiple regularization operators) to be added to our solvers
              (see <xref linkend="sect.linear_solvers"/> below), this operator
              acts as a container when multiple encoding operators are
              desired. For example: The cost function right below (<xref
              linkend="sect.cg_solver"/>) has two terms in its general form.
              Most often the vector <emphasis role="bold">p</emphasis> is
              <emphasis role="bold">0</emphasis> and consequently the operator
              <emphasis role="bold">R</emphasis> is considered a
              regularization operator while the operator <emphasis
              role="bold">E</emphasis> the single encoding operator. However,
              if <emphasis role="bold">p</emphasis> is non-zero, both
              <emphasis role="bold">E</emphasis> and <emphasis
              role="bold">R</emphasis> must be added to an
              <classname>encodingOperatorContainer</classname> that takes in
              both <emphasis role="bold">m</emphasis> and <emphasis
              role="bold">p</emphasis> during multiplication. A single
              <classname>encodingOperatorContainer</classname> is then added
              to the solver.</para>
            </listitem>
          </itemizedlist>
        </sect3>
      </sect2>

      <sect2 xml:id="sect.linear_solvers">
        <title>Linear Solvers</title>

        <para>The Gadgetron's solvers toolbox contains both a generic
        conjugate gradient solver to solve linear least squares reconstruction
        problems (see <xref linkend="sect.linear_solvers"/> ) and a two
        flavors of a Split Bregman solver for non-linear problems using
        l1-norms for regularization (see <xref
        linkend="sect.nonlinear_solvers"/>). More solvers can be expected in
        upcoming releases.</para>

        <sect3 xml:id="sect.cg_solver">
          <title>Conjugate Gradient Method for Linear Least Squares</title>

          <para>The conjugate gradient solver is used to reconstruct an image
          posed as a minimizer to an l2-based optimization problem:</para>

          <informalequation>
            <mediaobject>
              <imageobject role="html">
                <imagedata fileref="figs/math/lls.jpg" format="JPEG"
                           width="3in"/>
              </imageobject>

              <imageobject role="fo">
                <imagedata fileref="figs/math/lls.jpg" format="JPEG"
                           width="3in"/>
              </imageobject>
            </mediaobject>
          </informalequation>

          <para>The unknown image to be reconstructed is denoted here by
          <emphasis role="bold">u</emphasis> and the measured data by
          <emphasis role="bold">m</emphasis>. <emphasis
          role="bold">E</emphasis> is a linear operator modelling the encoding
          of the imaging modality (e.g. a Fourier transform for MRI, a Radon
          transform for CT etc.). <emphasis role="bold">R</emphasis> is a
          regularization operator often required to ensure uniqueness of the
          solution. Lambda is a scalar weight (with a default value of one)
          associated to each matrix operator and used to balance the various
          terms in the cost function. Finally <emphasis
          role="bold">p</emphasis> denotes some (possibly blank) prior image
          in the regularization term. Any number of terms can be added.</para>

          <para>The closed form solution to the optimization problem is given
          by the linear system of equations:</para>

          <informalequation>
            <mediaobject>
              <imageobject role="html">
                <imagedata fileref="figs/math/lls_form.jpg" format="JPEG"
                           width="3in"/>
              </imageobject>

              <imageobject role="fo">
                <imagedata fileref="figs/math/lls_form.jpg" format="JPEG"
                           width="3in"/>
              </imageobject>
            </mediaobject>
          </informalequation>

          <para>Put extremely short; you set up and run a solver by 1) adding
          the corresponding linear operators to the solver, and 2) invoking
          the <function>solve</function> function in the solver providing
          <emphasis role="bold">m</emphasis> (and <emphasis
          role="bold">p</emphasis> if non-zero) as input arguments.</para>

          <para>An abbreviated version of the interface to the conjugate
          gradient solver is shown here<programlisting>// Defined in solver.h

template &lt;class ARRAY_TYPE_IN, class ARRAY_TYPE_OUT&gt; class solver
{
public:

  // Constructor/destructor
  //

  solver() { output_mode_ = OUTPUT_SILENT; }
  virtual ~solver() {}
  
  // Output modes
  //

  enum solverOutputModes { OUTPUT_SILENT = 0, 
                           OUTPUT_WARNINGS = 1, 
                           OUTPUT_VERBOSE = 2, 
                           OUTPUT_MAX = 3 };
  
  // Set/get output mode
  //

  virtual int get_output_mode() { return output_mode_; }

  virtual void set_output_mode( int output_mode ) {
      output_mode_ = output_mode;
  }
  
  // Set/get starting solution/estimate for solver
  //

  virtual void set_x0( boost::shared_ptr&lt;ARRAY_TYPE_OUT&gt; x0 ){ x0_ = x0; }

  virtual boost::shared_ptr&lt;ARRAY_TYPE_OUT&gt; get_x0(){ return x0_; }

  // Default error output
  //

  virtual void solver_error( std::string msg ) { ... }

  // Default warning output
  //

  virtual void solver_warning( std::string msg ) { ... }

  // Invoke solver
  //

  virtual boost::shared_ptr&lt;ARRAY_TYPE_OUT&gt; solve( ARRAY_TYPE_IN* ) = 0;
 
protected:
  int output_mode_;
  boost::shared_ptr&lt;ARRAY_TYPE_OUT&gt; x0_;
};
</programlisting><programlisting>// Defined in cgSolver.h

template &lt;class REAL, class ELEMENT_TYPE, class ARRAY_TYPE&gt; class cgSolver 
  : public linearSolver&lt;REAL, ELEMENT_TYPE, ARRAY_TYPE&gt;
{
public:

  // Class defining the termination criterium
  //

  friend class cgTerminationCallback&lt;REAL,ELEMENT_TYPE,ARRAY_TYPE&gt;;

  // Constructor / destructor
  //

  cgSolver() : linearSolver&lt;REAL, ELEMENT_TYPE, ARRAY_TYPE&gt;() {...}
  virtual ~cgSolver() {}

  // Set preconditioner
  //

  virtual void set_preconditioner( 
    boost::shared_ptr&lt; cgPreconditioner&lt;ARRAY_TYPE&gt; &gt; precond ) {
      precond_ = precond;
  }
  
  // Set termination callback
  //

  virtual void set_termination_callback(
    boost::shared_ptr&lt; cgTerminationCallback&lt;REAL, ELEMENT_TYPE, ARRAY_TYPE&gt; &gt; cb ){
      cb_ = cb;
  }

  // Set/get maximally allowed number of iterations
  //

  virtual void set_max_iterations( unsigned int iterations ) { 
    iterations_ = iterations; }

  virtual unsigned int get_max_iterations() { return iterations_; }  

  // Set/get tolerance threshold for termination criterium
  //

  virtual void set_tc_tolerance( REAL tolerance ) { tc_tolerance_ = tolerance; }
  virtual REAL get_tc_tolerance() { return tc_tolerance_; }
  
  // Pre/post solver callbacks
  //

  virtual bool pre_solve( ARRAY_TYPE** ) { return true; }
  virtual bool post_solve( boost::shared_ptr&lt;ARRAY_TYPE&gt;&amp; ) { return true; }

  // Pure virtual functions defining core solver functionality
  // Implemented on the host/device respectively in a derived class
  //

  virtual ELEMENT_TYPE solver_dot( ARRAY_TYPE*, ARRAY_TYPE* ) = 0;
  virtual bool solver_clear( ARRAY_TYPE* ) = 0;
  virtual bool solver_scal( ELEMENT_TYPE, ARRAY_TYPE* ) = 0;
  virtual bool solver_axpy( ELEMENT_TYPE, ARRAY_TYPE*, ARRAY_TYPE* ) = 0;
  virtual bool solver_dump( ARRAY_TYPE* ) { return true; }

  //
  // Main solver interfaces
  //

  virtual boost::shared_ptr&lt;ARRAY_TYPE&gt; solve( ARRAY_TYPE *_d ) { ... }
  virtual boost::shared_ptr&lt;ARRAY_TYPE&gt; solve_from_rhs( ARRAY_TYPE *_rhs ) { ... }

  ...
};
</programlisting><programlisting>// Defined in cuCGSolver.h

template &lt;class REAL, class T&gt; class cuCgSolver 
  : public cgSolver&lt; REAL, T, cuNDArray&lt;T&gt; &gt;
{
public:

  cuCgSolver() : cgSolver&lt; REAL, T, cuNDArray&lt;T&gt; &gt;() { ... }
  virtual ~cuCgSolver() {}

  cuCGSolver() : cgSolver&lt; REAL, T, cuNDArray&lt;T&gt; &gt;() {}
  virtual ~cuCGSolver() {}

  virtual bool pre_solve(cuNDArray&lt;T&gt;**)
   { ... }

  virtual bool post_solve(cuNDArray&lt;T&gt;**)
   { ... }

  virtual void solver_error( std::string err )
   { ... }

  virtual T solver_dot( cuNDArray&lt;T&gt; *x, 
   cuNDArray&lt;T&gt; *y ){ ... }

  virtual bool solver_clear( cuNDArray&lt;T&gt; *x )
   { ... }

  virtual bool solver_scal( T a, 
   cuNDArray&lt;T&gt; *x ){ ... }

  virtual bool solver_axpy( T a, cuNDArray&lt;T&gt; *x, 
   cuNDArray&lt;T&gt; *y ){ ... }

  ...
};</programlisting>The overall inheritance hierachy is modelled and
          implemented similarly to the <classname>linearOperator</classname>
          class hierachy described above (see <xref
          linkend="sect.matrix_operators"/>). To use the solver the user
          creates an instance of the solver for either the host or device
          (e.g. the <classname>cuCGSolver</classname> above for a GPU-based
          solver). The solver is configured using the functions in the
          <classname>cgSolver</classname> base class. The core solve function
          itself is found in the root of the hierachy; the
          <classname>solver</classname>.</para>

          <para>Note that any number of terms (linear operators) can be added
          to the solver (or cost function).</para>

          <para>The following code listing provides a short example of how to
          define a conjugate gradient solver for GPU-based image deblurring
          given an image and an estimate of the point spread function that
          degraded the image. It uses the
          <classname>convolutionOperator</classname> to model the blurring and
          a <classname>partialDerivativeOperator</classname> in each spatial
          dimension for regularization. The full code can be found in
          <envar>$(GADGETRON_SOURCE)</envar><filename>/apps/standalone/gpu/deblurring/2d/deblur_2d_cg.cpp</filename>.<programlisting>{
  &lt;&lt; Code that parses the command line 
     and loads the image and kernel from disk &gt;&gt;

  // Define the desired precision
  typedef float _real; 
  typedef complext&lt;_real&gt;::Type _complext;

  // Upload host data to device
  cuNDArray&lt;_complext&gt; data(host_data.get());
  cuNDArray&lt;_complext&gt; kernel(host_kernel.get());
    
  // Setup regularization operators

  boost::shared_ptr&lt; cuPartialDerivativeOperator&lt;_real,_complext,2&gt; &gt; 
    Rx( new cuPartialDerivativeOperator&lt;_real,_complext,2&gt;(0) ); 

  boost::shared_ptr&lt; cuPartialDerivativeOperator&lt;_real,_complext,2&gt; &gt; 
    Ry( new cuPartialDerivativeOperator&lt;_real,_complext,2&gt;(1) ); 

  Rx-&gt;set_weight( lambda );
  Ry-&gt;set_weight( lambda );
     
  //
  // Setup conjugate gradients solver
  //

  // Define encoding matrix
  boost::shared_ptr&lt; cuConvolutionOperator&lt;_real,2&gt; &gt; 
    E( new cuConvolutionOperator&lt;_real,2&gt;() );

  E-&gt;set_kernel( &amp;kernel );
  E-&gt;set_domain_dimensions(data.get_dimensions().get());
    
  // Setup conjugate gradient solver
  cuCGSolver&lt;_real, _complext&gt; cg;

  // encoding matrix
  cg.set_encoding_operator( E );

  // regularization matrix                   
  if( kappa&gt;0.0 ) cg.add_reuglarization_operator( Rx );
  
  // regularization matrix
  if( kappa&gt;0.0 ) cg.add_regularization_operator( Ry ); 

  cg.set_max_iterations( num_iterations );
  cg.set_tc_tolerance( 1e-8 );
  cg.set_output_mode( cuCGSolver&lt;_real, _complext&gt;::OUTPUT_VERBOSE );
                
  //
  // Conjugate gradient solver
  //
  
  boost::shared_ptr&lt; cuNDArray&lt;_complext&gt; &gt; cgresult = cg.solve(&amp;data);

  // All done, write out the result
  
  boost::shared_ptr&lt; hoNDArray&lt;_complext&gt; &gt; 
    host_result = cgresult-&gt;to_host();
  
  write_nd_array&lt;_complext&gt;(host_result.get(), 
    (char*)parms.get_parameter('r')-&gt;get_string_value());
}</programlisting></para>

          <para>For an overview of the various standalone applications the
          Gadgetron provides - and instruction on how to run them - we refer
          to <xref linkend="sect.standalone_applications"/>.</para>
        </sect3>
      </sect2>

      <sect2 xml:id="sect.nonlinear_solvers">
        <title>Non-linear Solvers</title>

        <sect3>
          <title>Split Bregman Solver for L1-regularized Problems</title>

          <para>The Gadgetron includes two Split Bregman solvers to solve
          respectively</para>

          <informalequation>
            <mediaobject>
              <imageobject role="html">
                <imagedata fileref="figs/math/sb.jpg" format="JPEG"
                           width="3in"/>
              </imageobject>

              <imageobject role="fo">
                <imagedata fileref="figs/math/sb.jpg" format="JPEG"
                           width="3in"/>
              </imageobject>
            </mediaobject>
          </informalequation>

          <para>where |.|<subscript>TV</subscript> denotes the Total Variation
          norm. The solver to the upper (unconstraint) optimization problem is
          defined in <filename>sbSolver.h</filename> while the solver to the
          latter constraint problem declared in
          <filename>sbcSolver.h</filename>. The Split Bregman solver was
          chosen as it integrates nicely with the linear conjugate solver
          desribed above (<xref linkend="sect.linear_solvers"/>). In fact,
          most of the work in the two Split Bregman solvers is performed by a
          linear inner solver (e.g. a conjugate gradient solver), but the
          input (right hand side) to the inner solver varies from iteration to
          iteration.</para>

          <para>The interface to the unconstraint Split Bregman solver is
          given here. We have seen the overall inheritance hierachy several
          times already, so it should suffice to provide only very abbreviated
          headers here:<programlisting>// Defined in sbSolver.h


template&lt; class REAL, 
          class ELEMENT_TYPE, 
          class ARRAY_TYPE_REAL, 
          class ARRAY_TYPE_ELEMENT, 
          class INNER_SOLVER,
          class OPERATOR_CONTAINER &gt; class sbSolver 

 : public linearSolver&lt;REAL, ELEMENT_TYPE, ARRAY_TYPE_ELEMENT&gt;
{
public:

  // Constructor
  //

  sbSolver() : linearSolver&lt;REAL, ELEMENT_TYPE, ARRAY_TYPE_ELEMENT&gt;() 
   { ... }
  
  // Destructor
  //

  virtual ~sbSolver() {}
   

  // Add regularization group operator 
  // (isotropic, multiple operators per group allowed)
  //

  virtual bool add_regularization_group_operator( 
    boost::shared_ptr&lt; linearOperator&lt;REAL, ARRAY_TYPE_ELEMENT&gt; &gt; op ) 
  { ... }

  // Add isotroic regularization group (multiple groups allowed)
  //

  virtual bool add_group() { ... }

  // Get regularization group operator
  //
 
  &lt; omitted for brevity&gt;
  
  // Set/get prior image (PICCS style). 
  // I.e. for every regularization operator (group) R that is added we minimize:
  // alpha|R(x-prior)|_{l1} + (1-alpha)|R(x)|_{l1}
  //

  virtual bool set_prior_image( 
    boost::shared_ptr&lt;ARRAY_TYPE_ELEMENT&gt; prior, REAL alpha )
  { ... }
 
  // Get the prior image and corresponding weighing factor
  //
  
  virtual boost::shared_ptr&lt;ARRAY_TYPE_ELEMENT&gt; get_prior_image() 
    { return prior_; }

  virtual REAL get_prior_alpha() { return alpha_; }


  // Set termination criterium tolerance
  //

  virtual void set_tc_tolerance( REAL tolerance ) 
  { ... }

  // Set/get maximum number of outer Split-Bregman iterations
  //

  virtual void set_max_outer_iterations( 
    unsigned int iterations ) { outer_iterations_ = iterations; }
 
  virtual unsigned int get_max_outer_iterations() { 
    return outer_iterations_; }

  // Set/get maximum number of inner Split-Bregman iterations
  //

  virtual void set_max_inner_iterations( 
    unsigned int iterations ) { inner_iterations_ = iterations; }

  virtual unsigned int get_max_inner_iterations() 
   { return inner_iterations_; }

  // Get the inner solver
  //

  virtual boost::shared_ptr&lt;INNER_SOLVER&gt; get_inner_solver() 
   { return inner_solver_; }
  

  // Core solver functionality to be implemented
  // in a derived class (host/device specific implementations)
  //

  virtual bool solver_clear_real( ARRAY_TYPE_REAL* ) = 0;

  virtual bool solver_clear_element( ARRAY_TYPE_ELEMENT* ) = 0;

  virtual bool solver_sqrt( ARRAY_TYPE_REAL* ) = 0;

  virtual bool solver_scal( ELEMENT_TYPE, 
                            ARRAY_TYPE_ELEMENT* ) = 0;

  virtual bool solver_axpy_real( REAL, ARRAY_TYPE_REAL*, 
                                 ARRAY_TYPE_REAL* ) = 0;

  virtual bool solver_axpy_element( ELEMENT_TYPE, 
                                    ARRAY_TYPE_ELEMENT*, 
                                    ARRAY_TYPE_ELEMENT* ) = 0;

  virtual REAL solver_asum( ARRAY_TYPE_ELEMENT* ) = 0;

  virtual boost::shared_ptr&lt;ARRAY_TYPE_REAL&gt; solver_abs
    ( ARRAY_TYPE_ELEMENT* ) = 0;

  virtual boost::shared_ptr&lt;ARRAY_TYPE_REAL&gt; solver_norm
    ( ARRAY_TYPE_ELEMENT* ) = 0;

  virtual bool solver_shrink1( REAL, ARRAY_TYPE_ELEMENT*, 
                               ARRAY_TYPE_ELEMENT* ) = 0;

  virtual bool solver_shrinkd( REAL, ARRAY_TYPE_REAL*, 
                               ARRAY_TYPE_ELEMENT*, 
                               ARRAY_TYPE_ELEMENT* ) = 0;

  //
  // Main solver interface
  //

  virtual boost::shared_ptr&lt;ARRAY_TYPE_ELEMENT&gt; solve
   ( ARRAY_TYPE_ELEMENT *f ) { ... }

 ...
};
</programlisting><programlisting>// Defined in cuSbCgSolver.h

template &lt;class REAL, class T&gt; class cuSbCgSolver 
  : public sbSolver&lt; REAL, T, cuNDArray&lt;REAL&gt;, 
                     cuNDArray&lt;T&gt;, cuCgSolver&lt;REAL,T&gt;, 
                     cuEncodingOperatorContainer&lt;REAL,T&gt; &gt;
{
public:
  
  cuSbCgSolver() : sbSolver&lt; REAL, T, cuNDArray&lt;REAL&gt;, 
                             cuNDArray&lt;T&gt;, cuCgSolver&lt;REAL,T&gt;, 
                             cuEncodingOperatorContainer&lt;REAL,T&gt; &gt;() 
  { ... }
  
  virtual ~cuSbCgSolver() {}

  // Implementation of pure virtual functions
  ...
};</programlisting></para>

          <para>To run the algorithm on the GPU the user would create an
          instance of a <classname>cuSbCgSolver</classname> providing the two
          template arguments; the desired precision and data type. Prior to
          running the <function>solve</function> function with the measured
          data <emphasis role="bold">m</emphasis>, the user should provide 1)
          the encoding operator, 2) the regularization operators, and 3) the
          desired domain and codomain dimensions as these cannot in general be
          deduced from the measured data.</para>

          <para>We outline the code required to set up the solver for TV-based
          image denoising. The full code can be found in
          <envar>$(GADGETRON_SOURCE)</envar><filename>/apps/standalone/gpu/denoising/2d/denoise_TV.cpp</filename>.<programlisting>{
  &lt;&lt; Command line parsing and data loading &gt;&gt;
  
  //
  // Setup regularization operators
  // 

  boost::shared_ptr&lt; cuPartialDerivativeOperator&lt;_real,_real,2&gt; &gt; 
    Rx( new cuPartialDerivativeOperator&lt;_real,_real,2&gt;(0) ); 

  boost::shared_ptr&lt; cuPartialDerivativeOperator&lt;_real,_real,2&gt; &gt; 
    Ry( new cuPartialDerivativeOperator&lt;_real,_real,2&gt;(1) ); 

  Rx-&gt;set_weight( lambda );
  Rx-&gt;set_domain_dimensions(data.get_dimensions().get());
  Rx-&gt;set_codomain_dimensions(data.get_dimensions().get());

  Ry-&gt;set_weight( lambda );
  Ry-&gt;set_domain_dimensions(data.get_dimensions().get());
  Ry-&gt;set_codomain_dimensions(data.get_dimensions().get());

  // Define encoding operator (identity)
  boost::shared_ptr&lt; cuIdentityOperator&lt;_real,_real&gt; &gt; 
    E( new cuIdentityOperator&lt;_real,_real&gt;() );

  E-&gt;set_weight( mu );
  E-&gt;set_domain_dimensions(data.get_dimensions().get());
  E-&gt;set_codomain_dimensions(data.get_dimensions().get());

  // Setup split-Bregman solver
  //

  cuSbCgSolver&lt;_real,_real&gt; sb;

  sb.set_encoding_operator( E );

  sb.add_regularization_group_operator( Rx );
  sb.add_regularization_group_operator( Ry);
  sb.add_group();

  sb.set_max_outer_iterations(num_outer_iterations);
  sb.set_max_inner_iterations(num_inner_iterations);

  sb.set_output_mode( cuCgSolver&lt;_real,_real&gt;::OUTPUT_VERBOSE );
  
  // Setup inner conjugate gradient solver
  //

  sb.get_inner_solver()-&gt;set_max_iterations
   ( num_cg_iterations );
  sb.get_inner_solver()-&gt;set_tc_tolerance( 1e-4 );
  sb.get_inner_solver()-&gt;set_output_mode
   ( cuCgSolver&lt;_real,_real&gt;::OUTPUT_WARNINGS );  

  //
  // Run split-Bregman solver
  //

  boost::shared_ptr&lt; cuNDArray&lt;_real&gt; &gt; 
   sbresult = sb.solve(&amp;data);

  &lt;&lt; do something with the result &gt;&gt;
}</programlisting></para>

          <para>The constrained Split Bregman solver inherits from the
          unconstaint Split Bregman solver is thus defined with an identical
          interface.</para>
        </sect3>
      </sect2>

      <sect2>
        <title>HDF5</title>

        <para>The Gadgetron framework uses HDF5 files for storing raw data and
        reconstructed images. Please see <xref linkend="section.hdf5"/> for a
        simple overview of the HDF5 file format.</para>

        <para xlink:href="http://www.hdfgroup.org/HDF5/">The HDF5 file format
        has a well defined C/C++ interface as described on the HDF5 website:
        <uri
        xlink:href="http://www.hdfgroup.org/HDF5/">http://www.hdfgroup.org/HDF5/</uri>.
        The Gadgetron has two toolboxes (<filename>hdf5utils</filename> and
        <filename>hdf5mri</filename>) that wrap this C/C++ interface and make
        it easy to add different types of data to datasets.</para>

        <para xlink:href="http://www.hdfgroup.org/HDF5/">The main functions
        for accessing HDF5 files are:</para>

        <para xlink:href="http://www.hdfgroup.org/HDF5/"><programlisting>template &lt;class T&gt; int hdf5_append_array(hoNDArray&lt;T&gt;* a,
              const char* filename, const char* varname);

template &lt;class T&gt; boost::shared_ptr&lt; hoNDArray&lt;T&gt; &gt; 
              hdf5_read_array_slice(
              const char* filename, const char* varname, 
              unsigned int index = 0);

template &lt;class T&gt; int hdf5_append_struct(T* s,
              boost::shared_ptr&lt;DataType&gt; datatype,
              const char* filename, const char* varname);

template &lt;class T&gt; boost::shared_ptr&lt;T&gt; hdf5_read_struct(
              boost::shared_ptr&lt;DataType&gt; structdatatype, 
              const char* filename, const char* varname,
              unsigned int index = 0);</programlisting>The first two functions
        are used to append and read <classname>hoNDArray</classname>
        structures. The templated functions are implemented for
        <classname>hoNDArrray</classname>s with types
        <classname>float</classname>, <classname>char</classname>,
        <classname>std::complex&lt;float&gt;</classname>, and
        <classname>unsigned short</classname>. The functions rely on templated
        functions to define the HDF5 datatypes corresponding to a given
        datatype in the <classname>hoNDArray</classname>. In order to add
        support for an additional type, the user must implement a template
        specialization of a function, which returns the HDF5 datatype for a
        given type in the C++ code. For example, to implement support for
        <classname>float</classname>, the following code is used:</para>

        <para xlink:href="http://www.hdfgroup.org/HDF5/"><programlisting>
/**
 *   Base class template for returning HDF5 data type
 */
template &lt;class T&gt; boost::shared_ptr&lt;DataType&gt; getHDF5Type();

//Specialization
template &lt;&gt; boost::shared_ptr&lt;DataType&gt; getHDF5Type&lt;float&gt;()
{
  boost::shared_ptr&lt;DataType&gt; 
      ret(new DataType(H5Tcopy(H5T_NATIVE_FLOAT)));

  return ret;
}
</programlisting>The last two of the interface functions are used for adding
        and reading generic structs. The word struct in the function name is a
        reminder that the object supllied with the pointer <parameter>T*
        s</parameter> should be layed out in memory so that it can be written
        directly to the file with the standard HDF5 function, i.e. it cannot
        be a class with dynamically allocate members, etc. Typically this
        function is used to read and write image and data headers to the HDF5
        files.</para>

        <para xlink:href="http://www.hdfgroup.org/HDF5/">The
        <filename>hdf5mri</filename> toolbox contains some specializations for
        the MRI specific datatypes (<xref linkend="sect.mridatastructures"/>).
        The specific MRI datatypes are defined in the HDF5 format using
        specific template specializations in a similar fashing to the types
        for the <classname>hoNDArray</classname>. Additionally the MRI
        specific toolbox has wrapper functions that will append a struct and
        an <classname>hoNDArray</classname> simultaneously. Specifically, it
        will create a new struct which contains both the struct (typically a
        header) and the array and then append that new struct to the file. The
        functions for using this functionality are defined as:</para>

        <para xlink:href="http://www.hdfgroup.org/HDF5/"><programlisting>
template &lt;class STRUCT, class DATATYPE&gt; 
int hdf5_append_struct_with_data(STRUCT* s,
hoNDArray&lt;DATATYPE&gt;* a, const char* filename, const char* varname);


template &lt;class STRUCT, class DATATYPE&gt; struct header_data_struct
{
  boost::shared_ptr&lt;STRUCT&gt; h;
  boost::shared_ptr&lt; hoNDArray&lt;DATATYPE&gt; &gt; d;
};

template &lt;class STRUCT, class DATATYPE&gt; 
 header_data_struct&lt;STRUCT, DATATYPE&gt;
 hdf5_read_struct_with_data(const char* filename, 
                            const char* varname, 
                            unsigned index = 0);
</programlisting>There are several usage examples in the
        <command>mriclient</command> code. For example, to read an MRI
        acquisiton (header and data) from a HDF5 file, the client uses the
        following code:</para>

        <para xlink:href="http://www.hdfgroup.org/HDF5/"><programlisting>
header_data_struct&lt;GadgetMessageAcquisition, 
                  std::complex&lt;float&gt; &gt; acquisition;

{
  HDF5Exclusive lock; //This will ensure threadsafe access to HDF5

  acquisition = 
    hdf5_read_struct_with_data&lt; GadgetMessageAcquisition, 
                                std::complex&lt;float&gt; &gt;
         (hdf5_in_data_file, hdf5_data_varname.c_str(), i); 
         //i is a loop variable over MRI acquisitions
}

....

//To access header struct (GadgetMessageAcquisition):
acquisition.h.get();

//To access data (hoNDArray)
acquisition.d.get();</programlisting>For examples of how to write images to an
        HDF5 file, see <filename>HDF5ImageWriter.h</filename> in
        <filename>apps/clients/mriclient</filename>.</para>
      </sect2>
    </sect1>

    <sect1>
      <title>Gadgetron Gadgets</title>

      <para>Gadgets wrap the functionality of the toolboxes and provide
      generic building blocks for configuring the streaming reconstruction in
      the Gadgetron.</para>

      <sect2 xml:id="sect.mrigadgets">
        <title>MRI Gadgets</title>

        <para>One of the original motivations for creating the Gadgetron was
        to make a high throughput MRI reconstruction engine that could be
        interfaced to different MRI vendor systems. Consequently, a lot of the
        functionality present in the initial release toolboxes and Gadgets is
        focused on MRI reconstruction. In this section we review the basic
        data structures used to describe MRI data and list some of the MRI
        Gadgets that are available. These Gadgets are used in several of the
        example applications in <xref
        linkend="sect.exampleapplications"/>.</para>

        <sect3 xml:id="sect.mridatastructures">
          <title>MRI Data Structures</title>

          <para>MRI data is processed in two different phases. In the first
          phase individual data (k-space) acquisitions are processed while in
          the second phase these acquisitions have been combined into images
          (which may still be in k-space). Correspondingly, there are two
          different types of Gadgets that dominate the MRI Gadgets; those who
          operate on individual acquisitions and those who operate on images.
          Naturally, there are also transitional Gadgets that operate on
          acquisitions but output images.</para>

          <para>All MRI Gadgets inherit from <classname>Gadget2</classname> as
          described in <xref linkend="sect.gadgets"/>, i.e. they operate on
          two argument types, the main two base classes used are:</para>

          <programlisting>Gadget2&lt; GadgetMessageAcquisition, hoNDArray&lt; std::complex&lt;float&gt; &gt; &gt;
Gadget2&lt; GadgetMessageImage, hoNDArray&lt; std::complex&lt;float&gt; &gt; &gt;</programlisting>

          <para>As seen, they take a data array (which is typically of complex
          float type) and a header describing either the acquisition or the
          image. These headers are defined in
          <filename>GadgetMRIHeaders.h</filename>. The definition of
          <classname>GadgetMessageAcquisition</classname> looks like
          (abbreviated):</para>

          <programlisting>struct LoopCounters {
  ACE_UINT16 acquisition;
  ACE_UINT16 slice;
  ACE_UINT16 partition;
  ACE_UINT16 echo;
  ACE_UINT16 phase;
  ACE_UINT16 repetition;
  ACE_UINT16 set;
  ACE_UINT16 segment;
  ACE_UINT16 channel;
};

struct GadgetMessageAcquisition
{
  ACE_UINT32     flags;
  ACE_UINT32     meas_uid;
  ACE_UINT32     scan_counter;
  ACE_UINT32     time_stamp;
  ACE_UINT16     samples;
  ACE_UINT16     channels;
  float          position[3];
  float          quarternion[4];
  float          table_position;
  LoopCounters   idx;
  LoopCounters   min_idx;
  LoopCounters   max_idx;
};</programlisting>

          <para>It is a simple struct, which mainly serves the purpose of
          keeping track of a) the encoding properties of a given acquisition
          (phase ending number, etc.) and b) the spatial position and
          orientation that the data was acquired from. Different MRI systems
          have different conventions for how to label data, but in most cases
          one would be able to convert to this format.</para>

          <para>The <classname>GadgetMessageImage</classname> data structure
          is also just a struct for keeping track of image labels, position,
          and orientation:</para>

          <programlisting>struct GadgetMessageImage
{
  ACE_UINT32     flags;
  ACE_UINT16     matrix_size[3];
  ACE_UINT16     channels;
  float          position[3];
  float          quarternion[4];
  float          table_position;
  LoopCounters   data_idx_min;
  LoopCounters   data_idx_max;
  LoopCounters   data_idx_current;
  ACE_UINT32     time_stamp;
  ACE_UINT16     image_format;
  ACE_UINT16     image_type;
  ACE_UINT16     image_index;
  ACE_UINT16	    image_series_index;
}; </programlisting>

          <para/>
        </sect3>

        <sect3>
          <title>List of available MRI Gadgets</title>

          <para>This section contains a non-exhaustive list of available MRI
          Gadgets with a few brief comments on their function. The purpose is
          to make it easier to read the XML configuration files provided with
          the Gadgetron and to give some ideas of what modules can be reused
          in new reconstruction programs.</para>

          <itemizedlist>
            <listitem>
              <para><classname>AccumulatorGadget</classname>
              (<filename>gadgetroncore</filename>):</para>

              <para>Simple Gadget for accumulating k-space profiles in an
              array and passing it on to next Gadget. Used for simple
              Cartesian FT MRI reconstructions.</para>
            </listitem>

            <listitem>
              <para><classname>AutoScaleGadget</classname>
              (<filename>gadgetroncore</filename>):</para>

              <para>Does simple histogram analysis of floating point images
              passing through and scales them. This is typically used upstream
              of conversion from floating point to unsigned short
              images.</para>
            </listitem>

            <listitem>
              <para><classname>CoilReductionGadget</classname>
              (<filename>gadgetroncore</filename>):</para>

              <para>Used to reduce the number of coils in a dataset. Typically
              used to tune the performance of a given reconstruction by
              eliminating data. This Gadget is commonly used in conjunction
              with the <classname>PCACoilGadget</classname> which generates
              virtual coils based on principal component analysis. The coil
              reduction can be specified with either a mask or the number of
              target coils as illustrated below</para>

              <programlisting>&lt;gadget&gt;
 &lt;name&gt;CoilReduction&lt;/name&gt;
 &lt;dll&gt;gadgetroncore&lt;/dll&gt;
 &lt;class&gt;CoilReductionGadget&lt;/class&gt;
 &lt;!-- Keep a max of 16 coils --&gt;
 &lt;property&gt;&lt;name&gt;coils_out&lt;/name&gt;&lt;value&gt;16&lt;/value&gt;&lt;/property&gt;
&lt;/gadget&gt;

&lt;gadget&gt;
 &lt;name&gt;CoilReduction&lt;/name&gt;
 &lt;dll&gt;gadgetroncore&lt;/dll&gt;
 &lt;class&gt;CoilReductionGadget&lt;/class&gt;
 &lt;!-- Keep only coil 2,3,4,5 and discard the rest--&gt;
 &lt;property&gt;
  &lt;name&gt;coil_mask&lt;/name&gt;
  &lt;value&gt;0 1 1 1 0 0 0 0&lt;/value&gt;
 &lt;/property&gt;
&lt;/gadget&gt;
</programlisting>
            </listitem>

            <listitem>
              <para><classname>CropAndCombineGadget</classname>
              (<filename>gadgetroncore</filename>):</para>

              <para>This Gadget is used to do a simple RMS coil combination in
              the image domain and remove 2x oversampling in the first
              dimension of the image as is commonly used in MRI. This Gadget
              is intended to be used after FFT of the data.</para>
            </listitem>

            <listitem>
              <para><classname>ExtractGadget</classname>
              (<filename>gadgetroncore</filename>):</para>

              <para>This Gadget is used to extract a given component
              (magnitude, real, imaginary, phase) from complex images, i.e. it
              converts complex images to real images containing specific
              components. The Gadget can be used to extract multiple
              components using a mask. The bit fields used to define the
              components are defined as:</para>

              <programlisting>#define GADGET_EXTRACT_MAGNITUDE              (1 &lt;&lt; 0) //1
#define GADGET_EXTRACT_REAL                   (1 &lt;&lt; 1) //2
#define GADGET_EXTRACT_IMAG                   (1 &lt;&lt; 2) //4
#define GADGET_EXTRACT_PHASE                  (1 &lt;&lt; 3) //8
</programlisting>

              <para>To specify the components, you just specify the mask, for
              example, the following specification would extract magnitude (1)
              and phase (8):</para>

              <programlisting>&lt;gadget&gt;
 &lt;name&gt;Extract&lt;/name&gt;
 &lt;dll&gt;gadgetroncore&lt;/dll&gt;
 &lt;class&gt;ExtractGadget&lt;/class&gt;
 &lt;property&gt;&lt;name&gt;extract_mask&lt;/name&gt;&lt;value&gt;9&lt;/value&gt;&lt;/property&gt;
&lt;/gadget&gt;
</programlisting>

              <para>Default behavior is to extract magnitude.</para>
            </listitem>

            <listitem>
              <para><classname>FFTGadget</classname>
              (<filename>gadgetroncore</filename>):</para>

              <para>This Gadget Fourier transforms along the first 3
              dimensions of the dataset (frequency, phase, partition encoding
              directions) and passes on the data to the next Gadget.</para>
            </listitem>

            <listitem>
              <para><classname>FloatToUShortGadget</classname>
              (<filename>gadgetroncore</filename>):</para>

              <para>Converts floating point images to unsigned short images.
              This Gadget would often be used in conjunction with a scaling
              step (e.g. <classname>AutoScaleGadget</classname>) upstream to
              ensure that the values will not get clipped or overflow during
              the conversion to unsigned short. This Gadget does not make any
              attempt to scale the data, it is assumed to be scaled upon
              entry.</para>
            </listitem>

            <listitem>
              <para><classname>GPUCGGoldenRadial</classname>,
              <classname>GPUCGFixedRadial</classname>
              (<filename>gadgetroncgsense</filename>):</para>

              <para>These Gadgets perform conjugate gradient based
              non-Cartesian SENSE reconstruction (<xref
              linkend="sect.cgsense"/>). The reconstruction behavior can be
              controlled with number of properties:</para>

              <programlisting>&lt;gadget&gt;
 &lt;name&gt;GPUCGRadial0&lt;/name&gt;
 &lt;dll&gt;gadgetroncgsense&lt;/dll&gt;
 &lt;class&gt;GPUCGGoldenRadialGadget&lt;/class&gt;

 &lt;property&gt;
  &lt;name&gt;deviceno&lt;/name&gt;
  &lt;value&gt;0&lt;/value&gt;
 &lt;/property&gt;
 
 &lt;property&gt;
  &lt;name&gt;sliceno&lt;/name&gt;
  &lt;value&gt;0&lt;/value&gt;
 &lt;/property&gt;
 
 &lt;property&gt;
  &lt;name&gt;profiles_per_frame&lt;/name&gt;
  &lt;value&gt;32&lt;/value&gt;
 &lt;/property&gt;
 
 &lt;property&gt;
  &lt;name&gt;shared_profiles&lt;/name&gt;
  &lt;value&gt;0&lt;/value&gt;
 &lt;/property&gt;

 &lt;property&gt;
  &lt;name&gt;number_of_iterations&lt;/name&gt;
  &lt;value&gt;10&lt;/value&gt;
 &lt;/property&gt;

 &lt;property&gt;
  &lt;name&gt;cg_limit&lt;/name&gt;
  &lt;value&gt;1e-6&lt;/value&gt;
 &lt;/property&gt;

 &lt;property&gt;
  &lt;name&gt;oversampling&lt;/name&gt;
  &lt;value&gt;1.5&lt;/value&gt;
 &lt;/property&gt;

 &lt;property&gt;
  &lt;name&gt;kernel_width&lt;/name&gt;
  &lt;value&gt;5.5&lt;/value&gt;
 &lt;/property&gt;

 &lt;property&gt;
  &lt;name&gt;kappa&lt;/name&gt;
  &lt;value&gt;0.1&lt;/value&gt;
 &lt;/property&gt;

 &lt;property&gt;
  &lt;name&gt;pass_on_undesired_data&lt;/name&gt;
  &lt;value&gt;true&lt;/value&gt;
 &lt;/property&gt;

&lt;/gadget&gt;
</programlisting>
            </listitem>

            <listitem>
              <para><classname>GrappaGadget</classname>,
              <classname>GrappaUnmixingGadget</classname>
              (<filename>gadgetrongrappa</filename>):</para>

              <para>These Gadgets are used together to perform 2D Cartesian
              parallel imaging on the GPU. The
              <classname>GrappaGadget</classname> is responsible for
              calculating GRAPPA coefficients and the
              <classname>GrappeUnmixingGadget</classname> Fourier transforms
              the raw data and applies the coefficients. The
              <classname>GrappaGadget</classname> has the ability to use
              target channel compression, i.e. it can reconstruct using fewer
              target channels than input channels to improve performance. See
              <xref linkend="sect.grappa"/> for details. The target channel
              compression is specificied like this:</para>

              <programlisting>&lt;gadget&gt;
 &lt;name&gt;Grappa&lt;/name&gt;
 &lt;dll&gt;gadgetrongrappa&lt;/dll&gt;
 &lt;class&gt;GrappaGadget&lt;/class&gt;
 &lt;property&gt;&lt;name&gt;target_coils&lt;/name&gt;&lt;value&gt;8&lt;/value&gt;&lt;/property&gt;
&lt;/gadget&gt;
</programlisting>
            </listitem>

            <listitem>
              <para><classname>ImageFinishGadgetSHORT</classname>,
              <classname>ImageFinishFLOAT</classname>,
              <classname>ImageFinishCPLX</classname>
              (<filename>gadgetroncore</filename>):</para>

              <para>These 3 Gadgets are all template instances of the same
              <classname>ImageFinishGadget</classname>. The only different
              between them is that they operate on different types of image
              data types as indicated by their names. Their purpose is to
              return the reconstructed images to the output queue of the
              Gadgetron so that they can be returned to the client.</para>
            </listitem>

            <listitem>
              <para><classname>MRINoiseAdjustGadget</classname>
              (<filename>gadgetronmricore</filename>):</para>

              <para>The Gadgetron has two noise pre-whitening Gadgets with
              similar names <classname>MRINoiseAdjustGadget</classname> and
              <classname>NoiseAdjustGadget</classname>. They both perform the
              same operation, which is a) to collect noise adjust data when
              present, calculate the noise decorrelation matrix, and perform
              noise decorrelation (when the noise adjustment data is
              available). The difference between the two Gadgets is that
              <classname>MRINoiseAdjustGadget</classname> uses BLAS and LAPACK
              routines to perform the operation, which makes it much faster
              than the <classname>NoiseAdjustGadget</classname>. The latter
              Gadget is provided to enable reconstruction on systems where
              those libraries are not available.</para>
            </listitem>

            <listitem>
              <para><classname>NoiseAdjustGadget</classname>
              (<filename>gadgetroncore</filename>):</para>

              <para>See description of
              <classname>MRINoiseAdjustGadget</classname>.</para>
            </listitem>

            <listitem>
              <para><classname>PCACoilGadget</classname>
              (<filename>gadgetronmricore</filename>):</para>

              <para>This Gadget is used to create virtual channels based on
              principal component analysis of a portion of the data.
              Specifically, data is accumulated for the first frame (for each
              location, i.e. slice) and a principal component analysis is done
              of this data. Once the PCA coefficients are available, all
              subsequent data will be transformed into the virtual channel
              domain and passed on down the Gadget chain. This Gadget is often
              combined with the
              <classname>CoilReductionGadget</classname>.</para>
            </listitem>

            <listitem>
              <para><classname>RemoveROOversamplingGadget</classname>
              (<filename>gadgetroncore</filename>):</para>

              <para>Removes the 2x oversampling often used in the readout
              direction for (Cartesian) MRI.</para>
            </listitem>
          </itemizedlist>
        </sect3>
      </sect2>

      <sect2>
        <title>Python Gadgets</title>

        <para>The Gadgetron provides a mechanism to do prototype development
        in Python. Again, we use MRI as the example application.</para>

        <para>The Python layer is accessed through a set of Python Gadgets
        that can encapsulate a Python module. This is seen in <xref
        linkend="fig.pythonoverview"/>, which illustrates a part of a Gadget
        chain with two Python Gadgets and one C/C++ Gadget. A Gadget chain can
        have any number of Python Gadgets and Python Gadgets can be mixed with
        C++ Gadgets.</para>

        <figure xml:id="fig.pythonoverview">
          <title>Overview of Python Prototyping</title>

          <mediaobject>
            <imageobject>
              <imagedata fileref="figs/python.png" format="PNG" width="5in"/>
            </imageobject>
          </mediaobject>
        </figure>

        <para>The Python modules that are encapsulated in the Python Gadgets
        are expected to have certain characteristics. Specifically, the
        Gadgets must have at least 3 functions and these functions will be
        called by the Gadgetron framework at certain specific times:</para>

        <orderedlist>
          <listitem>
            <para><emphasis>Gadget reference function</emphasis>. A specific
            function will be called when the Python Gadget is created. This
            function is expected to receive a
            <classname>GadgetReference</classname> which is a class (wrapped
            in a Python module), which holds a reference to the Gadget, which
            owns the Python module. The purpose of passing this reference is
            to allow the Python module to return data to the Gadget when
            reconstruction outputs are ready. See below for details.</para>
          </listitem>

          <listitem>
            <para><emphasis>Configuration function</emphasis>. This function
            is used to receive the configuration (usually in XML format), when
            it is passed to the Gadget, i.e. it is the Python equivalent of
            <function>process_config</function> in the Gadget (see <xref
            linkend="sect.gadgets"/>).</para>
          </listitem>

          <listitem>
            <para><emphasis>Reconstruction function</emphasis>. This function
            is called when the Gadget receives data, i.e. it is the Python
            equivalent of the <function>process</function> function in the
            Gadget (see <xref linkend="sect.gadgets"/>).</para>
          </listitem>
        </orderedlist>

        <para>The user can chose the names of these functions freely in the
        Python module, but the function names must be specified when the
        Gadget is inserted in the XML configuration:</para>

        <programlisting>&lt;gadget&gt;
 &lt;name&gt;AccReconPython&lt;/name&gt;
 &lt;dll&gt;gadgetronpython&lt;/dll&gt;
 &lt;class&gt;AcquisitionPythonGadget&lt;/class&gt;

 &lt;property&gt;
  &lt;name&gt;python_path&lt;/name&gt;
  &lt;value&gt;/home/myuser/scripts/python&lt;/value&gt;
 &lt;/property&gt;

 &lt;property&gt;
  &lt;name&gt;python_module&lt;/name&gt;
  &lt;value&gt;accumulate_and_recon&lt;/value&gt;
 &lt;/property&gt;

 &lt;property&gt;
  &lt;name&gt;gadget_reference_function&lt;/name&gt;
  &lt;value&gt;set_gadget_reference&lt;/value&gt;
 &lt;/property&gt;

 &lt;property&gt;
  &lt;name&gt;input_function&lt;/name&gt;
  &lt;value&gt;recon_function&lt;/value&gt;
 &lt;/property&gt;

 &lt;property&gt;
  &lt;name&gt;config_function&lt;/name&gt;
  &lt;value&gt;config_function&lt;/value&gt;
 &lt;/property&gt;
&lt;/gadget&gt;

</programlisting>

        <para>Notice how the 3 function names are specified through the
        <varname>gadget_reference_function</varname>,
        <varname>input_function</varname>, and
        <varname>config_function</varname> parameter names. Also notice that
        it is possible to specify a <varname>python_path</varname> to let the
        Python interpreter know where to search for script. By default, the
        <filename>gadgetron/lib</filename> is added to the search path.
        Multiple pathnames can be added by separating the paths with
        "<filename>;</filename>".</para>

        <para>The Python script referenced in the XML configuration above
        could look like this:</para>

        <programlisting>import numpy as np
import GadgetronPythonMRI as g
import GadgetronXML
import kspaceandimage as ki

myRef = g.GadgetReference()
myBuffer = 0
myParameters = 0
myCounter = 1;
mySeries = 1;

def set_gadget_reference(gadref):
    global myLocalGadgetReference
    myLocalGadgetReference = gadref

def config_function(conf):
    global myBuffer
    global myParameters
    myParameters =  GadgetronXML.getEncodingParameters(conf)
    myBuffer = (np.zeros((myParameters["channels"], \
                myParameters["slices"], \
                myParameters["matrix_z"], \
                myParameters["matrix_y"], \
                myParameters["matrix_x"]))).astype('complex64')

def recon_function(acq, data):
    global myLocalGadgetReference
    global myBuffer
    global myParameters
    global myCounter
    global mySeries

    line_offset = (myParameters["matrix_y"] - \
                   myParameters["phase_encoding_lines"])&gt;&gt;1
  
    myBuffer[:,acq.idx.slice, \
             acq.idx.partition,acq.idx.line+line_offset,:] = data
    
    if (acq.flags &amp; (1&lt;&lt;1)): #Is this the last scan in slice
        #FFT
        image = ki.ktoi(myBuffer,(2,3,4))

        #Create a new image header and transfer value
        img_head = g.GadgetMessageImage()
        img_head.channels = acq.channels
        img_head.data_idx_curent = acq.idx
        img_head.data_idx_max = acq.max_idx
        img_head.data_idx_min = acq.min_idx
        img_head.set_matrix_size(0,myBuffer.shape[4])
        img_head.set_matrix_size(1,myBuffer.shape[3])
        img_head.set_matrix_size(2,myBuffer.shape[2])
        img_head.set_matrix_size(3,myBuffer.shape[1])
        img_head.set_position(0,acq.get_position(0))
        img_head.set_position(1,acq.get_position(1))
        img_head.set_position(2,acq.get_position(2))
        img_head.set_quarternion(0,acq.get_quarternion(0))
        img_head.set_quarternion(1,acq.get_quarternion(1))
        img_head.set_quarternion(2,acq.get_quarternion(2))
        img_head.set_quarternion(3,acq.get_quarternion(3))
        img_head.table_position = acq.table_position
        img_head.time_stamp = acq.time_stamp
        img_head.image_index = myCounter;
        img_head.image_series_index = mySeries;


        #Return image to Gadgetron
        return myRef.return_image(img_head,image.astype('complex64'))

        #print "Returning to Gadgetron"
        return 0 #Everything OK

</programlisting>

        <para>There is a lot going on in this script. Let us walk through the
        different parts and add some explanation. First look at the
        imports:</para>

        <programlisting>import numpy as np
import GadgetronPythonMRI as g
import GadgetronXML
import kspaceandimage as ki</programlisting>

        <para>All the Python Gadget modules must include
        <filename>numpy</filename>. The arrays
        (<classname>NDArray</classname>) are passed to the Python module as
        <filename>numpy</filename> arrays. The second module
        <filename>GadgetronPythonMRI</filename> is a Python wrapped version of
        some of the data structures used in the MRI part of the Gadgetron (see
        <xref linkend="sect.mrigadgets"/>). Specifically, the
        <classname>GadgetMessageAcquisition</classname> and
        <classname>GadgetMessageImage</classname> headers are wrapped as
        Python types (using Boost Python). The
        <filename>GadgetronPythonMRI</filename> also contains a wrapped
        version of the <classname>GadgetReference</classname> class:</para>

        <programlisting>class GadgetReference
{

 public:
  GadgetReference();
  ~GadgetReference();
  
  int set_gadget(Gadget* g)
  {
    gadget_ = g;
    return 0;
  }

  template&lt;class T&gt; int return_data(T header, 
          boost::python::numeric::array arr);

  int return_acquisition(GadgetMessageAcquisition acq, 
          boost::python::numeric::array arr);

  int return_image(GadgetMessageImage img, 
          boost::python::numeric::array arr);

 protected:
  Gadget* gadget_;

};
</programlisting>

        <para>Using the return functions in this class interface, it is
        possible for the Python module to return data to the Gadget.
        <filename>GadgetronXML</filename> is a Python module provided with the
        Gadgetron, which contains some XML helper functions that can (it is
        not a requirement) be used to parse the XML parameters that the module
        will receive from <function>process_config</function>.
        <filename>kspaceandimage</filename> is also a python module provided
        with the Gadgetron, it contains some simple wrapper functions for
        performing Fourier transforms (to and from k-space) of MRI data. The
        following section contains some initialization of global variables in
        the Python module;</para>

        <programlisting>myRef = g.GadgetReference()
myBuffer = 0
myParameters = 0
myCounter = 1;
mySeries = 1;</programlisting>

        <para>As described above, each Python module must contain at least 3
        functions corresponding to the 3 entry points from the Gadgetron
        framework. The first one of these functions captures the
        <classname>GadgetReference</classname>:</para>

        <programlisting>def set_gadget_reference(gadref):
    global myLocalGadgetReference
    myLocalGadgetReference = gadref
</programlisting>

        <para>Using this reference, the Python module will be able to return
        images (or acquisitions) to the Gadget. The next function processes
        the configuration data:</para>

        <programlisting>def config_function(conf):
    global myBuffer
    global myParameters
    myParameters =  GadgetronXML.getEncodingParameters(conf)
    myBuffer = (np.zeros((myParameters["channels"], \
                myParameters["slices"], \
                myParameters["matrix_z"], \
                myParameters["matrix_y"], \
                myParameters["matrix_x"]))).astype('complex64')
</programlisting>

        <para>The <filename>GadgetronXML</filename> module is used to parse
        some simple encoding parameters out of the XML configuration and they
        are stored in a convenient data structure for later reference. The
        <function>config_function</function> function also initializes a
        buffer for the data.</para>

        <para>Finally the <function>recon_function</function> (not repeated
        here) simply takes the data as it comes it and stores it in a buffer.
        Based on the <varname>flags</varname> field in the header, it is
        determined when the last acquisition in each slice has arrived. As
        this happens the buffer is Fourier transformed, an image header is
        populated, and the result is returned (via the
        <classname>GadgetReference</classname>) to the Gadgetron where it will
        be processed by the next Gadget in the chain.</para>

        <para>The Gadgetron distribution comes with a simple Python-based 2D
        FT MRI reconstruction. The Gadget chain configuration for this
        reconstruction can be found in
        <filename>gadgets/python/python.xml</filename>.</para>
      </sect2>

      <sect2 xml:id="sect.makingnewgadgetlibrary">
        <title>Making a new Gadget Library</title>

        <para>The easiest way to get started making a new Gadget library is to
        follow an example. In this example we create a new Gadget library
        containing a single Gadget; <classname>ThresholdGadget</classname>.
        Its purpose is to set all values below a certain fraction of the max
        value to zero.</para>

        <para>New Gadget libraries can either be created in the Gadgetron
        source tree, which allows easy access to all the other files in the
        Gadgetron, or they can be made as external libraries that link against
        an installed Gadgetron system. In this example we do the latter since
        this creates a new library that does not "taint" the Gadgetron source
        tree. It is trivial to move the library inside the Gadgetron source
        tree at some later point in time if desired. We assume that the
        Gadgetron is installed on the machine that you are working on. The
        command line entries, etc. correspond to a Linux console. If you are
        using Windows you have to adjust a bit.</para>

        <para>Start by creating a new folder for the library:</para>

        <screen><prompt>user@mycomputer:~/temp$</prompt> <userinput>mkdir gadgetron_examplelib</userinput>
user@mycomputer:~/temp$ <userinput>cd gadgetron_examplelib</userinput></screen>

        <para>We start by creating the class
        <classname>ThresholdGadget</classname>. Create the following 3 files:
        <filename>ThresholdGadget.h</filename>,
        <filename>ThresholdGadget.cpp</filename>,
        <filename>examplelib_export.h</filename> (the last file is just to
        help us make sure that things work on Windows) with the following
        content:</para>

        <programlisting>//ThresholdGadget.h

#ifndef THRESHOLDGADGET_H
#define THRESHOLDGADGET_H

#include "examplelib_export.h"
#include "Gadget.h"
#include "GadgetMRIHeaders.h"
#include "hoNDArray.h"
#include &lt;complex&gt;

class EXPORTGADGETSEXAMPLE ThresholdGadget : 
public Gadget2&lt;GadgetMessageImage, hoNDArray&lt; std::complex&lt;float&gt; &gt; &gt;
{
 public:
  GADGET_DECLARE(ThresholdGadget)

 protected:
  virtual int process( GadgetContainerMessage&lt; GadgetMessageImage&gt;* m1,
       GadgetContainerMessage&lt; hoNDArray&lt; std::complex&lt;float&gt; &gt; &gt;* m2);

  virtual int process_config(ACE_Message_Block* mb);

  float threshold_level_;

};

#endif //THRESHOLDGADGET_H</programlisting>

        <programlisting>//ThresholdGadget.cpp

#include "ThresholdGadget.h"

int ThresholdGadget::process_config(ACE_Message_Block* mb) 
{
  threshold_level_ = get_double_value("level");
  if (threshold_level_ == 0.0) {
    threshold_level_ = 1.0;
  }

  return GADGET_OK;
}

int ThresholdGadget::process( 
   GadgetContainerMessage&lt; GadgetMessageImage&gt;* m1,
   GadgetContainerMessage&lt; hoNDArray&lt; std::complex&lt;float&gt; &gt; &gt;* m2)
{

  std::complex&lt;float&gt;* d = 
    m2-&gt;getObjectPtr()-&gt;get_data_ptr();

  unsigned long int elements =  
    m2-&gt;getObjectPtr()-&gt;get_number_of_elements();

  //First find max
  float max = 0.0;
  for (unsigned long int i = 0; i &lt; elements; i++) {
    if (abs(d[i]) &gt; max) {
      max = abs(d[i]);
    }
  }

  //Now threshold
  for (unsigned long int i = 0; i &lt; elements; i++) {
    if (abs(d[i]) &lt; threshold_level_*max) {
      d[i] = std::complex&lt;float&gt;(0.0,0.0);
    }
  }

  //Now pass on image
  if (this-&gt;next()-&gt;putq(m1) &lt; 0) {
     return GADGET_FAIL;
  }

  return GADGET_OK;
}

GADGET_FACTORY_DECLARE(ThresholdGadget)</programlisting>

        <programlisting>//examplelib_export.h

#ifndef EXAMPLE_EXPORT_H_
#define EXAMPLE_EXPORT_H_


#if defined (WIN32)
#if defined (gadgetronexamplelib_EXPORTS)
#define EXPORTGADGETSEXAMPLE __declspec(dllexport)
#else
#define EXPORTGADGETSEXAMPLE __declspec(dllimport)
#endif
#else
#define EXPORTGADGETSEXAMPLE
#endif

#endif /* EXAMPLE_EXPORT_H_ */
</programlisting>

        <para>Now that we have the files for the Gadget we need to set up the
        build environment. In the folder
        <filename>gadgetron_examplelib</filename> create a file called
        <filename>CMakeLists.txt</filename> with the following content:</para>

        <programlisting>cmake_minimum_required(VERSION 2.6)

project(examplelib)

if (WIN32)
ADD_DEFINITIONS(-DWIN32 -D_WIN32 -D_WINDOWS)
ADD_DEFINITIONS(-DUNICODE -D_UNICODE)
SET (CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} /EHsc")
SET (CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} /W3")
endif (WIN32)

###############################################################
#Bootstrap search for libraries 
# (We need to find cmake modules in Gadgetron)
###############################################################
find_path(GADGETRON_CMAKE_MODULES FindGadgetron.cmake HINTS
$ENV{GADGETRON_HOME}/cmake
/usr/local/gadgetron)

if (NOT GADGETRON_CMAKE_MODULES)
  MESSAGE(FATAL_ERROR "GADGETRON_CMAKE_MODULES cannot be found. 
   Try to set GADGETRON_HOME environment variable.")
endif(NOT GADGETRON_CMAKE_MODULES)

set(CMAKE_MODULE_PATH ${GADGETRON_CMAKE_MODULES})
###############################################################

find_package(Gadgetron REQUIRED)
find_package(Boost REQUIRED)
find_package(ACE REQUIRED)

set(CMAKE_INSTALL_PREFIX ${GADGETRON_HOME})

INCLUDE_DIRECTORIES(${ACE_INCLUDE_DIR} 
     ${Boost_INCLUDE_DIR}
     ${GADGETRON_INCLUDE_DIR})

LINK_DIRECTORIES(${GADGETRON_LIB_DIR})

ADD_LIBRARY(gadgetronexamplelib SHARED ThresholdGadget.cpp)

TARGET_LINK_LIBRARIES(gadgetronexamplelib 
                      hondarray 
                      optimized ${ACE_LIBRARIES} 
                      debug ${ACE_DEBUG_LIBRARY})

INSTALL (FILES	ThresholdGadget.h
         examplelib_export.h
         DESTINATION include)

INSTALL(TARGETS gadgetronexamplelib DESTINATION lib)

INSTALL(FILES threshold.xml DESTINATION config)
</programlisting>

        <para>The last thing we need is the XML configuration file to use when
        running our new <classname>ThresholdGadget</classname>. In the same
        folder create the <filename>threshold.xml</filename> file:</para>

        <programlisting>&lt;?xml version="1.0" ?&gt;  
&lt;gadgetron&gt;
  &lt;readers&gt;
    &lt;reader&gt;
      &lt;slot&gt;1001&lt;/slot&gt;
      &lt;dll&gt;gadgetroncore&lt;/dll&gt;
      &lt;class&gt;MRIAcquisitionReader&lt;/class&gt;
    &lt;/reader&gt;
  &lt;/readers&gt;
  
  &lt;writers&gt;
    &lt;writer&gt;
      &lt;slot&gt;1005&lt;/slot&gt;
      &lt;dll&gt;gadgetroncore&lt;/dll&gt;
      &lt;class&gt;MRIImageWriterFLOAT&lt;/class&gt;
    &lt;/writer&gt;
  &lt;/writers&gt;
  
  &lt;stream&gt;
    &lt;gadget&gt;
      &lt;name&gt;Acc&lt;/name&gt;
      &lt;dll&gt;gadgetroncore&lt;/dll&gt;
      &lt;class&gt;AccumulatorGadget&lt;/class&gt;
    &lt;/gadget&gt;

    &lt;gadget&gt;
      &lt;name&gt;FFT&lt;/name&gt;
      &lt;dll&gt;gadgetroncore&lt;/dll&gt;
      &lt;class&gt;FFTGadget&lt;/class&gt;
    &lt;/gadget&gt;

    &lt;gadget&gt;
      &lt;name&gt;CropCombine&lt;/name&gt;
      &lt;dll&gt;gadgetroncore&lt;/dll&gt;
      &lt;class&gt;CropAndCombineGadget&lt;/class&gt;
    &lt;/gadget&gt;

    &lt;!-- This is where we insert our new Gadget --&gt;
    &lt;gadget&gt;
      &lt;name&gt;Threshold&lt;/name&gt;
      &lt;dll&gt;gadgetronexamplelib&lt;/dll&gt;
      &lt;class&gt;ThresholdGadget&lt;/class&gt;
      &lt;property&gt;&lt;name&gt;level&lt;/name&gt;&lt;value&gt;0.25&lt;/value&gt;&lt;/property&gt;
    &lt;/gadget&gt;

    &lt;gadget&gt;
      &lt;name&gt;Extract&lt;/name&gt;
      &lt;dll&gt;gadgetroncore&lt;/dll&gt;
      &lt;class&gt;ExtractGadget&lt;/class&gt;
    &lt;/gadget&gt;

    &lt;gadget&gt;
      &lt;name&gt;ImageFinishFLOAT&lt;/name&gt;
      &lt;dll&gt;gadgetroncore&lt;/dll&gt;
      &lt;class&gt;ImageFinishGadgetFLOAT&lt;/class&gt;
    &lt;/gadget&gt;

   &lt;/stream&gt;

&lt;/gadgetron&gt;
</programlisting>

        <para>Check that you have 5 files in your folder:</para>

        <screen><prompt>user@mycomputer:gadgetron_examplelib$</prompt> <userinput>ls</userinput>
CMakeLists.txt
ThresholdGadget.cpp
ThresholdGadget.h
examplelib_export.h
threshold.xml
</screen>

        <para>Next, let us create a <filename>build</filename> directory and
        compile:</para>

        <screen><prompt>user@mycomputer:gadgetron_examplelib$</prompt> <userinput>mkdir build; cd build</userinput></screen>

        <para>In the <filename>build</filename> folder</para>

        <screen><prompt>user@mycomputer:build$</prompt> <userinput>cmake ../</userinput></screen>

        <para>Assuming the <application>cmake</application> process was
        successful:</para>

        <screen><prompt>user@mycomputer:build$</prompt> <userinput>make</userinput> 
Scanning dependencies of target gadgetronexamplelib

[100%] Building CXX object \
    CMakeFiles/gadgetronexamplelib.dir/ThresholdGadget.cpp.o

Linking CXX shared library libgadgetronexamplelib.dylib
[100%] Built target gadgetronexamplelib

<prompt>user@mycomputer:build$</prompt> <userinput>make install</userinput>
[100%] Built target gadgetronexamplelib
Install the project...
-- Install configuration: ""
-- Up-to-date: /usr/local/gadgetron/include/ThresholdGadget.h
-- Up-to-date: /usr/local/gadgetron/include/examplelib_export.h
-- Installing: /usr/local/gadgetron/lib/libgadgetronexamplelib.so
-- Up-to-date: /usr/local/gadgetron/config/threshold.xml</screen>

        <para>You may have to use <application>sudo</application> for the
        <command>make install</command> command depending on your
        setup.</para>

        <para>You should now be able to run a reconstruction using your new
        reconstruction chain. Follow the instructions in <xref
        linkend="sect.simpleexample"/> if you have not yet tried to run a
        simple reconstruction. After having started up the Gadgetron, run the
        <application>mriclient</application>:</para>

        <screen>user@mycomputer:~/temp/test_data$ <userinput>mriclient \
    -d gadgetron_testdata.h5 \ 
    -g simple_gre \ 
    -c threshold.xml</userinput>

Gadgetron MRI Data Sender
  -- host            :      localhost
  -- port            :      9002
  -- hdf5 file  in   :      gadgetron_testdata.h5
  -- hdf5 group in   :      simple_gre
  -- conf            :      theshold.xml
  -- loop            :      1
  -- hdf5 file out   :      ./out.h5
  -- hdf5 group out  :      2012-05-11 12:52:14
(31540|140170355443520) Connection from 127.0.0.1:9002
31540, 81, GadgetronConnector, Close Message received
(31540|140170283570944) Handling close...
(31540|140170283570944) svc done...
(31540|140170283570944) Handling close...</screen>

        <para>If you run it again with the <varname>level</varname> parameter
        set to 0.00000001 (remember to re-install the
        <filename>threshold.xml</filename> file in
        <filename>gadgetron/config</filename> by running <command>make
        install</command>):</para>

        <programlisting>    &lt;gadget&gt;
      &lt;name&gt;Threshold&lt;/name&gt;
      &lt;dll&gt;gadgetronexamplelib&lt;/dll&gt;
      &lt;class&gt;ThresholdGadget&lt;/class&gt;
      &lt;property&gt;&lt;name&gt;level&lt;/name&gt;&lt;value&gt;0.00000001&lt;/value&gt;&lt;/property&gt;
    &lt;/gadget&gt;
</programlisting>

        <para>You should get two different results that look something like
        <xref linkend="fig.examplelib"/>.</para>

        <figure xml:id="fig.examplelib">
          <title>Result from <classname>ThresholdGadget</classname>
          experiment</title>

          <mediaobject>
            <imageobject>
              <imagedata fileref="figs/examplelibresult.png" format="PNG"
                         width="6in"/>
            </imageobject>
          </mediaobject>
        </figure>

        <para>If you create interesting Gadget libraries please consider
        publishing them online to the benefit of the reconstruction community.
        An easy way to do this is by sending them to the Gadgetron team for us
        to publish right away on the web and possibly include in a future
        release of the Gadgetron.</para>
      </sect2>
    </sect1>

    <sect1>
      <title>Gadgetron Clients</title>

      <sect2>
        <title>Available Clients</title>

        <para>The purpose of this section is to maintain a list over the
        available clients that are included in the Gadgetron distribution. The
        current available clients are:</para>

        <itemizedlist>
          <listitem>
            <para><application>mriclient</application>:</para>

            <para>This is the standard client for sending MRI data to the
            Gadgetron. Two files are needed to send data to the Gadgetron; a
            data file and an XML file with parameters. The data file is just a
            flat file format of
            <classname>GadgetMessageAcquisition</classname> structs and raw
            data. In order to get usage information for the client, simply run
            the client with no arguments.</para>
          </listitem>
        </itemizedlist>
      </sect2>

      <sect2>
        <title>Making a new Client</title>

        <para>The Gadgetron distribution comes with a
        <classname>GadgetronConnector</classname> class, which can be used to
        create clients. An example <filename>main.cpp</filename> file for a
        client could look like:</para>

        <programlisting>
#include "GadgetMessageInterface.h"
#include "GadgetronConnector.h"

int main(int argc, char** argv)
{

  std::string host_name("localhost");
  std::string port("9002");
  std::string config_file("threshold.xml");
  std::string xml_config;

  //Generate some XML configuration in xml_fconfig

  GadgetronConnector con;

  //Register Readers and Writers
  con.register_writer(....);
  con.register_reader(....);
  con.register_reader(....);

  //Open a connection with the gadgetron
  if (con.open(hostname, port_no) != 0) {
    //Deal with errors
  }

  //Tell Gadgetron which XML configuration to run.
  if (con.send_gadgetron_configuration_file(config_file) != 0) {
    //Deal with errors
  }

  if (con.send_gadgetron_parameters(xml_config) != 0) {
     //Deal with errors
  }


  //Send data
  while ( .... ) { //some condition
    GadgetContainerMessage&lt;GadgetMessageIdentifier&gt;* m1 =
      new GadgetContainerMessage&lt;GadgetMessageIdentifier&gt;();
      
      //Create data and add to m1

      if (con.putq(m1) == -1) {
         //Deal with errors
      }
  }

  //Put a close package on the queue

  GadgetContainerMessage&lt;GadgetMessageIdentifier&gt;* m1 =
    new GadgetContainerMessage&lt;GadgetMessageIdentifier&gt;();

  m1-&gt;getObjectPtr()-&gt;id = GADGET_MESSAGE_CLOSE;

  if (con.putq(m1) == -1) {
   //Deal with errors
  }

  con.wait(); //Wait for recon to finish

  return 0;
}</programlisting>

        <para>To compile this client, create a
        <application>cmake</application> file:</para>

        <programlisting>cmake_minimum_required(VERSION 2.6)

project(exampleclient)

if (WIN32)
ADD_DEFINITIONS(-DWIN32 -D_WIN32 -D_WINDOWS)
ADD_DEFINITIONS(-DUNICODE -D_UNICODE)
SET (CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} /EHsc")
SET (CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} /W3")
endif (WIN32)

###############################################################
#Bootstrap search for libraries 
# (We need to find cmake modules in Gadgetron)
###############################################################
find_path(GADGETRON_CMAKE_MODULES FindGadgetron.cmake HINTS
$ENV{GADGETRON_HOME}/cmake
/usr/local/gadgetron)

if (NOT GADGETRON_CMAKE_MODULES)
  MESSAGE(FATAL_ERROR "GADGETRON_CMAKE_MODULES cannot be found. 
   Try to set GADGETRON_HOME environment variable.")
endif(NOT GADGETRON_CMAKE_MODULES)

set(CMAKE_MODULE_PATH ${GADGETRON_CMAKE_MODULES})
###############################################################

find_package(Gadgetron REQUIRED)
find_package(Boost REQUIRED)
find_package(ACE REQUIRED)

set(CMAKE_INSTALL_PREFIX ${GADGETRON_HOME})

INCLUDE_DIRECTORIES(${ACE_INCLUDE_DIR} 
     ${Boost_INCLUDE_DIR}
     ${GADGETRON_INCLUDE_DIR})

LINK_DIRECTORIES(${GADGETRON_LIB_DIR})

add_executable(mygadgetronclient main.cpp)

target_link_libraries(mygadgetronclient 
      optimized gadgettools debug gadgettools${CMAKE_DEBUG_SUFFIX}
      tinyxml 
      optimized ${ACE_LIBRARIES} debug ${ACE_DEBUG_LIBRARY})

install(TARGETS mygadgetronclient DESTINATION bin)
</programlisting>

        <para>Run <application>cmake</application> and follow the normal
        <command>make</command> and <command>make install</command>
        instructions (see <xref
        linkend="sect.makingnewgadgetlibrary"/>).</para>
      </sect2>
    </sect1>
  </chapter>

  <chapter xml:id="sect.exampleapplications">
    <title>Gadgetron Applications</title>

    <sect1 xml:id="sect.2dftexample">
      <title>Basic 2D FFT MRI</title>

      <para>A basic example application in the Gadgetron is a simple 2D FT MRI
      reconstruction. It receives 2D MRI data, collects it into k-space
      arrays, performs FFT of the data, combines channels (if there are
      multiple), and returns the images to the client. This example is
      included in the Gadgetron for testing and demonstration purposes only.
      It was not intended to be fast or otherwise optimal in any sense.</para>

      <para>The Gadgets for this reconstruction are in the
      <filename>core</filename> folder and the configuration file to use to
      run this reconstruction is <filename>default.xml</filename>. The section
      <xref linkend="sect.simpleexample"/> describes how to run a simple
      reconstruction using this Gadget chain and how to download data to test
      it.</para>

      <para>In this section we will take a closer look at the Gadgets in this
      chain and how they are implemented. The Gadgetron XML configuration file
      (<filename>default.xml</filename>) looks like this:</para>

      <programlisting>&lt;?xml version="1.0" ?&gt;  
&lt;gadgetron&gt;
  &lt;readers&gt;
    &lt;reader&gt;
      &lt;slot&gt;1001&lt;/slot&gt;
      &lt;dll&gt;gadgetroncore&lt;/dll&gt;
      &lt;class&gt;MRIAcquisitionReader&lt;/class&gt;
    &lt;/reader&gt;
  &lt;/readers&gt;
  
  &lt;writers&gt;
    &lt;writer&gt;
      &lt;slot&gt;1004&lt;/slot&gt;
      &lt;dll&gt;gadgetroncore&lt;/dll&gt;
      &lt;class&gt;MRIImageWriterCPLX&lt;/class&gt;
    &lt;/writer&gt;
    &lt;writer&gt;
      &lt;slot&gt;1005&lt;/slot&gt;
      &lt;dll&gt;gadgetroncore&lt;/dll&gt;
      &lt;class&gt;MRIImageWriterFLOAT&lt;/class&gt;
    &lt;/writer&gt;
    &lt;writer&gt;
      &lt;slot&gt;1006&lt;/slot&gt;
      &lt;dll&gt;gadgetroncore&lt;/dll&gt;
      &lt;class&gt;MRIImageWriterUSHORT&lt;/class&gt;
    &lt;/writer&gt;
  &lt;/writers&gt;

  &lt;stream&gt;
    &lt;gadget&gt;
      &lt;name&gt;Acc&lt;/name&gt;
      &lt;dll&gt;gadgetroncore&lt;/dll&gt;
      &lt;class&gt;AccumulatorGadget&lt;/class&gt;
    &lt;/gadget&gt;

    &lt;gadget&gt;
      &lt;name&gt;FFT&lt;/name&gt;
      &lt;dll&gt;gadgetroncore&lt;/dll&gt;
      &lt;class&gt;FFTGadget&lt;/class&gt;
    &lt;/gadget&gt;

    &lt;gadget&gt;
      &lt;name&gt;CropCombine&lt;/name&gt;
      &lt;dll&gt;gadgetroncore&lt;/dll&gt;
      &lt;class&gt;CropAndCombineGadget&lt;/class&gt;
    &lt;/gadget&gt;

    &lt;gadget&gt;
      &lt;name&gt;Extract&lt;/name&gt;
      &lt;dll&gt;gadgetroncore&lt;/dll&gt;
      &lt;class&gt;ExtractGadget&lt;/class&gt;
    &lt;/gadget&gt;
  
    &lt;gadget&gt;
      &lt;name&gt;ImageFinishFLOAT&lt;/name&gt;
      &lt;dll&gt;gadgetroncore&lt;/dll&gt;
      &lt;class&gt;ImageFinishGadgetFLOAT&lt;/class&gt;
    &lt;/gadget&gt;
   &lt;/stream&gt;
&lt;/gadgetron&gt;
</programlisting>

      <para>The resulting Gadget chain is illustrated in <xref
      linkend="fig.simple2dft"/>. As described in <xref
      linkend="sect.streamconfiguration"/> the Gadgetron configuration
      contains 3 sections: Readers, Writers, and the Stream. In this
      particular case, there is only one Reader, which received MRI
      Acquisitions. This data format is described in <xref
      linkend="sect.mrigadgets"/>. There are 3 Writers registered with this
      configuration. They are all used to write MRI images, but responsible
      for the different data types (complex float, float, or unsigned short).
      In principle this means that this reconstruction is capable of returning
      3 different types of images, but as is seen from the stream
      configuration, the only output from this reconstruction will be float
      format images. However, many reconstructions will have all 3 Writers
      registered to make it easy to switch formats, i.e. it would be trivial
      to turn this reconstruction into one that outputs unsigned short images
      (have a look at the file <filename>default_short.xml</filename>) for an
      example of how this is done.</para>

      <figure xml:id="fig.simple2dft">
        <title>Simple 2D FT Reconstruction Chain</title>

        <mediaobject>
          <imageobject>
            <imagedata fileref="figs/simple2dft.png" width="4in"/>
          </imageobject>
        </mediaobject>
      </figure>

      <para>As is seen in the <varname>stream</varname> section of the
      configuration, this reconstruction uses 5 Gadgets. The first Gadget is
      responsible for accumulating MRI acquisitions. To accomplish this, it
      uses an accumulation buffer. When a k-space line arrives at the Gadget,
      it will be inserted into the k-space buffer and when the last
      acquisition in a slice/repetition has arrived, it will copy the entire
      buffer and pass it on to the next Gadget.</para>

      <para>Let's have a look at the definition of the
      <classname>AccumulatorGadget</classname> class:</para>

      <programlisting>class EXPORTGADGETSCORE AccumulatorGadget : 
public Gadget2&lt; GadgetMessageAcquisition, 
                hoNDArray&lt; std::complex&lt;float&gt; &gt; &gt;
{
  
 public:
  GADGET_DECLARE(AccumulatorGadget);

  AccumulatorGadget();
  ~AccumulatorGadget();

 protected:
  virtual int process_config(ACE_Message_Block* mb);
  virtual int process(
    GadgetContainerMessage&lt; GadgetMessageAcquisition &gt;* m1,
    GadgetContainerMessage&lt; hoNDArray&lt; std::complex&lt;float&gt; &gt; &gt; * m2);

  hoNDArray&lt; std::complex&lt;float&gt; &gt;* buffer_;
  std::vector&lt;unsigned int&gt; dimensions_;

  int image_counter_;
  int image_series_;

};
</programlisting>

      <para>There are a few member variables to help us keep track of the
      buffer and the data dimensions and the core functionality is implemented
      in two functions: <function>process_config</function>, is used to set up
      the buffer, and <function>process</function>, which is responsible for
      the accumulation of data. Let us examine the
      <function>process_config</function> function:</para>

      <programlisting linenumbering="numbered">int AccumulatorGadget
::process_config(ACE_Message_Block* mb)
{

  TiXmlDocument doc;
  doc.Parse(mb-&gt;rd_ptr());

  GadgetXMLNode n =
   GadgetXMLNode(&amp;doc).get&lt;GadgetXMLNode&gt;(std::string("gadgetron"))[0];

  std::vector&lt;long&gt; dims =
   n.get&lt;long&gt;(std::string("encoding.kspace.matrix_size.value")); 

  if (dims.size() &lt; 3) {
   dims.push_back(0);
  }

  if (dims[2] == 0) {
    dims[2] = 1;
  }

  dimensions_.push_back(
   n.get&lt;long&gt;(std::string("encoding.kspace.readout_length.value"))[0]);
  dimensions_.push_back(dims[1]);
  dimensions_.push_back(dims[2]);
  dimensions_.push_back(
   n.get&lt;long&gt;(std::string("encoding.channels.value"))[0]);
  dimensions_.push_back(
   n.get&lt;long&gt;(std::string("encoding.slices.value"))[0]);


  if (!(buffer_ = new hoNDArray&lt; std::complex&lt;float&gt; &gt;())) {
   GADGET_DEBUG1("Failed create buffer\n");
   return GADGET_FAIL;
  }

  if (!buffer_-&gt;create(&amp;dimensions_)) {
   GADGET_DEBUG1("Failed allocate buffer array\n");
   return GADGET_FAIL;
  }

  image_series_ = this-&gt;get_int_value("image_series");

  return GADGET_OK;
}</programlisting>

      <para>The main purpose of this function is to pull parameters out of the
      XML configuration information in order to set up the buffer. As
      mentioned in <xref linkend="sect.xmlparameters"/>, the convention is to
      pass parameters into the Gadgets in XML format. To enable convenient
      parsing of these parameters, the Gadgetron includes the
      <filename>TinyXML</filename> library which can be used to parse the
      parameters directly or the <classname>TiXmlDocument</classname> can be
      used to create a <classname>GadgetXMLNode</classname>, which allows
      access to the parameters using the path description of the parameters.
      For example if part of the XML configuration information looks
      like:</para>

      <programlisting>&lt;gadgetron&gt;
    &lt;encoding&gt;
        &lt;kspace&gt;
            &lt;matrix_size&gt;
                &lt;value&gt;128&lt;/value&gt;
                &lt;value&gt;128&lt;/value&gt;
            &lt;/matrix_size&gt;
    &lt;/encoding&gt;
&lt;/gadgetron&gt;</programlisting>

      <para>The line</para>

      <programlisting>  std::vector&lt;long&gt; dims =
   n.get&lt;long&gt;(std::string("encoding.kspace.matrix_size.value")); 
</programlisting>

      <para>would cause <varname>dims</varname> to become a vector with two
      <classname>long</classname> values of 128, 128. In simple example, we
      have made some assumptions, i.e. our buffer always has the same number
      of dimensions, which is 5. Specifically the dimensions are [kx, ky, kz,
      channel, slice], to make sure that works out, we check if the number of
      dimensions is less than 3 (i.e. it is 2D) in which case we add a
      dimension.</para>

      <para>Next we want to create a <classname>hoNDArray</classname> (see
      <xref linkend="sect.ndarray"/>) to store the data. In order to be able
      to allocate the array we need a <classname>std::vector&lt;unsigned
      int&gt;</classname> to hold the dimensions of the array. We build the
      dimensions up based on the parameters in the XML file.</para>

      <para>After creating the dimensions vector, creation of the
      <classname>hoNDArray</classname> is a two-step process, first the class
      itself is allocated and then the <function>create</function> function is
      used to allocate the data inside the class.</para>

      <para>Now we are ready to receive and buffer data, which is done by the
      <function>process</function> function:</para>

      <programlisting>int AccumulatorGadget::
process(GadgetContainerMessage&lt;GadgetMessageAcquisition&gt;* m1,
 GadgetContainerMessage&lt; hoNDArray&lt; std::complex&lt;float&gt; &gt; &gt;* m2)
{

  //Create buffer if it doesn't exist
  if (!buffer_) {
   GADGET_DEBUG1("Buffer not allocated\n");
   return GADGET_FAIL;
  }


  //Grab pointers to buffer and data
  std::complex&lt;float&gt;* b =
   buffer_-&gt;get_data_ptr();

  std::complex&lt;float&gt;* d =
   m2-&gt;getObjectPtr()-&gt;get_data_ptr();

  int samples =  m1-&gt;getObjectPtr()-&gt;samples;
  int line = m1-&gt;getObjectPtr()-&gt;idx.line;
  int partition = m1-&gt;getObjectPtr()-&gt;idx.partition;
  int slice = m1-&gt;getObjectPtr()-&gt;idx.slice;

  //Does the data look OK?
  if (samples != static_cast&lt;int&gt;(dimensions_[0])) {
   GADGET_DEBUG1("Wrong number of samples received\n");
   return GADGET_FAIL;
  }

  //Copy the data into the buffer.
  size_t offset= 0;
  //Copy the data for all the channels
  for (int c = 0; c &lt; m1-&gt;getObjectPtr()-&gt;channels; c++) {
    offset = 
      slice*dimensions_[0]*dimensions_[1]*
      dimensions_[2]*dimensions_[3] +
      c*dimensions_[0]*dimensions_[1]*dimensions_[2] +
      partition*dimensions_[0]*dimensions_[1] +
      line*dimensions_[0];
    
    memcpy(b+offset,
     d+c*samples,
     sizeof(std::complex&lt;float&gt;)*samples);
  }
  
  //Use the flags to determine if this is the last acquisition
  bool is_last_scan_in_slice =
    (m1-&gt;getObjectPtr()-&gt;flags &amp; GADGET_FLAG_LAST_ACQ_IN_SLICE);
  
  if (is_last_scan_in_slice) {
    //OK, let's send out the k-space

    //Create header
    GadgetContainerMessage&lt;GadgetMessageImage&gt;* cm1 = 
      new GadgetContainerMessage&lt;GadgetMessageImage&gt;();
    
    cm1-&gt;getObjectPtr()-&gt;flags = 0;

    //Create the data array
    GadgetContainerMessage&lt; 
           hoNDArray&lt; std::complex&lt;float&gt; &gt; &gt;* cm2 = 
      new GadgetContainerMessage&lt;hoNDArray&lt; std::complex&lt;float&gt; &gt; &gt;();
    
    cm1-&gt;cont(cm2);
    
    std::vector&lt;unsigned int&gt; img_dims(4);
    img_dims[0] = dimensions_[0];
    img_dims[1] = dimensions_[1];
    img_dims[2] = dimensions_[2];
    img_dims[3] = dimensions_[3];
    

    //Allocate array
    if (!cm2-&gt;getObjectPtr()-&gt;create(&amp;img_dims)) {
      GADGET_DEBUG1("Unable to allocate new image array\n");
      cm1-&gt;release();
      return -1;
    }
    
    size_t data_length = dimensions_[0]*dimensions_[1]*
     dimensions_[2]*dimensions_[3];
    
    offset = slice*data_length;
    
    //Copy data
    memcpy(cm2-&gt;getObjectPtr()-&gt;get_data_ptr(),b+offset,
    sizeof(std::complex&lt;float&gt;)*data_length);
    
    //Populate image header
    cm1-&gt;getObjectPtr()-&gt;matrix_size[0]     = img_dims[0];
    cm1-&gt;getObjectPtr()-&gt;matrix_size[1]     = img_dims[1];
    cm1-&gt;getObjectPtr()-&gt;matrix_size[2]     = img_dims[2];
    cm1-&gt;getObjectPtr()-&gt;channels           = img_dims[3];
    cm1-&gt;getObjectPtr()-&gt;data_idx_min       = m1-&gt;getObjectPtr()-&gt;min_idx;
    cm1-&gt;getObjectPtr()-&gt;data_idx_max       = m1-&gt;getObjectPtr()-&gt;max_idx;
    cm1-&gt;getObjectPtr()-&gt;data_idx_current   = m1-&gt;getObjectPtr()-&gt;idx;	

    memcpy(cm1-&gt;getObjectPtr()-&gt;position,
     m1-&gt;getObjectPtr()-&gt;position,
     sizeof(float)*3);

    memcpy(cm1-&gt;getObjectPtr()-&gt;quarternion,
     m1-&gt;getObjectPtr()-&gt;quarternion,
     sizeof(float)*4);
 
    cm1-&gt;getObjectPtr()-&gt;table_position =
     m1-&gt;getObjectPtr()-&gt;table_position;

    cm1-&gt;getObjectPtr()-&gt;image_format = GADGET_IMAGE_COMPLEX_FLOAT;
    cm1-&gt;getObjectPtr()-&gt;image_index = ++image_counter_;
    cm1-&gt;getObjectPtr()-&gt;image_series_index = image_series_;

    //OK, pass it on
    if (this-&gt;next()-&gt;putq(cm1) &lt; 0) {
     return GADGET_FAIL;
    }
  } 

  //We are done with this acquisition
  m1-&gt;release();

  return GADGET_OK;
}
</programlisting>

      <para>This function has two basic tasks: insert data into the buffer and
      when enough data is present, copy the buffer and pass it on to next
      gadget.</para>

      <para>In this case the copying of data is done with a very simple
      <function>memcpy</function> command. There is a basic check for the
      image dimensions, but a more robust application may have more checks of
      the incoming data.</para>

      <para>Once the data is in the buffer, we check to see if we should put
      out an image. This is done with the <varname>flags</varname> field on
      the acquisition. Specifically we check if a specific bit
      (<varname>GADGET_FLAG_LAST_ACQ_IN_SLICE</varname>) is set. It is up to
      the user how the <varname>flags</varname> field should be interpreted,
      but the <filename>GadgetMRIHeaders.h</filename> file contains some
      definitions of flags that are used to indicate various events in the
      acquisition. If you define other flags for other Gadgets it may be a
      good idea to check that they don't collide with existing flags:</para>

      <programlisting>#define GADGET_FLAG_ACQ_END                   (1 &lt;&lt; 0)
#define GADGET_FLAG_LAST_ACQ_IN_SLICE         (1 &lt;&lt; 1)
#define GADGET_FLAG_LAST_ACQ_IN_MEAS          (1 &lt;&lt; 2)
#define GADGET_FLAG_LAST_ACQ_IN_CONCAT        (1 &lt;&lt; 3)
#define GADGET_FLAG_FIRST_ACQ_IN_SLICE        (1 &lt;&lt; 4)
#define GADGET_FLAG_FIRST_ACQ_IN_MEAS         (1 &lt;&lt; 5)
#define GADGET_FLAG_FIRST_ACQ_IN_CONCAT       (1 &lt;&lt; 6)
#define GADGET_FLAG_IS_NOISE_SCAN             (1 &lt;&lt; 7)
</programlisting>

      <para>If it is determined that this is the last acquisition for this
      slice, we create a copy of the buffer and pass it on to the next Gadget.
      Instead of a <classname>GadgetMessageAcquisition</classname> header we
      now need a <classname>GadgetMessageImage</classname> header to pass
      along with the data. This header structure is created and populated with
      fields (orientation, etc.) from the acquisition header before it is
      passed on to the Gadget in the stream.</para>

      <para>Next Gadget is the <classname>FFTGadget</classname>. Since the
      k-space buffering has been taken care of, the Fourier transform is a
      relatively simple task. The <function>process</function> function uses
      the FFTW wrapper class (<xref linkend="sect.ffttoolbox"/>) to perform
      the FFT along the first 3 dimensions of the array:</para>

      <programlisting>int FFTGadget::process( 
GadgetContainerMessage&lt; GadgetMessageImage&gt;* m1,
GadgetContainerMessage&lt; hoNDArray&lt; std::complex&lt;float&gt; &gt; &gt;* m2)
{
  FFT&lt;float&gt;::instance()-&gt;ifft(m2-&gt;getObjectPtr(),0);
  FFT&lt;float&gt;::instance()-&gt;ifft(m2-&gt;getObjectPtr(),1);
  FFT&lt;float&gt;::instance()-&gt;ifft(m2-&gt;getObjectPtr(),2);

  if (this-&gt;next()-&gt;putq(m1) &lt; 0) {
     return GADGET_FAIL;
  }

  return GADGET_OK;
}</programlisting>

      <para>Now that the images have been Fourier transformed, we need to
      remove the oversampling that is done in the readout dimensions and we
      need to combine the receiver channels. In this case, we are making some
      assumptions, i.e. we assume two-fold oversampling in the readout and we
      are doing a simple RMS coil combination to obtain combined magnitude
      images. We will not repeat the source code here, it can be found in
      <filename>gadgets/core/CropAndCombineGadget.cpp</filename>.</para>

      <para>Last two remaining steps after the coil combination is to extract
      the magnitude of the data and return the floating point images to the
      Gadgetron so that they can be returned to the client. This is
      accomplished in the <classname>ExtractGadget</classname> and the
      <classname>ImageFinishGadgetFLOAT</classname>. Both of these Gadgets are
      described in <xref linkend="sect.mrigadgets"/>.</para>
    </sect1>

    <sect1 xml:id="sect.grappa">
      <title>Cartesian 2D Parallel MRI (GRAPPA)</title>

      <para>The Gadgetron contains a high-throughput real-time 2D Cartesian
      parallel imaging reconstruction (GRAPPA) implemented on the GPU. It is
      beyond the scope of this manual to review all the algorithmic details of
      this application, but we will give an overview here as an example of a
      more complicated reconstruction chain.</para>

      <para>The Gadget chain is defined in the <filename>grappa.xml</filename>
      and the resulting chain is illustrated in <xref
      linkend="fig.grappachain"/>.</para>

      <para>To test this configuration, please download the GRAPPA test
      datasets from <uri type="website"
      xlink:href="https://sourceforge.net/projects/gadgetron/files/testdata/">https://sourceforge.net/projects/gadgetron/files/testdata/</uri>.
      In the MRI test data file <filename>gadgetron_testdata.h4</filename> you
      will find two test datasets <filename>gre_tgrappa_rate2</filename> and
      <filename>gre_tgrappa_rate4</filename>. They are Cartesian parallel
      imaging datasets with rate 2 and 4 acceleration respectively. They were
      acquired with a 32 channel coil.</para>

      <para>In order to run the GRAPPA reconstruction you have to have a CUDA
      enable GPU on your system and your Gadgetron distribution should be
      compiled with CUDA and CULA enabled. Please see <xref
      linkend="sect.installation"/> for details for your specific
      platform.</para>

      <para>To run the reconstruction, start up your Gadgetron (in its own
      terminal window) and use the <application>mriclient</application> to
      send the data from another terminal:</para>

      <screen>user@host:~/temp$ mriclient \
    -d gadgetron_testdata.h5 \
    -g gre_tgrappa_rate4 \
    -c grappa.xml
Gadgetron MRI Data Sender
  -- host            :      localhost
  -- port            :      9002
  -- hdf5 file  in   :      gadgetron_testdata.h5
  -- hdf5 group in   :      gre_tgrappa_rate4
  -- conf            :      grappa.xml
  -- loop            :      1
  -- hdf5 file out   :      ./out.h5
  -- hdf5 group out  :      2012-05-11 15:43:03
(32580|140398140757824) Connection from 127.0.0.1:9002
32580, 81, GadgetronConnector, Close Message received
(32580|140398068885248) Handling close...
(32580|140398068885248) svc done...
(32580|140398068885248) Handling close...
</screen>

      <para>You should get example images that look similar to the ones in
      <xref linkend="fig.examplegrapparesult"/>.</para>

      <figure xml:id="fig.grappachain">
        <title>GRAPPA Reconstruction Chain</title>

        <mediaobject>
          <imageobject>
            <imagedata fileref="figs/grappa.png" width="4in"/>
          </imageobject>
        </mediaobject>
      </figure>

      <figure xml:id="fig.examplegrapparesult">
        <title>GRAPPA Reconstruction Results</title>

        <mediaobject>
          <imageobject>
            <imagedata fileref="figs/examplegrapparesult.png" format="PNG"
                       width="5in"/>
          </imageobject>
        </mediaobject>
      </figure>

      <para>Let's take a closer look at some of the components of this
      reconstruction application.</para>

      <para>The first Gadget is the <classname>NoiseAdjustGadget</classname>.
      As described in <xref linkend="sect.mrigadgets"/>, the purpose of this
      Gadget is to decorrelate the noise in the receiver channels. This
      improves the parallel imaging performance, especially in cases where
      there is a large amount of noise in just a few receiver elements. There
      are two versions of this Gadget, one that uses the BLAS/LAPACK routines
      for performance improvements and one that implements the same
      functionality without these optimizations. When you call the included
      <filename>grappa.xml</filename> configuration, you will use the
      optimized version. If you do not have BLAS and LAPACK on your system,
      you can modify the XML configuration to use the one from the
      <filename>gadgets/core</filename> library.</para>

      <para>Second step is removing the oversampling. This step could also be
      performed after the reconstruction (as it is done in <xref
      linkend="sect.2dftexample"/>), but here we opt to remove this excess
      data to improve downstream performance.</para>

      <para>The purpose of the next two Gadgets
      (<classname>PCAGadget</classname> and
      <classname>CoilReductionGadget</classname>) is to a) transform the
      receiver coils into PCA virtual coils ordered by their information
      content and b) remove some of the coils to improve downstream
      performance. The first step is achieved by buffering the first frame of
      data and then performing a principal component analysis (PCA) on the
      first frame of data. Based on the determined PCA transformation all data
      is then subsequently transformed into virtual coils. In the coil
      reduction gadget we can now simple eliminate the channels that are above
      a certain number. See <xref linkend="sect.mrigadgets"/> for details on
      how to control the channel compression.</para>

      <para>The next two Gadgets are responsible for the actual GRAPPA
      reconstruction. The <classname>GrappaGadget</classname> calculates the
      GRAPPA coefficients and <classname>GrappaUnmixingGadget</classname>
      performs the Fourier transform of the raw data and applies the GRAPPA
      coefficients to the aliased imaged to obtain unaliased images.</para>

      <para>In general it is assumed that the data is acquired in such a way
      that a set of neighboring frames can be averaged to yield a fully
      sampled k-space; the data is acquired with a time-interleaved sampling
      pattern. When enough calibration data is available to calculate GRAPPA
      coefficients, i.e. when a fully sampled region of k-space is available,
      the calibration data is sent to a grappa coefficient calculation object
      (<classname>GrappaWeightsCalculator</classname>).</para>

      <para>The <classname>GrappaWeightsCalculator</classname> is an active
      object, which picks up weight calculation jobs from an input queue and
      passes them on to the GPU where it uses toolbox functions to calculate
      GRAPPA unmixing coefficients. These coefficients are Fourier transformed
      to image space where they are combined for all coils and stored in a
      <classname>GrappaWeights</classname> object.</para>

      <para>When the <classname>GrappaGadget</classname> passes on the raw
      data to the <classname>GrappaUnmixingGadget</classname> it passes a
      reference to the <classname>GrappaWeights</classname> object which is to
      be used when performing the unmixing operation. Let's have closer look
      at the <filename>GrappaUnmixingGadget.h</filename> file:</para>

      <programlisting>struct GrappaUnmixingJob
{
 boost::shared_ptr&lt; GrappaWeights&lt;float&gt; &gt; weights_;
};

class GrappaUnmixingGadget: 
public Gadget3&lt;GrappaUnmixingJob, 
               GadgetMessageImage, 
               hoNDArray&lt;std::complex&lt;float&gt; &gt; &gt; 
{
public:
 GADGET_DECLARE(GrappaUnmixingGadget);

 GrappaUnmixingGadget();
 virtual ~GrappaUnmixingGadget();
protected:
 virtual int process(GadgetContainerMessage&lt;GrappaUnmixingJob&gt;* m1,
   GadgetContainerMessage&lt;GadgetMessageImage&gt;* m2, 
   GadgetContainerMessage&lt;hoNDArray&lt;std::complex&lt;float&gt; &gt; &gt;* m3);

};
</programlisting>

      <para>We can see that the <classname>GrappaUnmixingGadget</classname> is
      an example of a Gadget, which takes 3 arguments and the additional
      argument in this case holds a reference to the unmixing
      coefficients.</para>

      <para>The <classname>GrappaWeightsCalculator</classname> will update the
      coefficients as often as it is instructed to do so and the
      <classname>GrappaGadget</classname> is in charge of determining when an
      update should be done. Specifically, it monitors the incoming data and
      when the slice orientation changes, a job will be submitted to update
      the coefficients. If the slice is not changing, it is in principle OK to
      continue with the current coefficients, but if data is available and the
      <classname>GrappaWeightsCalculator</classname> is idle (the queue is
      empty) a job will be submitted.</para>

      <para>With this design, the data passes through the
      <classname>GrappaGadget</classname> very quickly and the
      <classname>GrappaUnmixingGadget</classname> can reconstruction the
      images very quickly, i.e. it is simply a Fourier transform and an
      element wise multiplication and sum over the coils. It is in other words
      designed for very high throughput.</para>

      <para>If the slice orientation changes, new coefficients will be
      calculated, but this calculation will not be done by the time the data
      reaches the <classname>GrappaUnmixingGadget</classname> and
      consequently, the images will be reconstructed with the "old"
      coefficients until the coefficients are ready. This design ensures low
      latency, but when the slice changes, aliasing may occur for a few frames
      until coefficients are updated.</para>

      <para>After the unmixing, the images are scaled and magnitude is
      extracted before returning images to the client. The
      <classname>AutoScaleGadget</classname> has been added in this case to
      ensure that images are in a reasonable range before converting to
      unsigned short as the output in this case. Automatic image scaling can
      be problematic, especially when doing quantitative imaging, but it was
      added in this case to make the reconstruction more robust to data from
      different sources. A better solution is to only use data where noise
      calibration data is available and reconstruct SNR scaled images. Based
      on typical SNR values for MRI images, it is fairly trivial to keep the
      images in the appropriate range and perform a proper conversion to
      unsigned short.</para>

      <para>A final comment about the GRAPPA reconstruction is that it allows
      a second step of channel compression. More specifically, it is possible
      to reconstruct to a limited number of target channels to further improve
      performance. Between the upstream and downstream channel compression
      steps, it is possible to tune the performance of the reconstruction to
      enable real-time reconstruction on the available. hardware.</para>
    </sect1>

    <sect1 xml:id="sect.cgsense">
      <title>Non-Cartesian 2D Parallel MRI (SENSE)</title>

      <para>The Gadgetron includes a real-time implementation of a GPU-based
      real-time non-Cartesian Sense reconstruction published in <citation
      linkend="sorensen09"><xref linkend="sorensen09"/></citation>. One of the
      keys to obtaining real-time performance is an efficient GPU
      implementation of the non-Cartesian Fast Fourier Transform
      <citation><xref linkend="sorensen08"/></citation>. The application
      reuses several of the gadgets we have seen in use already for the
      Cartesian Grappa implementation above (<xref linkend="sect.grappa"/>).
      An overview of the non-Cartesian Sense gadget chain is given in figure
      <xref linkend="fig.cgsense"/>. <figure xml:id="fig.cgsense">
          <title>Gadgetron Chain for Non-Cartesian Sense</title>

          <mediaobject>
            <imageobject role="html">
              <imagedata align="left" fileref="figs/cgsense.png" format="PNG"
                         width="3in"/>
            </imageobject>

            <imageobject role="fo">
              <imagedata align="left" fileref="figs/cgsense.png" format="PNG"
                         width="3in"/>
            </imageobject>

            <textobject>
              <phrase>Gadgetron chain for non-Cartesian Sense</phrase>
            </textobject>
          </mediaobject>
        </figure></para>

      <para>The <classname>CGSenseGadget</classname> implements the
      non-Cartesian Sense reconstruction. It contains a conjugate gradient
      solver (<xref linkend="sect.linear_solvers"/>) set up with a
      <classname>nonCartesianSense</classname> image encoding matrix and an
      <classname>imageOperator</classname> for regularization. Internally it
      maintains a cyclic buffer of a few seconds of imaging data. It uses this
      buffer to maintain a fully sampled (i.e. unaliased but blurred) k-space
      image from which coil sensititivities and regularization images are
      dynamically estimated. The combination of parallel imaging and image
      regularization operators allows for alias-suppressed image
      reconstruction using significant undersampling hereby achieving
      real-time data acquisition rates per frame. The conjugate gradient
      solver is able to reconstruct faster than the acquisition time e.g. a
      192x192 image from 32 coils using 10 solver iterations on newer graphics
      hardware.</para>

      <para>To test this configuration use the 32 channel radial MRI test
      dataset (<filename>gre_golden_angle</filename>) from
      <filename>gadgetron_testdata.h5</filename>, which you can download from
      <uri
      xlink:href="https://sourceforge.net/projects/gadgetron/files/testdata/mri/">
      https://sourceforge.net/projects/gadgetron/files/testdata/mri/</uri>. We
      assume that you have added <envar>$(GADGETRON_HOME)/bin</envar> to your
      <envar>PATH</envar> environment variable. You need a CUDA enable GPU on
      your system and your Gadgetron distribution should be compiled with CUDA
      and CULA enabled. Please see <xref linkend="sect.installation"/> for
      details for your specific platform.</para>

      <para>To run the reconstruction; start up
      <application>gadgetron</application> (in its own terminal window) and
      use the <application>mriclient</application> to send the data from
      another terminal. First start
      <application>gadgetron</application>:</para>

      <screen>user@host$ <userinput>gadgetron</userinput> 
Configuring services</screen>

      <para>If asked, allow the gadgetron application to allow incoming
      network connection. Next start the
      <application>mriclient</application>:</para>

      <screen>user@host:~/temp$ mriclient \
       -d gadgetron_testdata.h5 \
       -g gre_golden_angle \
       -c radial_single.xml

Gadgetron MRI Data Sender
  -- host            :      localhost
  -- port            :      9002
  -- hdf5 file  in   :      gadgetron_testdata.h5
  -- hdf5 group in   :      gre_golden_angle
  -- conf            :      radial_single.xml
  -- loop            :      1
  -- hdf5 file out   :      ./out.h5
  -- hdf5 group out  :      2012-05-11 15:47:22
(32608|139797448419136) Connection from 127.0.0.1:9002
32608, 81, GadgetronConnector, Close Message received
(32608|139797376546560) Handling close...
(32608|139797376546560) svc done...
(32608|139797376546560) Handling close...

</screen>

      <para>Your current folder now holds the reconstructed images in the
      <filename>out.h5</filename> HDF5 file. They will look something like the
      one depicted in <xref linkend="fig.examplecgsenseresult"/>. <figure
          xml:id="fig.examplecgsenseresult">
          <title>Non-Cartesian Sense Reconstruction Results</title>

          <mediaobject>
            <imageobject>
              <imagedata fileref="figs/examplecgsenseresult.png" format="PNG"
                         width="3in"/>
            </imageobject>
          </mediaobject>
        </figure></para>
    </sect1>
  </chapter>

  <chapter xml:id="sect.standalone_applications">
    <title>Standalone Applications</title>

    <para>This chapter demonstrates through a few examples how to use the
    Gadgetron toolboxes (<xref linkend="sect.toolboxes"/>) to build standalone
    applications outside the streaming framework. You need a CUDA enabled GPU
    on your system and your Gadgetron distribution should be compiled with
    CUDA (and CULA) enabled. Then the examples are automatically build with
    the Gadgetron and binaries should consequently be available in
    <envar>$GADGETRON_HOME/bin</envar>. </para>

    <sect1 xml:id="sect.image_denoising">
      <title>Image Denoising</title>

      <para>This example uses the unconstraint Split Bregman solver for total
      variation based 2D image denoising. The encoding matrix is defined as an
      <classname>identityOperator</classname> and a
      <classname>partialDerivativeOperator</classname> is used for each of the
      two spatial directions to implement the total variation regularization
      term. The two partial derivatives are added as a "group" of
      regularization operators to implement isotropic denoising.
      Alternatively, by changing a few lines of code they can be added as
      individual regularization operators instaed to implement anisotropic
      denoising.</para>

      <para>The full source code for the example can be found at
      <envar>$(GADGETRON_SOURCE)</envar><filename>/apps/standalone/gpu/denoising/2d/denoise_TV.cpp</filename>.</para>

      <para>You can download some noisy Shepp-Logan phantom test datasets from
      <uri
      xlink:href="https://sourceforge.net/projects/gadgetron/files/testdata/phantom/shepp_logan/shepp.tar.gz">https://sourceforge.net/projects/gadgetron/files/testdata/phantom/shepp.tar.gz</uri></para>

      <para>In a terminal, go to the folder in which you unpacked the data. We
      assume that you have added <envar>$(GADGETRON_HOME)/bin</envar> to your
      <envar>PATH</envar> environment variable.</para>

      <para>Try</para>

      <screen>user@host$ <userinput>denoise_TV -d shepp_logan_256_256_med_noise.real -O 250 -m 1</userinput>
Running denoising with the following parameters: 
---------------------------------------------------- 
  Noisy image file name (.real)  : shepp_logan_256_256_med_noise.real 
  Result file name               : denoised_image_TV.real 
  Number of cg iterations        : 20 
  Number of sb inner iterations  : 1 
  Number of sb outer iterations  : 250 
  Regularization weight (mu)     : 1 
---------------------------------------------------- 
...
user@host$</screen>

      <para>which runs 250 iterations of the solver with a regularization
      weight of 1. The output is saved in the current folder in the file
      <filename>denoised_image_TV.real</filename>. </para>

      <para>The noisy and denoised phantom is depicted below.</para>

      <figure xml:id="fig.noisy2d">
        <title>A noisy version of the Shepp-Logan phantom</title>

        <mediaobject>
          <imageobject>
            <imagedata fileref="figs/shepp_noisy.png" format="PNG" width="2in"/>
          </imageobject>
        </mediaobject>
      </figure>

      <figure>
        <title>Result after total variation denoising</title>

        <mediaobject>
          <imageobject>
            <imagedata fileref="figs/shepp_denoised.png" format="PNG"
                       width="2in"/>
          </imageobject>
        </mediaobject>
      </figure>

      <para>Running <application>denoise_TV</application> with no arguments
      prints out a brief usage description. We leave it as an exercise to run
      the algorihm with various settings. The data file you downloaded
      contains two further dataset (with lower and higher noise levels
      respectively) to try out as well.</para>
    </sect1>

    <sect1>
      <title>Image Deblurring</title>

      <para>This example uses 1) the linear least squares solver, and 2) the
      constraint Split Bregman solver for image deblurring. The encoding
      matrix is defined as a <classname>convolutionOperator</classname>. A
      <classname>partialDerivativeOperator</classname> is added for each of
      the two spatial directions as regularization terms.</para>

      <para>We reuse the Shepp-Logan data from the image denoising experiement
      above (<xref linkend="sect.image_denoising"/>).</para>

      <para>First we generate a blurry Shepp-Logan phantom by convolution with
      a Gaussian kernel. This is easily achieved using the method
      <function>mult_M</function> in the
      <classname>convolutionOperator</classname>. Soure code is provided at
      <envar>$(GADGETRON_SOURCE)</envar><filename>/apps/standalone/gpu/deblurring/2d/blur_2d.cpp</filename></para>

      <para>In a terminal, go to the folder in which you unpacked the Shepp
      Logan phantom.</para>

      <para>Try</para>

      <screen>user@host$ <userinput>blur_2d -d shepp_logan_256_256_no_noise.real</userinput></screen>

      <para>which generates two complex images;
      <filename>blurred_image.cplx</filename> and
      <filename>kernel_image.cplx</filename>. For convienience a corresponding
      magnitudes image is also saved as
      <filename>blurred_image.real</filename>.</para>

      <para>Next run the conjugate gradient solver. The source code for the
      example can be found in
      <envar>$(GADGETRON_SOURCE)</envar><filename>/apps/standalone/gpu/deblurring/2d/deblur_2d_cg.cpp</filename>.</para>

      <screen>user@host$ <userinput>deblur_2d_cg -K 1e-4</userinput>
 Running deblurring with the following parameters: 
---------------------------------------------------- 
  Blurred image file name (.cplx)  : blurred_image.cplx 
  Kernel image file name (.cplx)   : kernel_image.cplx 
  Result file name                 : cg_deblurred_image.cplx 
  Number of iterations             : 25 
  Regularization weight            : 1e-4 
---------------------------------------------------- 
Iterating...
...
user@host$</screen>

      <para>The result is saved in the current folder in the file
      <filename>cg_deblurred_image.cplx</filename>. A magnitudes image is also
      saved as <filename>cg_deblurred_image.real</filename>. </para>

      <para>Next run the constraint Split Bregman solver. The source code for
      the example can be found in
      <envar>$(GADGETRON_SOURCE)</envar><filename>/apps/standalone/gpu/deblurring/2d/deblur_2d_sb.cpp</filename>.</para>

      <screen>user@host$ <userinput>deblur_2d_sb -O 100 -L 0.5 -M 0.5</userinput>
 Running deblurring with the following parameters: 
---------------------------------------------------- 
  Blurred image file name (.cplx)  : blurred_image.cplx 
  Kernel image file name (.cplx)   : kernel_image.cplx 
  Result file name                 : sb_deblurred_image.cplx 
  Number of cg iterations          : 20 
  Number of sb inner iterations    : 1 
  Number of sb outer iterations    : 100 
  Mu                               : 0.5 
  Lambda                           : 0.5 
---------------------------------------------------- 
...
user@host$</screen>

      <para>The result is saved as
      <filename>sb_deblurred_image.cplx</filename>. A magnitudes image is also
      saved as <filename>sb_deblurred_image.real</filename>. </para>

      <para>The blurred and deblurred phantoms are depicted below.</para>

      <figure>
        <title>Blurry Shepp-Logan phantom</title>

        <mediaobject>
          <imageobject>
            <imagedata fileref="figs/shepp_blurred.png" format="PNG"
                       width="2in"/>
          </imageobject>
        </mediaobject>
      </figure>

      <figure>
        <title>Deblurred phantom from the Conjugate Gradient solver</title>

        <mediaobject>
          <imageobject>
            <imagedata fileref="figs/shepp_deblurred_cg.png" format="PNG"
                       width="2in"/>
          </imageobject>
        </mediaobject>
      </figure>

      <figure>
        <title>Deblurred phantom from the constrained Split Bregman
        solver</title>

        <mediaobject>
          <imageobject>
            <imagedata fileref="figs/shepp_deblurred_sb.png" format="PNG"
                       width="2in"/>
          </imageobject>
        </mediaobject>
      </figure>

      <para>In the present examples no noise was added to the blurred images
      before the deconvolution. Consequently for the conjugate gradient
      solver, a very low weight of the regularization term was "sufficient".
      We leave it as an exercise to run the algorihms with various settings.
      In particular, try to add noise to the blurred image before the
      deconvolution to observe the very ill-posed nature of the
      problem.</para>

      <para><remark>Notice</remark>. If the dimensions of the provided
      convolution kernel is exactly double that of the provided image, the
      convolution operator zero-pads the image before the convolution and
      removes the padding again after. As the convolution operator utilizes
      FFTs in its implementation, this oversampling is a way of avoiding
      cyclic boundary conditions during the convolution.</para>
    </sect1>

    <sect1>
      <title>Non-Cartesian FFT</title>

      <para>This example shows how to use the forwards and adjoint
      non-Cartesian Fast Fourier Transform (NFFT and
      NFFT<superscript>H</superscript> respecitvely) on a 2D image. The source
      code can be found at
      <envar>$(GADGETRON_SOURCE)</envar><filename>/apps/standalone/gpu/MRI/nfft/2d/main_nfft.cpp</filename>
      and
      <envar>$(GADGETRON_SOURCE)</envar><filename>/apps/standalone/gpu/MRI/nfft/2d/main_nffth.cpp</filename>.</para>

      <para>We reuse the Shepp-Logan data downloaded for the previous
      experiments (<xref linkend="sect.image_denoising"/>).</para>

      <para>In the following we run the NFFT followed by the
      NFFT<superscript>H</superscript>. The image matrix size is
      256<superscript>2</superscript>. We use an oversampled matrix size of
      384<superscript>2</superscript>, 128 profiles in k-space (<emphasis
      role="underline">undersampling</emphasis>) with 384 samples each. The
      NFFT Kaiser-Bessel convolution kernel width is set to
      5.5<superscript>2</superscript> (see <xref
      linkend="sorensen08"/>).</para>

      <screen>user@host$ <userinput>nfft -d shepp_logan_256_256_no_noise.real \ 
   -o 384 -p 128 -s 384 -k 5.5
</userinput>
 Running reconstruction with the following parameters: 
---------------------------------------------------- 
  Input image file name (.real)  : shepp_logan_256_256_no_noise.real 
  Result file name               : samples.cplx 
  Oversampled matrix size        : 384 
  Number of profiles             : 128 
  Samples per profiles           : 384 
  Kernel width                   : 5.5 
---------------------------------------------------- 
Loading image from disk
Uploading, normalizing and converting to complex
Initializing plan
Computing golden ratio radial trajectories
NFFT preprocessing
Computing density compensation weights
Computing nfft (inverse gridding)
Output result to disk
user@host$</screen>

      <screen>user@host$ <userinput>nffth -d samples.cplx -m 256 -o 384 -k 5.5</userinput>
 Running reconstruction with the following parameters: 
---------------------------------------------------- 
  Input samples file name (.cplx)  : samples.cplx 
  Output image file name (.cplx)   : result.cplx 
  Matrix size                      : 256 
  Oversampled matrix size          : 384 
  Kernel width                     : 5.5 
---------------------------------------------------- 
Loading samples from disk
Uploading samples to device
Initializing plan
Computing golden ratio radial trajectories
NFFT preprocessing
Computing density compensation weights
Computing nffth (gridding)
Output result to disk
user@host$</screen>

      <para>The result is saved in file <filename>result.cplx</filename>. A
      magnitudes image is saved as <filename>result.real</filename>. The
      result is shown below. As an exercise, experiment with the settings to
      reduce (or increase) the aliasing.</para>

      <figure>
        <title>Shepp-Logan phantom</title>

        <mediaobject>
          <imageobject>
            <imagedata fileref="figs/shepp.png" format="PNG" width="2in"/>
          </imageobject>
        </mediaobject>
      </figure>

      <figure>
        <title>Shepp-Logan phantom after application of a ("two-fold")
        undersampled golden ratio based radial NFFT followed by the
        NFFT<superscript>H</superscript></title>

        <mediaobject>
          <imageobject>
            <imagedata fileref="figs/shepp_iteration.png" format="PNG"
                       width="2in"/>
          </imageobject>
        </mediaobject>
      </figure>

      <para>The <envar>
      $(GADGETRON_SOURCE)</envar><filename>/apps/standalone/gpu/MRI/nfft/2d/</filename>
      folder also contains examples of using the
      <classname>nfftOperator</classname> in a Conjugate Gradient solver and a
      Split Bregman solver respectively.</para>
    </sect1>
  </chapter>

  <chapter>
    <title>Frequently Asked Questions (FAQ)</title>

    <itemizedlist>
      <listitem>
        <para><emphasis>Can I make a branching Gadget chain?</emphasis></para>

        <para>The short answer is no. We plan on supporting this in a future
        release, but it is not quite ready yet.</para>
      </listitem>

      <listitem>
        <para><emphasis>How can I help?</emphasis></para>

        <para>We are always looking for people who are interested in helping
        with the continuing development of the Gadgetron. There are many
        things you can do:</para>

        <itemizedlist>
          <listitem>
            <para>Use it.</para>
          </listitem>

          <listitem>
            <para>When you develop new Gadgets or Toolboxes, please consider
            submitting them to us so that we can include them in the
            archive.</para>
          </listitem>

          <listitem>
            <para>Help us implement some of the future features in <xref
            linkend="futurefeatures"/>. It is probably a good idea to get in
            touch with us before you start coding, just in case somebody is
            already working on it.</para>
          </listitem>
        </itemizedlist>
      </listitem>
    </itemizedlist>
  </chapter>

  <appendix xml:id="simplearrayfiles">
    <title>Simple Array File Format</title>

    <para>When working with the Gadgetron it is often necessary to write files
    with reconstructed images to disk, either as part of debugging or as the
    final reconstruction result. We have adopted a very simple
    multidimensional array file format for this purpose. The main advantage of
    this file format is its simplicity but there are a number of disadvantages
    and caveats as well as described in this section.</para>

    <para>The simple array files are made up of a) a header followed by b) the
    data itself. This layout of data and header is illustrated in <xref
    linkend="fig.gadgetron.fileformat"/>. The header has a single 32-bit
    integer to indicate the number of dimensions of the dataset followed by
    one integer for each dimension to indicate the length of that dimension.
    The data follows immediately after the header. The data is stored such
    that the first dimension is the fastest moving dimension, second dimension
    is second fastest, etc. The header contains no information about the size
    of each individual data element and consequently the user needs to know
    what type of data is contained in the array. In general, the Gadgetron
    uses 3 different types of data and the convention is to use the file
    extension to indicate the data type in the file:</para>

    <itemizedlist>
      <listitem>
        <para>16-bit unsigned short. File extension:
        <filename>*.short</filename></para>
      </listitem>

      <listitem>
        <para>32-bit float. File extension: <filename>*.real</filename></para>
      </listitem>

      <listitem>
        <para>32-bit complex float. Two 32-bit floating point values per data
        element. File extension: <filename>*.cplx</filename></para>
      </listitem>
    </itemizedlist>

    <figure xml:id="fig.gadgetron.fileformat">
      <title>Simple Array File Format</title>

      <mediaobject>
        <imageobject condition="print">
          <imagedata align="left" fileref="figs/arrayfileformat.png"
                     format="PNG" width="2in"/>
        </imageobject>

        <textobject>
          <phrase>Simple Array</phrase>
        </textobject>
      </mediaobject>

      <caption>
        <para>The simple array file format has a header followed by the data.
        The header consists of one 32-bit integer defining the number of
        dimensions (N-dimensions) followed by N-dimensions 32-bit unsigned
        integers each defining the length of each dimensions. In the example,
        the dataset has 4 dimensions and the size of those dimensions is
        128x128x1x1, i.e. 16384 elements.</para>
      </caption>
    </figure>

    <para>The Gadgetron framework provides function for reading these files in
    C++. The functions are located in
    <filename>toolboxes/ndarray/hoNDArray_fileio.h</filename> in the Gadgetron
    source code distribution.</para>

    <para>It is also trivial to read the files into Matlab. Below is a
    function which detects the data type based on the file extension and reads
    the file into Matlab.</para>

    <programlisting>

function data = read_gadgetron_array(filename)
%  data = read_gadgetron_array(filename)
%  
%  Reads simplified array format output from the Gadgetron
%
%  The datatype is determined by the file extension.
%     - *.short : 16-bit unsigned integer
%     - *.real  : 32-bit float
%     - *.cplx  : 32-bit complex (two 32-bit values per data element)
%
%
if (~exist(filename,'file')),
    error('File not found.');
end

[path,name,ext] = fileparts(filename);

ext = lower(ext);

if (~strcmp(ext,'.short') &amp;&amp; ~strcmp(ext,'.real') &amp;&amp; ~strcmp(ext,'.cplx')),
   error('Unknown file extension'); 
end

f = fopen(filename);
ndims = fread(f,1,'int32'); 
dims = fread(f,ndims,'int32'); 

switch ext
    case '.short'
        data = fread(f,prod(dims),'uint16'); 
    case '.real'
        data = fread(f,prod(dims),'float32'); 
    case '.cplx'
        data = fread(f,2*prod(dims),'float32'); 
        data = complex(data(1:2:end),data(2:2:end));
    otherwise     
end

fclose(f);

data = reshape(data,dims');

end

  </programlisting>
  </appendix>

  <appendix xml:id="section.hdf5">
    <title>HDF5 Files</title>

    <para>The Gadgetron framework is used to procress many different types of
    data and it is cumbersome to add specific read and write routines for all
    these different kinds of data. Consequently we have chosen to use the
    generic HDF5 file format. A detailed description of this format can be
    found at <uri>http://www.hdfgroup.org/HDF5/</uri>.</para>

    <para>The HDF5 file format is much like a file system. Data can be
    organized hierarchically into groups (like folders in a filesystem) and
    each file can contain multiple groups and datasets. Each dataset can be an
    array of any type, e.g. an array of images. There is a generic tool
    <command>hdfview</command> which can be used to view the files. It is
    available on all the platforms supported by the Gadgetron framework. HDF5
    files can also be read easily in newer versions of Matlab.</para>

    <para>As an example of a HDF5 file with MRI raw data can be found at <uri
    type="website"
    xlink:href="https://sourceforge.net/projects/gadgetron/files/testdata/">https://sourceforge.net/projects/gadgetron/files/testdata/</uri>.
    Download the file <filename>gadgetron_testdata.h5</filename>. When opened
    with <command>hdfview</command>, it should look like <xref
    linkend="fig.hdfview_testdata"/>. As seen, the file contains 4 groups of
    data. Each group consists of some data and an XML configuration for the
    Gadgetron.</para>

    <figure xml:id="fig.hdfview_testdata">
      <title>Examining Data with HDFView</title>

      <screenshot>
        <mediaobject>
          <imageobject>
            <imagedata fileref="figs/hdfview_mri_testdata.png" width="6in"/>
          </imageobject>
        </mediaobject>
      </screenshot>
    </figure>

    <para>HDF5 Files can also be used to store images. Several of the
    Gadgetron clients included with the framework save images in HDF5 files.
    An example of viewing the output of a reconstruction can be seen in <xref
    linkend="fig.hdfview_image"/>.</para>

    <figure xml:id="fig.hdfview_image">
      <title>Viewing Images in HDF5 Files</title>

      <mediaobject>
        <imageobject>
          <imagedata fileref="figs/hdfview_image_view.png" width="5.5in"/>
        </imageobject>
      </mediaobject>
    </figure>

    <para>Images saved by Gadgetron clients are saved as arrays in the HDF5
    files. Due to the array storage conventions in the Gadgetron environment,
    the first dimension is the slowest varying dimension in the arrays and the
    last dimention is the fastest varying dimention. That means that an array
    with 10 images with dimensions 128x128 would be stored in a variable in
    the HDF5 file with dimensions 10x1x128x128 as seen in <xref
    linkend="fig.hdfview_image"/>. To display the images, right click on the
    data and choose settings as illustrated in <xref
    linkend="fig.settings_hdfview"/>.</para>

    <figure xml:id="fig.settings_hdfview">
      <title>Setting for viewing HDF5 output images.</title>

      <mediaobject>
        <imageobject>
          <imagedata fileref="figs/hdfview_image_view_setting.png" width="3in"/>
        </imageobject>
      </mediaobject>
    </figure>

    <para>The HDF5 files can also be read with Matlab. The images in the file
    above could be read with:<programlisting>&gt;&gt; images = h5read('out.h5','/2012-05-11 10:57:48/data_0');
&gt;&gt; size(images)

ans =

   128   128     1    10

&gt;&gt; imagesc(images(:,:,1,1));colormap(gray) 
</programlisting></para>
  </appendix>

  <appendix xml:id="futurefeatures">
    <title>Future Features</title>

    <para>The Gagdetron is evolving continuously and there are many things
    still that we would like to include but have not yet had the time to do.
    This appendix serves as a to-do list of features to be implement as we go
    along.</para>

    <itemizedlist>
      <listitem>
        <para>Branching Gadget chains. There is currently no ability to branch
        and collect in the Gadgetron.</para>
      </listitem>

      <listitem>
        <para>Persistent memory storage across Gadget chains.</para>
      </listitem>

      <listitem>
        <para>Matlab Gadgets. It would be great to have a way to encapsulate
        Matlab code in a Gadget similar to the way that the Python Gadgets
        work.</para>
      </listitem>
    </itemizedlist>
  </appendix>

  <bibliography>
    <biblioentry role="article" xml:id="hansen12">
      <abbrev>HANSEN12</abbrev>

      <biblioset role="article">
        <authorgroup>
          <author>
            <personname><firstname>M. S.</firstname>
            <surname>Hansen</surname></personname>
          </author>

          <author>
            <personname><firstname>T. S.</firstname>
            <surname>SÃ¸rensen</surname></personname>
          </author>
        </authorgroup>

        <title>Gadgetron: An Open Source Framework for Medical Image
        Reconstruction</title>
      </biblioset>

      <biblioset role="journal">
        <title>Magnetic Resonance in Medicine</title>

        <volumenum>Submitted</volumenum>

        <pubdate>2012</pubdate>
      </biblioset>
    </biblioentry>

    <biblioentry role="article" xml:id="hansen08">
      <abbrev>HANSEN08</abbrev>

      <biblioset role="article">
        <authorgroup>
          <author>
            <personname><firstname>M. S.</firstname>
            <surname>Hansen</surname></personname>
          </author>

          <author>
            <personname><firstname>D.</firstname>
            <surname>Atkinson</surname></personname>
          </author>

          <author>
            <personname><firstname>T. S.</firstname>
            <surname>SÃ¸rensen</surname></personname>
          </author>
        </authorgroup>

        <title>Cartesian SENSE and k-t SENSE reconstruction using commodity
        graphics hardware</title>
      </biblioset>

      <biblioset role="journal">
        <title>Magnetic Resonance in Medicine</title>

        <volumenum>59 (3), 463-468</volumenum>

        <pubdate>2008</pubdate>
      </biblioset>
    </biblioentry>

    <biblioentry role="article" xml:id="sorensen08">
      <abbrev>SANGILD08</abbrev>

      <biblioset role="article">
        <authorgroup>
          <author>
            <personname><firstname>T. S.</firstname>
            <surname>SÃ¸rensen</surname></personname>
          </author>

          <author>
            <personname><firstname>T.</firstname>
            <surname>Schaeffter</surname></personname>
          </author>

          <author>
            <personname><firstname>K. O.</firstname>
            <surname>Noe</surname></personname>
          </author>

          <author>
            <personname><firstname>M. S.</firstname>
            <surname>Hansen</surname></personname>
          </author>
        </authorgroup>

        <title>Accelerating the nonequispaced fast fourier transform on
        commodity graphics hardware</title>

        <pagenums>538--47</pagenums>

        <bibliosource class="doi">10.1109/TMI.2007.909834</bibliosource>
      </biblioset>

      <biblioset role="journal">
        <title>IEEE Trans Med Imaging</title>

        <volumenum>27</volumenum>

        <issuenum>4</issuenum>

        <pubdate>Apr 2008</pubdate>
      </biblioset>
    </biblioentry>

    <biblioentry role="article" xml:id="sorensen09">
      <abbrev>SANGILD09</abbrev>

      <biblioset role="article">
        <authorgroup>
          <author>
            <personname><firstname>T. S.</firstname>
            <surname>SÃ¸rensen</surname></personname>
          </author>

          <author>
            <personname><firstname>D.</firstname>
            <surname>Atkinson</surname></personname>
          </author>

          <author>
            <personname><firstname>T.</firstname>
            <surname>Schaeffter</surname></personname>
          </author>

          <author>
            <personname><firstname>M. S.</firstname>
            <surname>Hansen</surname></personname>
          </author>
        </authorgroup>

        <title>Real-time reconstruction of sensitivity encoded radial magnetic
        resonance imaging using a graphics processing unit</title>

        <pagenums>1974--85</pagenums>

        <bibliosource class="doi">10.1109/TMI.2009.2027118</bibliosource>
      </biblioset>

      <biblioset role="journal">
        <title>IEEE Trans Med Imaging</title>

        <volumenum>28</volumenum>

        <issuenum>12</issuenum>

        <pubdate>Dec 2009</pubdate>
      </biblioset>
    </biblioentry>
  </bibliography>
</book>
